\chapter{指令级并行及其开发}
“谁是第一？”
“美国。”
“谁是第二？”
“没有第二。”
这是数年一度的“美洲杯”帆船赛后两位观众之间的对话。
Jobn Cocke受到它的启发将IBMI 的研究处理器命名为“美国”。T46
这个处理器是 RS/6000 系列的前身，是第一个超标量徽处理器。

\section{指令级并行：概念与挑战}
大约198S年之后的所有处理器都使用流水线来重叠指令的执行过程，以提高性能。由于指
令可以并行执行，所以指令之间可能实现的这种重叠称为指令级并行（ILP）。在本章和附录H
中，我们将研究一系列通过提高指令并行度来扩展基本流水线概念的技术。

与附录C中有关流水线的基础材料相比，本章内容要深入得多。如果读者还不是特别熟悉
附录C中的思想，应当在复习这个附录之后再开始探索本章内容。

本章首先研究数据和控制冒险带来的局限性，然后再转而讨论如何提高编译器和处理器对
并行的开发能力。在这几节中介绍了大量概念，本章和下一章都以这些概念为基础。尽管在理
解本章中一些比较基础的材料时并不需要前两节的全部思想，但这一基础材料对于本章后面各
节非常重要。

ILP大体有两种不同开发方法：（1）依靠硬件来帮助动态发现和开发并行，（2）依靠软件技术
在编译时静态发现并行。使用基于硬件动态方法的处理器，包括 Intel Core 系列，在桌面和服务
器市场上占据主导地位。在个人移动设备市场，提高能耗效率通常是一个关键目标，所以设计
人员开发较低级别的指令级并行。因此，2011年，PMD 市场的大多数处理器都采用静态方法，
我们将会看到 ARM Cortex-A8 中即是如此；不过，未来的处理器（比如新的ARM Cortex-A9）
将采用动态方法。从20世纪80年代开始到最近的Intel Itanium 系列，人们已经无数次尝试基于
编译器的积极方法。尽管付出了无数努力，但除了非常有限的科学应用领域之外，这些方法都
没有获得成功。

过去几年里，在主要基于某种方法进行设计时，也会采用大量原本为另一方法开发的技
术。本章介绍这些基本概念和这两种方法，还讨论 ILP 方法的一些局限性，正是因为这些局
限性而直接导致了向多核的转移。深人了解这些局限性对于平衡ILP 与线程级并行的应用仍
然非常重要。

在这一节，我们将讨论程序和处理器的一些特性，它们限制了可在指令间开发的并行数量，
还将介绍程序结构与硬件结构之间的一些重要映射，要知道某一程序特性是否会对性能造成限
制以及在什么条件下会造成限制，上述映射是非常关键的。

一个流水化处理器的CPI（每条指令占用的周期数）值等于基本CPI 与因为各种停顿而耗
费的全部周期之和：

\begin{equation}
    流水线 CPU=理想流水线 CPI+结构化停顿＋数据冒险停顿＋控制停顿
\end{equation}

理想流水线CPI 可以用来度量能够实现的最佳性能。通过缩短上式右侧各项，可以降低总
流水线CPI，也就是提高IPC（每个时钟周期执行的指令数）。利用上面的公式，我们可以说明
一项技术能够缩小总 CPI 的哪一部分，以此来刻画各种技术的特征。表3-1显示了将在本章和
附录H中研究的技术，还有一些主题将在附录C中的介绍性材料中介绍。在本章将会看到，我
们介绍用来降低理想流水线 CPI的技术会证明应对冒险的重要性。

表3-1 一井列出了附录C、第3章和附录H 中研究的主要技术，同时给出了这些技术会分别影CPI
公式的哪一部分
技术
转发和旁路
延迟分支和简单分支调度
降低CPI的哪一组成部分
潜在的数据冒险停顿
控制冒险停顿
章节
C.2
C.2
111
技术
基本编译器流水线调度
基本动态调度（记分板）
循环展开
分支预测
采用重命名的动态调度
硬件推测
动态存储器消除二义
每个周期发出多条指令
编译器相关性分析、软件流水线、踪迹调试
硬件支持编译器推测
降低CPI的哪一组成部分
数据冒险停顿
由真相关引起的数据冒险停顿
控制冒险停顿
控制停顿．
由数据冒险、输出相关和反相关引起的停顿
数据冒險和控制冒险停顿
涉及存储器的数据冒险停顿
理想CPI
理想CPI、数据冒险停顿
理想CPI、数据冒险停顿、分支冒险停顿
（续）
章
节
C2.32
C.7
3.2
3.3
3.4
3.6
3.6
3.7.3.8
H.2.H.3
HL4.H.5

\subsection{什么是指令级并行}
这一章的所有技术都是开发指令间的并行。基本块（一段顺序执行代码，除入口外没有其
他转人分支，除出口外没有其他转出分支）中可以利用的并行数非常有限。对于典型的MIPS
程序，平均动态分支频率通常介于15\%到25\%之间，也就是说在一对分支之同会执行3~6条
指令。由于这些指令可能相互依赖，所以在基本块中可以开发的重叠数量可能要少于基本块的
平均大小。为了真正地提高性能，我们必须跨越多个基本块开发 IL.P。

提高ILP 的最简单、最常见方法是在循环的各次迭代之间开发并行。这种并行经常被称作
循环级并行。下面是一个简单的循环示例，它对两个分别有1000个元素的数组求和，完全可以
并行实现：

\begin{verbatim}
    for(i=0; i<=999; i=i+1)
        x[i] = x[i] + y[i];
\end{verbatim}
这个循环的每一次迭代都可以与任意其他迭代重叠，当然，在每次循环迭代中进行重叠的机会
不大，甚至没有这种机会。

我们将研究大量将这种循环级并行转换为指令级并行的技术。这些技术的工作方式基本上
都是采用编译器静态展开循环（下一节介绍这种方法）或者利用硬件动态展开循环（3.5节、3.6
节介绍这种方法）。

开发循环级并行的一种重要替代方法是使用向量处理器和图形处理器（GPU）中的 SIMD，
这两种处理器都将在第4章介绍。SIMID 指令在开发数据级并行时，并行处理少量到中等数量
的数据项（通常为2~8项）。而向量指令在开发数据级并行时，则通过使用并行执行单元和深
流水线，并行处理许多数据项。例如，上述代码序列的简单形式在每次迭代中需要7条指令（2
次载人、1次求和、1次存储、2次地址更新和1次分支），总共7000条指令，而在每系指令可
以处理4个数据项的某种 SIMD 体系结构中，只需要四分之一的指令就能完成任务。在一些向
量处理器中，这个序列可能只需要4条指令：2条指令用于从存储器中载人向量×和y，1条指
令用于对两个问量求和，还有1条指令用于将结果向量存回存储器。当然，这些指令可以是流
水化的，其延迟相对较长，但可以对这些延迟进行重叠。

\subsection{数据相关与冒险}
要确定一个程序中可以存在多少并行以及如何开发并行，判断指令之间的相互依赖性是至
关重要的。具体来说，为了开发指令级并行，我们必须判断哪些指令可以并行执行。如果两条
指令是并行的，只要流水线有足够资源（因而也就不存在任何结构性冒险），就可以在一个任意
深度的流水线中同时执行它们，不会导致任何停顿。如果两条指令是相关的，它们就不是并行
的，尽管它们通常可以部分重叠，但必须按顺序执行。这两种情景的关键在于判断一条指令是
否依赖于另一指令。

\subsubsection{数据相关}
共有3种不同类型的相关：数据相关（也称光真数据相关）、名称相关和控制相关。如果以
下任一条件成立，则说指令j数据相关于指令i：

\begin{itemize}
    \item 指令i生成的结果可能会被指令j用到；
    \item 指令j数据相关于指令k，指令K数据相关于指令i。
\end{itemize}

第二个条件就是说：如果两条指令之间存在第一类型的相关链，那么这两条指令也是相关
的。这种相关链可以很长，贯穿整个程序。注意，单条指令内部的相关性（比如 ADDD R1,RI，
R1）不认为是相关。

例如，考虑以下 MIPS代码序列，它用寄存器 F2 中的一个标量来递增存储器中的一个值向
量（从O（R1）开始，最后一个元素是 8（R2））。（为简单起见，本章中的所有示例都忽略延迟分支
的影响。）
\begin{verbatim}
    L00p：
    L.D
    FO,O（R1）
    ；F0=数組元素
    ADD.D
    F4,F0,F2
    ；加上F2 中的标量
    S.D
    F4,0（R1）
    ；存储结果
    DADDUI R1,R1，#-8
    ；使指针递减8个字节
    BNE
    R1,R2,LOOP:R1！=R2 时跳转
\end{verbatim}
    这一代码序列中的数据相关涉及两个浮点数据：
\begin{verbatim}
    Loop：
    L.D
    50,0（R1）
    iFD=数組元素
    ADD.D
    F4,FO,F2
    ；加上F2中的标量
    S.D
    F4,0（R1）
    ；存储结果
\end{verbatim}
    和整型数据：
\begin{verbatim}
    DADDIU
    RI,R1，#-8 ；使指針通减8个字节
    ：（每个DW）
    BNE
    R1,R2,Loop ;R1！-R2 时跳转
\end{verbatim}
在以上两个相关序列中，如箭头所示，每条指令都依赖于上一条指令。这段代码及以下示例中给
出的箭头表示为了正确执行必须保持的顺序。位于箭头起始处的指令必须位于箭头所指指令之前。
如果两条指令是数据相关的，那它们必须按顺序执行，不能同时执行或不能完全重叠执行。

这种相关意味着两条指令之间可能存在由一个或多个数据冒险构成的链。（关于数据冒险的简
单描述，请参阅附录C，其中用几页的内容给出了数据冒险的详细定义。）同时执行这些指令会
导致一个具有流水线互锁（而且流水线深度大于指令间距离，以周期为单位）的处理器检测冒
险和停顿，从而降低或消除重叠。在依靠编译器调度、没有互锁的处理器中，编译器在调度相
关指令时不能使它们完全重叠，这样会使程序无法正常执行。指令序列中存在数据相关，反映
出据以生成该指令序列的源代码中存在数据相关。原数据相关的影响一定会保留下来。

相关是程序的一种属性。某种给定相关是否会导致检测到实际冒险，这一冒险又是否会实
际导致停顿，这都属于流水线结构的性质。这一区别对于理解如何开发指令级并行至关重要。
数据相关传递了三点信息：（1）冒险的可能性；（2）计算结果必须遵循的顺序；（3）可开发并行
度的上限。这些限制将在3.10节和附录H中进行更详尽的研究。

由于数据相关可能会限制我们能够开发的指令级并行数目，所以本章的一个重点就是如何
克服这些局限性。可以采用两种不同方法来克服相关性：（1）保护相关性但避免冒险；（2）通过转
换代码来消除相关性。对代码进行调度是在不修改相关性的情况下避免冒险的主要方法，这种
调度既可以由编译器完成，也可以由硬件完成。

数据值既可以通过寄存器也可以通过存储器位置在指令之间传送。当数据传送在寄存器中
发生时，由于指令中的寄存器名字是固定的，所以相关性的检测很简单，当然，如果存在分支
干扰以及为了保持正确性而迫使编译器或硬件变得保守，那可能会变得复杂一些。

当数据在存储器位置之间流动时，由于两个看起来不同的地址可能引用同一位置，所以其
相关性更难以检测，比如 100（R4）和 20（R6）可能是同一个存储器地址。此外，载入指令或存储指
令的实际地址可能会在每次执行时发生变化（所以 20（R4）和 20（R4）可能是不一样的），这使相关
性的检测进一步复杂化。

本章研究采用硬件来检测那些涉及存储器位置的数据相关，但我们将会看到，这些技术也
有局限性。用于检测这些相关的编译器技术是揭示循环级别并行的关键所在。

\subsubsection{名称相关}
第二种相关称为名称相关。当两条指令使用相同的寄存器或存储器位置（称为名称），但与
该名称相关的指令之间并没有数据流动时，就会发生名称相关。在指令i和指令j（按照程序顺
序，指令 位于指令 之前）之同存在两种类型的名称相关。

\begin{enumerate}
    \item 当指令j对指令i读取的寄存器或存储器位置执行写操作时就会在指令；和指令/之间发
    生反相关。为了确保i能读取到正确取值，必须保持原来的顺序。在前面的例子中，S.D和 DADDIU
    之间存在关于寄存器R1的反相关。
    \item 当指令i和指令j对同一个寄存器或存储器位置执行写操作时，发生输出相关。为了确
    保最后写人的值与指令；相对应，必须保持指令之间的排序。
\end{enumerate}

由于没有在指令之间传递值，所以反相关和输出相关都是名称相关，与真数据相关相对。
因为名称相关不是真正的相关，因此，如果改变这些指令中使用的名称（寄存器号或存储器位
置），使这些指令不再冲突，那名称相关中涉及的指令就可以同时执行，或者重新排序。
对于寄存器操作数，这一重命名操作更容易实现，这种操作称作寄存重命名。寄存器重
命名既可以由编译器静态完成，也可以由硬件动态完成。在介绍因分支导致的相关性之前，先
让我们来看看相关与流水线数据冒险之间的关系。

\subsubsection{数据冒险}
只要指令间存在名称相关或数据相关，而且它们非常接近，足以使执行期间的重叠改变对
相关操作数的访问顺序，那就会存在冒险。由于存在相关，必须保持程序顺序，也就是由原来
的源程序决定的指令执行顺序。软、硬件技术的目的都是尽量开发并行方式，仅在程序顺序会
影响程序输出时才保持程序顺序。检测和避免冒险可以确保不会打乱必要的程序顺序。
根据指令中读、写访问的顺序，可以将数据冒险分为三类，附录C中简要介绍了数据冒险。
根据惯例，一般按照流水线必须保持的程序顺序为这些冒险命名。考虑两条指令i和j，其中主
根据程序顺序排在j的前面。可能出现的数据冒险为：

\begin{itemize}
    \item RAW（写后读）—试图在；写人一个源位置之前读取它，所以j会错误地获得旧值。
    这一冒险是最常见的类型，与真数据相关相对应。为了确保j会收到来自i的值，必须保
    持程序顺序。
    
    \item WAW（写后写）——试图在：写一个操作数之前写该操作数。这些写操作最终将以错误
    顺序执行，最后留在目标位置的是由1写人的值，而不是由j写人的值。这种冒险与输出
    相关相对应。只有允许在多个流水级进行写操作的流水线中，或者在前一指令停顿时允
    许后一指令继续执行的流水线中，才会存在WAW冒险。
    
    \item WAR（读后写）—才尝试在：读取一个目标位置之前写人该位置，所以i会错误地获取
    新值。这一冒险源于反相关（或名称相关）。在大多数静态发射流水线中（即使是较深的
    流水线或者浮点流水线），由于所有读取操作都较早进行（在附录C流水线的中），
    所有写操作都要晚一些（附录C流水线中的WB中），所以不会发生 WAR冒险。如果有
    一些指令在指令流水线中提前写出结果，而其他指令在流水线的后期读取一个源位置，
    或者在对指令进行重新排序时，就会发生WAR冒险，在本章后面将对此进行讨论。
\end{itemize}

注意，RAR（读后读）情况不是冒险。

\subsection{控制相关}
最后一种相关是控制相关。控制相关决定了指令；相对于分支指令的顺序，使指令：按正确
程序顺序执行，而且只会在应当执行时执行。除了程序中第一基本块中的指令之外，其他所有
指令都与某组分支存在控制相关，一般来说，为了保持程序顺序，必须保留这些控制相关。控
制相关的最简单示例之一就是分支中 if语句的then 部分中的语句。例如，在以下代码段中：
\begin{verbatim}
    if p1 {
        S1;
    };
    if p2 {
        S2;
    }
\end{verbatim}
S1 与p1 控制相关，S2与p2控制相关，但与p1没有控制相关。
一般来说，控制相关会施加下述两条约束条件。

\begin{enumerate}
    \item 如果一条指令与一个分支控制相关，那就不能把这个指令移到这个分支之前，使它的执
    行不再受控于这个分支。例如，不能把if语句 then 部分中的一条指令拿出来，移到这个 if语
    句的前面。
    \item 如果一条指令与一个分支没有控制相关，那就不能把这个指令務到这个分支之后，使其
    执行受控于这个分支。例如，不能将 if之前的一个语句移到它的 then 部分。
\end{enumerate}

当处理器保持严格的程序顺序时，确保了控制相关也不会破坏。但是，在不影响程序正确
性的情况下，我们可能希望执行一些还不应当执行的指令，从而会违犯控制相关。因此，控制
相关并不是一个必须保持的关键特性。有两个特性对程序正确性是至关重要的，即异常行为和
数据流，通常保持数据相关与控制相关也就保护了这两种特性。

保护异步行为意味着对指令执行顺序的任何改变都不能改变程序中激发异常的方式。通常
会放松这一约束条件，要求改变指令的执行顺序时不得导致程序中生成任何新异常。下面的简
单示例说明维护控制相关和数据相关是如何防止出现这类情景的。考虑以下代码序列：
\begin{verbatim}
        DADDU   R2, R3, R4
        BEQZ    R2, L1
        LW      R1,O(R2)
    L1:
\end{verbatim}
在这个例子中，可以很容易地看出如果不维护涉及 R2 的数据相关，就会改变程序的结果。还有
一个事实没有那么明显：如果我们忽略控制相关，将载入指令移到分支之前，这个载人指令可
能会导致存储器保护异常。注意，没有数据相关禁止交换 BEOZ和LW；这只是控制相关。要允许
调整这些指令的顺序（而且仍然保持数据相关），我们可能希望在执行这一分支操作时忽略此异
常。在3.6节，我们将研究一种可以解决这一异常问题的硬件技术—推测。附录H研究用于
支持推测的软件技术。

通过维护数据相关和控制相关来保护的第二个特性是数据流。数据流是指数据值在生成结
果成和使用结果的指令之间进行的实际流动。分支允许一条给定指令从多个不同地方获取源数
据，从而使数据流变为动态的。换种说法，由于一条指令可能会与之前的多条指令存在数据相
关性，所以仅保持数据相关是不够的。一条指令的数据值究竟由之前哪条指令提供，是由程序
顺序决定的。而程序顺序是通过维护控制相关来保证的。

例如，考虑以下代码段：
\begin{verbatim}
        DADDU   R1,R2,R3
        BEQZ    R4,L
        DSUBU   RL,R5,R6
    L:
        OR      R7,R1,R8
\end{verbatim}

在这个例子中，OR指令使用的RI 值取决于是否进行了分支转移。单靠数据相关不足以保证正确
性。OR 指令数据相关于 DADDU 和 DSUBU 指令，但仅保持这一顺序并不足以保证能够正确执行。

在执行这些指令时，还必须保持数据流：如果没有进行分支转移，那么由 DSUBU 计算的 RI
值应当由 OR使用；如果进行了分支转移，由DADDU计算的 R1值则应当由OR使用。通过保持分
支中OR的控制相关，就能防止非法修改数据流。出于类似原因，DSUBU 指令也不能移到分支之
前。推测不但可以帮助解决异常问题，还能在仍然保持数据流的同时降低控制相关的影响，在
3.6节将会对此进行讨论。

有些情况下，我们可以断定违犯控制相关并不会影响异常行为或数据流。考虑以下代码
序列：
\begin{verbatim}
            DADDU   R1,R2,R3
            BEQZ    R12,skip
            DSUBU   R4,R5,R6
            DADDU   R5,R4,R9
    skip:   OR      R7,R8,R9
\end{verbatim}

假定我们知道DSUBU指令的目标寄存器（R4）在标有skip 的指令之后不再使用。（一个值是否会
被后续指令使用，这一特性被称为活性。）如果R4不会再被使用，由于它在 skip之后的代码部
分变为死亡（不再具备活性），那么就在这个分支之前改变R4的值并不会影响数据流。因此，
如果R4 已经死亡，而且现有DSUBU指令不会生成异常（处理器会从某些指令处重启同一过程，
这些指令除外），那就可以把DSUBU指令移到分支之前，数据流不会受这一改变的影响。

如果进行了分支转移，将会执行 DSUBU 指令，之后不再有用，但这样仍然不会影响程序结
果。由于编译器在对分支结果进行猜测，所以这种类型的代码调度也是一种推测形式，通常称
为软件推测；在这个例子中，编译器推测通常不会进行分支转移。附录H讨论了一些更加雄心
勃勃的编译器推测机制。在我们说到“推测”时，通常可以清楚地知道是在说硬件机制，还是
软件机制；如果不够明确，最好使用“硬件推测”或“软件推测”加以区分。

对导致控制停顿的控制冒险进行检测，可以保持控制相关。控制停顿可以通过各种软硬件
技术加以消除或减少，3.3节将研究这些技术。

\section{揭示 ILP 的基本编译器技术}
这一节研究一些简单的编译器技术，可以用来提高处理器开发 ILP的能力。这些技术对于
使用静态发射或静态调度的处理器非常重要。有了这一编译器技术，稍后将会研究那些采用静
态发射的处理器的设计与性能。附录H将研究一些更高级的编译器和相关硬件方案，其设计目
的就是使处理器能够开发更多的指令级并行。

\subsection{基本流水线调度和循环展开}
为使流水线保持满载，必须找出可以在流水线中重叠的不相关指令序列，充分开发指令并
行。为了避免流水线停顿，必须将相关指令与源指令的执行隔开一定的时间周期，这一间隔应
当等于源指令的流水线延迟。编译器执行这种调度的能力既依赖于程序中可用 ILP 的数目，也
依赖于流水线中功能单元的延迟。表3-2给出了在本章采用的FP单元延迟，如果偶尔采用不同
延迟，会另行明确说明。假定采用一个标准的5级整数流水线，所以分支的延迟为一个时钟周
期。假定这些功能单元被完全流水化或复制（复制次数与流水线深度相同），所以在每个时钟周
期可以发射任何一个类型的指令，不存在结构性冒险。

表3-2 本章使用的FP运算延迟
生成结果的指令
使用结果的指令
FP ALU 运算
另一个FP ALU运算
FP ALU 运算
存储双精度值
载入双精度值
FP ALU运算
载入双精度值
存储双精度值
延迟（以时钟周期为单位）
3
2
1
0

*最后一列是为了避免停顿而需要福入的时钟周期数。这些数字与我们在 FP单元上看到的平均延迟类似。由于可以旁
路载入指令的结果，不会使存储指令停顿，所以浮，点载入指令对載入指令的延迟为Q。我们还假定整数載入延迟为1，
整数ALU操作延迟为0。

在这一小节，我们将研究编译器如何通过转换循环来提高可用 ILP的数目。下面这个例子，
一方面用于说明一种非常重要的技巧，另一方面还用于推荐人们采用附录H中描述的一种功能
更强大的程序转换。我们的讨论将就以下代码段展开，它将对一个标量和一个向量求和：

\begin{verbatim}
    for(i=999; i>=0; i=i-1)
        x[i] = x[i] + 5;
\end{verbatim}

注意，这个循环的每个选代体都是相互独立的，从而可以看出这个循环是并行的。在附录H中
给出这一概念的正式定义，并说明如何在编译时判断循环迭代是独立的。首先来看这个循环的
性能，说明如何利用并行来提高一个 MIPS 流水线的性能（采用以上所示的延迟值）。

第一步是将以上代码段转换为 MIPS 汇编语言。在以下代码段中，R1最初是数组元素的最
高地址，F2包含标量值s。寄存器 R2 的值预先计算得出，使8（R2）成为最后一个进行运算的元
素的地址。

Loop：
这段简单的 MIPS代码应当类似如下所示（未针对流水线进行调度）：
\begin{verbatim}
    L.D
    ADD.D
    S.D
    DADDUI
    BNE
    FD,0（R1）
    F4,FO,F2
    F4,0（R1）
    RI,R1，#-8
    R1,R2,Loop
    ；FD=数组元素
    ；加上F2中的标量
    ；存储结果
    ；使指针逐减8个宇节
    ；（每个D）
    iR1！-R2 时跳转
    ：以巫和涮行时似个
    1/
\end{verbatim}
首先来看看在针对 MIPS 的简单流水线上调度这个循环时的执行情况（延迟如表3-2所示）。
例题

写出在进行调度与不进行调度的情况下，这个循环在MIPS上的执行过程，包
括所有停顿或空闲时钟周期。调度时要考虑浮点运算产生的延迟，但忽略延迟
分支。

解答

在不进行任何调度时，循环的执行过程如下，共花费9个周期：
发射的肘鈡周期
\begin{verbatim}
    Loop：
    L.D
    FO.0（RL）
    1
    停顿
    2
    ADD.D
    F4,FO,F2
    3
    停顿
    4
    停颊
    5
    S.D
    F4,0（R1）
    DADDUI
    RI,R1，#-8
    心
    停频
    BNE
    RI,RZ,Loop
\end{verbatim}
我们可以调度这个循环，使其只有2次停顿，将花费时间缩短至7个周期：
\begin{verbatim}
    Loop： L.D
    FD,O（R1）
    DADDUI
    R1,R1，#-8
    ADD.D
    F4,F0,F2
    停顿
    停顿
    S.D
    F4,8（R1）
    BNE
    R1,R2,Loop
\end{verbatim}
ADD.D之后的停顿是供S.D.使用的。
在上面这个例子中，每7个时钟周期完成一次循环选代，并存回一个数组元素，但对数组
元素进行的实际运算仅占用这7个时钟周期中的3个（载人、求和与存储）。其余4个时钟周期
包括循环开销（DADDUI 和BNE）和2次停顿。为了消除这4个时钟周期，需要使循环体中的运算
指令数多于开销指令数。

要提高运算指令相对于分支和开销指令的数目，一种简单的方案是循环展开。展开就是将
循环体复制多次，调整循环的终止代码。

循环展开还可用于提高调度效率。由于它消除了分支，因此可以将来自不同迭代的指令
放在一起调度。在这个例子中，我们通过在循环体内创建更多的独立指令来消除数据使用停
顿。如果在展开循环时只是简单地复制这些指令，最后使用的都是同一组寄存器，所以可能
会妨碍对循环的有效调度。因此，我们希望为每次迭代使用不同寄存器，这就需要增加寄存
器的数目。

例题
解答
展开以上循环，使其包含循环体的4个副本，假定R1-R2（即数组的大小）最初是
32 的倍数，也就是说循环迭代的数目是4的倍数。消除任何明显的冗余计算，不
要重复使用任何寄存器。

合并 DADDUI 指令，删除在展开期间重复的非必需 BNE 运算，得到的结果如下。注
意，现在必须对R2进行置位，使32（R2）成为后4个元素的起始地址。
\begin{verbatim}
    1159
    118
    Loop：
    L.D
    ADD,D
    S.D
    L.D
    A0D.D
    FO,O（R1）
    F4,FO,F2
    F4,0（R1）
    F6，-8（R1）
    F8.F6.F2
    F8，-8（RL）
    F10，-16（R1）
    F12,F10,F2
    F12，-16（R1）
    F14，-24（R1）
    ；刪除 DADDUI 和 BNE
    ；删除 DADDUI 和 BNE
    ADD.D
    cos
    ；删除 DADDUI 和BNE
    ADD.D
    S.D
    DADDUI
    BNE
    R1,RZ,Loop
\end{verbatim}
我们省掉了三次分支转移和对R1 的三次递减。并对载人和存储指令的地址进行了
补偿，以允许合并针对RI 的DADDUI 指令。这一优化看起来似乎微不足道，但实际
并非如此；它需要进行符号替换和化筒。符号替换和化简将重新整理表达式，以
合并其中的常量，比如表达式（（i+1）+1）可以重写为（i+（1+1）），然后化简为（i+2）。
这种优化方式消除了相关计算，在附录 H中将会看到它们的更一般形式。

如果没有调度，展开循环中的每个操作后面都会跟有一个相关操作，从而导致停
顿。这个循环将运行27个时钟周期（每个L0有1 次停顿，每个 ADDD 2、DADDUI 1，
加上14个指令发射周期），或者说在4个元素的每个元素上平均花费 6.75个时钟
周期，但通过调度可以显著提高其性能。循环展开通常是在编译过程的早期完成
的，所以优化器可以发现并消除冗余运算。

在实际程序中，人们通常不知道循环的上限。假定此上限为n，我们希望展开循环，制作
循环体的A个副本。我们生成的是一对连续循环，而不是单个展开后的循环。第一个循环执行
（nmod k）次，其主体就是原来的循环。第二个循环是由外层循环包围的展开循环，选代（n./k）次。
（在第4章将会看到，这一技巧类似于一种在向量处理器的编译器中使用的条带挖掘技巧。）当
n值较大时，大多数执行时间都花费在未展开的循环体上。

在前面的例子中，通过展开消除了开销指令，尽管这样会显著增大代码规模，但却可以提高
这一循环的性能。如果针对先前介绍的流水线来调度展开后的循环，它的执行情况又会如何呢？

例题

针对具有表3-2所示延迟的流水线，调度前面例子中展开后的循环，写出其执行
展开后循环的执行时间已经缩减到总共14个时钟周期，或者说每个元素需要 3.5
个时钟周期，而在未进行任何展开或调度之前为每个元素9个时钟周期，进行调度
但未展开时为7个周期。

解答
情况。
\begin{verbatim}
    Loop：
    L.D
    L.D
    L.D
    L.D
    ADD.D
    ADD.D
    S.D
    S.D
    DADDUI
    S.D
    s.D
    BNE
    FO,O（R1）
    F6，-8（R1）
    10，-16（R1
    14，-24（R1
    FA,FO,F2
    F8,F6,F2
    F12,F10,F2
    F16,F14,F2
    F4,0（R1）
    F8，-8（R1）
    R1,R1，#-32
    F12,16（R1）
    F16,8（R1）
    R1,R2,Loop
\end{verbatim}
对展开循环进行调度所获得的收益甚至还会大于对原循环进行调度的收益。之所以会这样，
是因为展开后的循环暴露了更多可以进行调度的计算，从而可以将停顿时间减至最低；上述代
码中就没有任何停顿。要以这种方式调度循环，必须意识到载人指令和存储指令是不相关的，
可以交換位置。
\subsection{循环展开与调度小结}
在本章和附录H中，我们将会研究各种可以利用指令级并行的硬件与软件技术，以充分发
挥处理器中各功能单元的潜力。大多数此类技术的关键在于判断何时能够改变指令顺序以及如
何改变。我们的例子中进行了许多此类改变，对于人类来说，可以很容易地判断出是可以进行
此类改变的。而在实践中，这一过程必须采用系统方式，由编译器或硬件来完成。为了获得最
终展开后的代码，必须进行如下决策和变换。

\begin{itemize}
    \item 确认循环迭代不相关（循环维护代码除外），判定展开循环是有用的。
    \item 使用不同寄存器，以避免由于不同运算使用相同寄存器而施加的非必要约束（比如，名
    称相关）。
    \item 去除多余的测试和分支指令，并调整循环终止与迭代代码。
    \item 观察不同迭代中的载人与存储指令互不相关，判定展开后的循环中的载人和存储指令可
    以交换位置。这一变换需要分析存储器地址，查明它们没有引用同一地址。
    \item 对代码进行调度，保留任何必要相关，以得到与原代码相同的结果。
\end{itemize}

要进行所有这些变换，最关键的要求就是要理解指令之间的相关依赖关系，而且要知道在
这些给定关系下如何改变指令或调整指令的顺序。

有3种不同的效果会限制循环展开带来的好处：（1）每次展开操作分摊的开销数目降低，（2）
代码规模限制，（3）编译器限制。我们首先考虑循环开销问题。如果将循环展开4次，所生成的
指令并行足以使循环调度消除所有停顿周期。事实上，在14个时钟周期中，只有2个周期是循
环开销：维护索引值的 DADDUI 和终止循环的BNE。如果将循环展开8次，这一开销将从每次原
迭代的1/2周期降低到1/4。

对展开的第二个限制是所生成代码规模的增长。对于较大规模的循环，如果代码规模的增
长会导致指令缓存缺失率的上升，那就要特别加以关注。

还有一个因素通常要比代码大小更为重要，那就是由于大量进行展开和调试而造成寄存器
数量不足。因为在大段代码中进行指令调度而产生的这一副作用被称为寄存器紧缺。它的出现
是因为在为了提高 ILP 而调试代码时，导致存活值的数目增加。在大量进行指令调度之后，可
能无法将所有存活值都分配到寄存器中。尽管转换后的代码在理论上可以提高运行速度，但由
于它会造成寄存器短缺，所以可能会损失部分乃至全部收益。在没有展开循环时，分支就足以
限制调度的大量使用，所以寄存器紧缺几乎不会成为问题。但是，循环展开与大量调度的综合
应用却可能导致这一问题。在多发射处理器中需要公开更多可以重叠执行的独立指令序列，上
述问题可能变得尤其困难。一般来说，高级复杂转换的应用已经导致现代编译器的复杂度大幅
增加，而在生成具体代码之前，很难衡量这种应用带来的潜在改进。

直行代码段可以进行有效的调度，而循环展开是一种增大直行代码段规模的简单有效方法。
这种转换在各种处理器上都非常有用，从我们前面已经研究过的简单流水线，到多发射超标量，
再到本章后面要研究的VLIW。

\section{用高级分支预测降低分支成本}
由于需要通过分支冒险和停顿来实施控制相关，所以分支会伤害流水线性能。循环展开是
降低分支冒险的一种方法，我们还可以通过预测分支的行为方式来降低分支的性能损失。在附
录C中，我们将研究一些简单的分支预测器，它们既可能依赖于编译时信息，也可能依赖于在
隔离状态下观测到的分支动态行为。随着所用指令数目的增大，更准确的分支预测也变得越来
越重要。在本节，我们将研究一些提高动态预测准确度的技术。
相关分支预测

2 位预测器方案仅使用单个分支的最近行为来预测该分支的未来行为。如果我们同时还能查
看其他分支的最近行为，而不是仅查看要预测的分支，那就有可能提高预测准确度。考虑 egntott
基准测试中的一小段代码，这个基准测试是早期SPEC 基准测试套件的一个成员，用来显示特
别糟糕的分支预测行为：

\begin{verbatim}
    if (aa==2)
        aa=0;
    if (bb==2)
        bb=0;
    if (aa!=bb) {
\end{verbatim}

下面是通常为这一代码段生成的 MIPS代码，假定aa 和bb 分别被赋值給 RI 和 R2：
\begin{verbatim}
    DADDIU
    R3,R1，#-2
    BNEZ
    R3,L1
    DADD
    R1,RO,RO
    ；branch b1
    （aa！=2）
    ；aa=0
    L1：
    DADDIU
    R3,RZ，#-2
    BNEZ
    R3,L2
    ；branch b2
    （bb！=2）
    DADD
    R2,RO,RO
    ；bb=0
    L2：
    DSUBU
    R3,R1,R2
    ；R3=aa-bb
    BEQZ
    R3, L3
    ；branch b3
    （aa==bb）
\end{verbatim}
我们将这些分支标记为bl、b2和b3。从中可以看出很重要的一点：分支b3的行为与分支b1 和
b2 的行为有关。显然，如果分支b1 和b2 都未执行转移（即其条件均为真，且aa 和bb 均被赋值
为0），aa和b明显相等，所以会进行b3分支转移。如果预测器仅利用一个分支的行为来预测
分支结果，那显然不会捕获到这一行为。

利用其他分支行为来进行预测的分支预测器称为相关预测或两级预测器。现有相关预测器增
加最近分支的行为信息，来决定如何预测一个给定分支。例如，（12）预测器在预测一个特定分支
时，利用最近一个分支的行为从一对2位分支预测器中进行选择。在一般情况下，（m.，n）预测器利
用最近 m个分支的行为从2“个分支预测器中进行选择，其中每个预测器都是单个分支的n位预测
器。这种相关分支预测器的吸引力在于它的预测率可以高于2位方案，而需要添加的硬件很少。

硬件的这种简易性源自一个简单的观察事实：最近 m个分支的全局历史可以记录在 m位移
位的寄存器中，其中每一位记录是否执行了该分支转移。将分支地址的低位与 m位全局历史串
联在一起，就可以对分支预测缓冲区进行寻址。例如，在一个共有64项的（2,2）缓冲区中，分支
的低4位地址（字地址）和2个全局位（表示最近执行的两个分支的行为）构成一个6位索引，
可用来对64个计数器进行寻址。

与标准的2位方案相比，相关分支预测器的性能可以提高多少呢？为了进行公平对比，进
行比较的预测器必须使用相同数目的状态位。一个（m,n）预测器的位数为：

2" xn×由分支地址选中的预测项数目

没有全局历史的2位预测器就是（0,2）预测器。

例题
在具有4K项的（0.2）分支预测器中有多少位？在具有同样位数的（2.2）预测器中有多
解答
少项？
具有4K项的预测器拥有：
2°x2×4K=8K位
在预测缓冲区中共有8K 位的（2,2）预测器中有多少由分支选中的项呢？我们知道：
22x2×由分支选中的预测项数=8K
因此，由分支选中的预测项数=1K。
图3-1对比了前面具有4K项的（0.2）预测器与具有1K 项的（2.2）预测器的错误预测率。可以
看出，这种相关预测器的性能不但优于具有相同状态位数的简单2位预测器，还经常会优于具
有无限项数的2位预测器。

图 3-1
2位预测器的对比。第一个是4096位的非相关预测器，然后是具有无限数目的非相关2位预测器，
和一个具有2位全局历史和总共1024项的2位预测器。尽管这些数据是从 SPBC的较早版本获取
的，但最近 SPEC基准测试的数据也显示了类似的准确度差异

\subsection{竞赛预测器：局部预测器与全局预测器的自适应联合}
采用相关分支预测器主是要因为观察到：仅使用局部信息的标准2 位预测器无法预测某
些重要分支，而通过增加全局信息就可以提升性能。竞赛预测器更进一步，采用了多个预测
器，通常是一个基于全局信息的预测器和一个基于局部信息的预测器，用选择器将它们结合
起来。竞赛预测器既可以以中等规模的预测位（8K~32K 位）实现更好的预测准确度，还可
以更有效地利用超大量预测位。现有竞赛预测器为每个分支使用一个 2位饱和预测器，根据
哪种预测器（局部、全局，甚至包括两者的组合方式）在最近的预测中最为有效，从两个不
同预测器中进行选择。在简单的2位预测器中，饱和计数器要在两次预测错误之后才会改变
优选预测器的身份。

竞赛预测器的优势在于它能够为特定分支选择正确的预测器，这一点对于整数基准测试尤
为重要。对于 SPEC整数基准测试，典型竞赛预测器为其选择全局预测器的概率大约为40\%，
而对于 SPECFP 基准测试，则少于15\%。除了在竞赛预测器方面走在前列的 Alpha处理器之外，
最近的 AMD处理器，包括 Opteron 和 Phenom，都已经采用了竞赛类型的预测器。

图3-2以 SPEC89为基准测试，研究三种不同预测器（一个局部2位预测器、一个相关预
测器和竞赛预测器）在不同位数时的性能。和我们前面曾经看到的一样，局部预测器的预测
性能改进不会超出一定的范围。相关预测器的改进非常突出，竞赛预测器的性能稍好一些。
对于 SPEC 的最新版本，其结果是类似的，但需要采用稍大一些的预测器规模才能达到渐趋
一致的行为。

总预测器规模
图3-2 在总位数升高时，3种不同预测运行 SPEC89的错误预测率。这些预测器包括：一个局部2位
预测器；一个相关预测器；针对图中每一点的全局和局部信息采用了结构优化；一个竞赛预测器。
尽管这些数据是从 SPEC 的较早版本获取的，但最近 SPEC 基准测试的数据也显示了类似行为，
当预测器规模稍大时，可能趋于一个渐近值

局部预测器包括一个两级预测器。顶级是一个局部历史表，包括1024个 10位项；每个10
位项对应这一项最近10个分支输出。即，如果这个分支被选中10次或更多次，那么这个局部
历史表中的相应项都是1。如果这个分支被交替选中和未选中，那么历史项中则包括交替的0
和1。这个10位历史信息最多可以发现和预测10个分支。局部历史表的选定项用来对一个拥
有1K项的表进行索引，这个表由3位饱和计数器组成，可以提供局部预测。这种组合共使用
29K 位，可以提高分支预测的准确度。

\subsection{Intel Core i7 分支预测}
关于 Core i7的分支预测器，Intel 只发布了非常有限的信息，这种预测器是以 Core Duo芯
片中使用的较早预测器为基础。i7使用了一个两级预测器，它的第一级预测器较小，设计用来
满足周期约束条件：每个时钟周期预测一个分支，还有一个较大的二级预测器作为备份。每个
预测器都组合了3个不同预测器：（1）简单的两位预测器，在附录C中介绍（上述竞赛预测器中
使用了这种预测器）：（2）全局历史预测器，类似于我们刚刚看到的预测器；（3）循环退出预测器。
对于一个被检测为循环分支的分支，循环退出预测器使用计数器来预测被选中分支的确切数目
（也就是循环迭代的数目）。对于每个分支，通过跟踪每种预测的准确度从 3个预测器中选择最
佳预测，就像一个竞赛预测器。除了这一多级主预测器之外，还有一个独立单元为间接分支预
测目标地址，还使用了栈来预测返回地址。

和在其他情景中一样，推测在评估预测器方面也导致了一些难题，这是因为对一个分支的
错误预测很容易导致提取和错误预测另一个分支。为了使事情变得简单一些，我们看一下错误
预测数占成功完成分支数（这些分支不是推测错误导致的结果）的百分比。图3-3显示了19个
SPECCPU2006 基准测试的数据。这些基准测试明显大于 SPEC89或SPEC2000，其结果是：即
使更精心地组合应用预测器，其错误预测率也只是稍大于图3-2中所示数据。由于分支预测错
误会导致推测效率低下，所以它会导致一些无效工作，在本章后面将会了解到这一点。

图 3-3
19 个 SPECCPU2006 基准测试错误预测数占成功完成分支数的比例，整数基准测试的平均值稍
高于 FP （4\%对3\%）。更重要的是，某些基准测试的错误率高出很多

\section{用动态调度克服数据冒险}
除非是流水线中的已有指令与要提取的指令之间存在数据相关，而且无法通过旁路或转发
来隐藏这一数据相关，否则，简单的静态调度流水线就会提取一条指令并发射出去。（转发逻辑
可以减少实际流水线延迟，所以某些特定的相关不会导致胃险。）如果存在不能隐藏的数据相关，
那些冒险检测软件会从使用该结果的指令开始，将流水线置于停顿状态。在清除这一相关之前，
不会提取和发射新的指令。

本节将研究动态调度，在这种调度方式中，硬件会重新安排指令的执行顺序以减少停顿，
并同时保持数据流和异常行为。动态调度有几个优点。第一，它允许针对一种流水线编译的
代码在不同流水线上高效执行，不需要在使用不同微体系结构时重新进行编译，并拥有多个
二进制文件。在当今的计算环境中，大多数软件都来自第三方，而且是以二进制文件形式分
发的，这一优势尤其明显。第二，在某些情况下，在编译代码时还不能知道相关性，利用动
态调度可以处理某些此类情况；比如，这些相关可能涉及存储器引用或者与数据有关的分支，
或者，它们可能源自使用动态链接或动态分发的现代编程环境。第三，也可能是最重要的一
个优点，它允许处理器容忍一些预料之外的延迟，比如缓存缺失，它可以在等待解决缺失问
题时执行其他代码。在3.6节，我们将研究以动态调度为基础的硬件推测，这一技术还有更多
性能方面的优势。我们将会看到，动态调度的好处是以硬件复杂度的显著提高为代价的。

尽管动态调度的处理器不能改变数据流，但它会在存在相关性时尽力避免停顿。相反，由
编译器调度的静态流水线（在3.2节介绍）也会尽力将停顿时间降至最低，具体方法是隔离相关
指令，使它们不会导致冒险。当然，对于那些本来准备在采用动态调度流水线的处理器上运行
的代码，也可以使用编译器流水线调度。

\subsection{动态调度：思想}

简单流水线技术的一个主要限制是它们使用循序指令发射与执行：指令按程序顺序发射，
如果一条指令停顿在流水线中，后续指令都不能继续进行。因此，如果流水线中两条相距很近
的指令存在相关性，就会导致冒险和停顿。如果存在多个功能单元，这些单元也可能处于空闲
状态。如果指令j依赖于长时间运行的指令i（当前正在流水线中执行），那么j之后的所有指令
都必须停顿，直到；完成、j可以执行为止。例如，考虑以下代码：

\begin{verbatim}
    DIV.D   FO,F2,F4
    ADD.D   F10,FO,F8
    SUB,D   F12,F8,F14
\end{verbatim}

由于 ADD.D对 DIV.D的相关性会导致流水线停顿，所以SUB.D指令不能执行；但是，SUB.D
与流水线中的任何指令都没有数据相关性。这一冒险会对性能造成限制，如果不需要以程序顺
序来执行指令，就可以消除这一限制。

在经典的五级流水线中，会在指令译码（ID）期间检查结构冒险和数据冒险：当一个指令
可以无冒险执行时，知道所有数据冒险都已经解决，从ID将其发射出去。

为了能够开始执行上面例子中的SUB.D，必须将发射过程分为两个部分：检查所有结构冒险
和等待数据冒险的消失。因此，我们仍然使用循序指令发射（即，按程序顺序发射指令），但我
们希望一条指令能够在其数据操作数可用时立即开始执行。这样一种流水线实际是乱序执行，
也就意味着乱序完成。

乱序执行就可能导致 WAR和WAW冒险，在这个五级整数流水线及其循序浮点流水线的逻
辑扩展中不存在这些冒险。考虑以下 MIPS 浮点代码序列：

\begin{verbatim}
    DIV.D   FO,F2,F4
    ADD.D   F6,F0,F8
    SUB.D   F8,F10,F14
    MUL.D   F6,F10,F8
\end{verbatim}

在 ADD.D和SUB.D之间存在反相关，如果流水线在 ADD.D之前执行 SUB.D（ADD.D 在等待 DIV.D），
将会违犯反相关，产生WAR冒险。与此类似，为了避免违犯输出相关，比如由 MUL.D写人F6，
就必须处理WAW冒险。后面将会看到，利用寄存器重命名可以避免这些冒险。

乱序完成还会使异常处理变得复杂。采用乱序完成的动态调度必须保持异常行为，使那些
在严格按照程序顺序执行程序时会发生的异常仍然会实际发生，也不会发生其他异常。动态调
度处理器会推迟发布相关异常的发布，一直等到处理器知道该指令就是接下来要完成的指令为
止，通过这一方式来保持异常行为。

尽管异常行为必须保持，但动态调度处理器可能生成一些非精确异常。如果在发生异常时，
处理器的状态与严格按照程序顺序执行指令时的状态不完全一致，那就说这一异常是非精确的。
非精确异常可以因为以下两种可能性而发生。

\begin{enumerate}
    \item 流水线在执行导致异常的指令时，可能已经完成了按照程序顺序排在这一指令之后的指令。
    \item 流水线在执行导致异常的指令时，可能还没有完成按照程序顺序排在这一指令之前的指令。
\end{enumerate}

非精确异常增大了在异常之后重新开始执行的难度。我们在这一节不会解决这些问题，而
是讨论一种解决方案，能够在具有推测功能的处理器环境中（见3.6节）提供精确异常。对于浮
点异常，已经采用了其他解决方案，见附录J中的讨论。

为了能够进行乱序执行，我们将五级简单流水线的ID 流水级大体分为以下两个阶段。
\begin{enumerate}
    \item 发射—译码指令，检查结构性冒险。
    \item 读操作数———直等到没有数据冒险，然后读取操作数。
\end{enumerate}

指令提取阶段位于发射阶段之前，既可以把指令放到指令寄存器中，也可能放到一个待完
成指令队列中：然后从寄存器或队列发射这些指令。执行阶段跟在读操作数阶段之后，这一点
和五级流水线中一样。执行过程可能需要多个周期，具体数目取决于所执行的操作。

我们区分一个指令开始执行和完成执行的时刻，在这两个时刻之间，指令处于执行过程中。
我们的流水线允许同时执行多条指令，没有这一功能，就会失去动态调度的主要优势。要同时
执行多条执行，需要有多个功能单元、流水化功能单元，或者同时需要这两者。由于这两种功
能（流水化功能单元和多个功能单元）在流水线控制方面大体相当，所以我们假定处理器拥有
多个功能单元。

在动态调度流水线中，所有指令都循序经历发射阶段（循序发射）；但是，它们可能在第二
阶段（读操作数阶段）停顿或者相互旁路，从而进行乱序执行状态。记分板技术允话有足够
资源和没有数据相关时乱序执行指令，它的名字源于 CDC6600记分板，CDC 6600记
板开发
了这一功能。这里重点介绍一种名为 Tomasulo算法的更高级技术。它们之间的主要区。
Tomasulo算法通过对寄存器进行有效动态重命名来处理反相关和输出相关。此外，还前以对
Tomasulo 算法进行扩展，用来处理推测，这种技术通过预测一个分支的输出、执行预测目标地
址的指令、当预测错误时采取纠正措施，从而降低控制相关的影响。使用记分板可能足以支持
诸如ARMA8之类的简单两发射超标量处理器，而诸如四发射 Intel i7之类更具主动性的处理器
则受益于乱序执行的使用。

\subsection{使用Tomasulo算法进行动态调度}
IBM360/91浮点单元使用一种支持乱序执行的高级方案。这一方案由Robert Tomasulo 发明，
它会跟踪指令的操作数何时可用，将RAW 冒险降至最低，并在硬件中引人寄存器重命名功能，
将WAW 和 WAR冒险降至最低。在现代处理器中存在这一方案的许多变体，但跟踪指令相关以
允许在操作数可用时立即执行指令、重命名寄存器以避免 WAR 和WAW 冒险，这些核心概念仍
然是它们的共同特征。

IBM 的目标是从指令集出发、从为整个350计算机系列设计的编译器出发来实现高浮点性
能，而不是通过采用专门为高端处理器设计的编译器来实现。360体系结构只有4个双精度浮
点寄存器，它限制了编译器调度的有效性；这一事实是开发 Tomasulo方法的另一个动机。此外，
IBM360/91 的内存访问时间和浮点延迟都很长，Tomasulo算法就是设计用来克服这些问题的。
在本节的最后，我们将会看到 Tomasulo算法还支持重叠执行一个循环的多个迭代。

我们将在 MIPS指令集上下文中解释这一算法，重点放在浮点单元和载人-存储单元。MIIPS
与360之间的主要区别是后者的体系结构中存在寄存器-存储器指令。由于 Tomasulo算法使用
一个载入功能单元，所以添加寄存器-存储器寻址模式并不需要进行大量修改。IBM 360/91还
有一点不同，它拥有的是流水化功能单元，而不是多个功能单元，但我们在描述该算法时仍然
假定它有多个功能单元。它只是对功能单元进行流水化的概念扩展。

我们将会看到，如果仅在操作数可用时才执行指令，就可以避免 RAW 冒险，而这正是一
些简单记分板方法提供的功能。WAR 和WAW冒险（源于名称相关）可以通过寄存器重命名来
消除。对所有目标寄存器（包括较早指令正在进行读取或写人的寄存器）进行重命名，使乱序
写人不会影响到任何依赖某一操作数较早值的指令，从而消除 WAR 和 WAW 冒险。

为了更好地理解寄存器重命名如何消除 WAR 和 WAW 冒险，考虑以下可能出现 WAR和
WAW胃险的代码序列示例：

\begin{verbatim}
    DIV.D   FO, F2,F4
    ADD.D   F6, FO,F8
    S.D     F6,0（R1）
    SUB.D   F8,F10,F14
    MUL.D   F6,F10, F8
\end{verbatim}

以上代码共有两处反相关：ADD.D与SUB.D之间，S.D和MUL.D之间。在ADD.D和MUL.D之间还有
一处输出相关，从而一共可能存在3处冒险：ADD.D使用F8和SUB.D使用F6时的WAR冒险，以
及因为ADD.D可能在MUL.D之后完成所造成的WAW 冒险。还有3个真正的数据相关：DIV.D和
ADD.D之间、SUB.D和MUL.D之间、ADD.D和S.D之间。

这3个名称相关都可以通过寄存器重命名来消除。为简便起见，假定存在两个临时寄存器：
S和T。利用S和T，可以对这一序列进行改写，使其没有任何相关，如下所示：

\begin{verbatim}
    DIV.D   FO, F2,F4
    AD0.D   S,FO,F8
    S.D     S,O(R1)
    SUB.D   T,F10,F14
    MUL.D   F6,F10,T
\end{verbatim}

此外，对F8的任何后续使用都必须用寄存器T来代替。在这个代码段中，可以由编译器静态完
成这一重命名过程。要在后续代码中找出所有使用F8 的地方，需要采用高级编译器分析或硬件
支持，这是因为上述代码段与后面使用F8的位置之间可能存在插人分支。我们将会看到，
Tomasulo算法可以处理跨越分支的重命名问题。

在Tomasulo 方案中，寄存器重命名功能由保留站提供，保留站会为等待发射的指令缓冲
操作数。其基本思想是：保留站在一个操作数可用时马上提取并缓冲它，这样就不再需要从
寄存器中获取该操作数。此外，等待执行的指令会指定保留站，为自已提供输人。最后，在
对寄存器连续进行写人操作并且重叠执行时，只会实际使用最后一个操作更新寄存器。在发
射指令时，会将待用操作数的寄存器说明符更名，改为保留站的名字，这就实现了寄存器重
命名功能。

由于保留站的数目可能多于实际寄存器，所以这一技术甚至可以消除因为名称相关而导致
的冒险，这类冒险是编译器所无法消除的。在研究 Tomasulo 方案的各个部分时，我们将再次讨
论寄存器重命名这一主题，了解重命名究竟如何实现以及它如何消除 WAR和WAW冒险。

使用保留站，而不使用集中式寄存器堆，可以导致另外两个重要特性。第一，冒险检测和
执行控制是分布式的：每个功能单元保留站中保存的信息决定了一条指令什么时候可以开始在
该单元中执行。第二，结果将直接从缓冲它们的保留站中传递给功能单元，而不需要经过寄存
器。这一旁路是使用公共结果总线完成的，它允许同时载入所有等待一个操作数的单元（在
360/91 中，这种总线被称为公共数据总线，或CDB）。在具有多个执行单元并且每个时钟周期
发射多条指令的流水线中，将需要不止一条总线。

图3-4给出了基于Tomasulo算法的处理器的基本结构，其中包括浮点单元和载人/存储单元；
所有执行控制表均未显示。每个保留站保存一条已经被发射、正在功能单元等待执行的指令，
如果已经计算出这一指令的操作数值，则保留这些操作数值，如果还没有计算出，则保留提供
这些操作数值的保留站名称。

载人缓冲区和存储缓冲区保存来自和进入存储器的数据或地址，其行为方式基本与保留站
相同，所以我们仅在必要时才区分它们。浮点寄存器通过一对总线连接到功能单元，由一根总
线连接到存储缓冲区。来自功能单元和来自存储器的所有结果都通过公共数据总线发送，它会
通向除载人缓冲区之外的所有地方。所有保留站都有标记字段，供流水线控制使用。

在详细描述保留站和此算法之前，让我们看看一条指令所经历的步骤。尽管每条指令现在
可能需要任意数目的时钟周期，但一共只有以下3个步骤。

(1) 发射—从指令队列的头部获取下一条指令，指令队列按 FIFO顺序维护，以确保能够
保持数据流的正确性。如果有一个匹配保留站为空，则将这条指令发送到这个站中，如果操作
数值当前已经存在于寄存器，也一并发送到站中。如果没有空保留站，则存在结构性冒险，该
指令会停顿，直到有保留站或缓冲区被释放为止。如果操作数不在寄存器中，则一直跟踪将生
成这些操作数的功能单元。这一步骤将对寄存器进行重命名，消除 WAR和WAW 冒险。（在动
态调度处理器中，这一阶段有时被称为分派。）

(2) 执行—如果还有一个或多个操作数不可用，则在等待计算的同时监视公共数据总线。
当一个操作数变为可用时，就将它放到任何一个正在等待它的保留站中。当所有操作数都可用
时，则可以在相应功能单元中执行运算。通过延迟指令执行，直到操作数可用为止，可以避免
RAW冒险。（一些动态调度处理器将这一步骤称次“发射”，但我们使用“执行”一词，在第一
个动态调度处理器 CDC 6600中使用的就是这个名字。）

使用 Tomasulo 算法的 MIPS 浮点单元的基本结构。指令由指令单元发送给指令队列，再按
先入先出（FIFO）顺序从指令队列中发射出去。保留站包括运算和实际操作数，还有用于检
测和解决冒险的信息。载人缓冲区有3项功能：（1）保存有效地址的各个部分，直到计算完成；
（2）跟踪正在等待存储器的未完成载入过程；（3）保存正在等待CDB的已完成载入过的结果。
与此类似，存储器缓冲区也有3项功能：（1）保存有效地址的各个部分，直到计算完成；（2）对
于尚未完成、正在等待待存储数据值的存储过程，存储其目标存储器地址；（3）保存要存储的地
址和数据值，直到存储器单元可用为止。来自FP单元或载人单元的所有结果都被放在CDB中，
它会通向 FP寄存器堆以及保留站和存储器缓冲区。FP加法器实现加法和减法，FP乘法器完成
乘法和除法

注意，在同一时钟周期，同一功能单元可能会有几条指令同时变为就绪状态。尽管独立功
能单元可以在同一时钟周期执行不同指令，如果单个功能单元有多条指令准备就绪，那这个单
元就必须从这些指令中进行选择。对于浮点保留站，可以任意作出这一选择；但是载入和存储
指令可能要更复杂一些。

载人和存储指令的执行过程需要两个步骤。第一步是在基址寄存器可用时计算有效地址，然
后将有效地址放在载人缓冲区或存储缓冲区中。载入缓冲区中的载人指令在存储器单元可用时立
即执行。存储缓冲区中的存储指令等待要存储的值，然后将其发送给存储器单元。通过有效地址
的計算，载人和存储指令保持程序顺序，稍后将会看到，这样有助于通过存储器来避免胃险。

为了保持异常行为，对于任何一条指令，必须要等到根据程序顺序排在这系指令之前的所
有分支全部完成之后，才能执行该指令。这一限制保证了在执行期间导致异常的指令实际上已
经执行。在使用分支预测的处理器中（就和所有动态调度处理器一样），这意味着处理器在允许
分支之后的指令开始执行之前，必须知道分支预测是正确的。如果处理器记录了异常的发生，
但没有实际触发，则可以开始执行一条措令，在进入写结果阶段之前没有停顿。

后面可以看到，推测提供了一种更灵活、更完整的异常处理方法，所以我会将推后进行这
一改进，并说明推测是如何解决这一问题的。

(3) 写结果—在计算出结果之后，将其写到 CDB上，再从CDB传送给寄存器和任意等待
这一结果的保留站（包括存储缓冲区）。存储指令一直缓存在存储缓冲区中，直到待存储值和存
储地址可用为止，然后在有空闲存储器单元时，立即写入结果。

保留站、寄存器堆和载人/存储缓冲区都采用了可以检测和消除冒险的数据结构，根据对
象的不同，这些数据结构中的信息也稍有不同。这些标签实际上就是用于重命名的虚拟寄存
器扩展集的名字。在这里的例子中，标签字段包含4个数位，用来表示5个保留站之一或5
个载人缓冲区之一。后面将会看到，这相当于设定了10个可以指定为结果寄存器的寄存器（而
360体系结构中包含4个双精度寄存器）。在拥有更多真正寄存器的处理器中，我们可能希望
重命名能够提供更多的虚拟寄存器。标签字段指出哪个保留站中包含的指令将会生成作为源
操作数的结果。

在指令被发射出去并开始等待源操作数之后，将使用一个保留站编号来引用该操作数，这
个保留站中保存着将对寄存器进行写操作的指令。如果使用一个未用作保留站编号的值来引用
该操作数（比如0），则表明该操作数已经在寄存器中准备就绪。由于保留站的数目多于实际寄
存器数目，所以使用保留站编号对结果进行重命名，就可以避免 WAW和 WAR冒险。在 Tomasulo
方案中，保留站被用作扩展虚拟寄存器，而其他方法可能使用拥有更多寄存器的寄存器集，也
可能使用诸如重排序缓冲区这样的结构，在3.6 节将会进行讨论。

在Tomasulo 方案以及后面将会介绍的支持推测的方法中，结果都是在受保留站监视的总线
（CDB）上广播。采用公用结果总线，再由保留站从总线中提取结果，共同实现了静态调度流水
线中使用的转发和旁路机制。但在这一做法中，动态调度方案会在源与结果之间引人一个时钟
周期的延迟，这是因为要等到“写结果”阶段才能让结果与其应用匹配起来。因此，在动态调
度流水线中，在生成结果的指令与使用结果的指令之间至少要比生成该结果的功能单元的延迟
长一个时钟周期。

一定别忘了，Tomasulo 方案中的标签引用的是将会生成结果的缓冲区或单元；当一条指令
发射到保留站之后，寄存器名称将会丢弃。（这是 Tomasulo 方案与记分板之间的一个关键区别：
在记分板中，操作数保存在寄存器中，只有生成结果的指令已经完成、使用结果的指令做好执
行准备之后才会读取操作数。）

每个保留站有以下7个字段。

\begin{itemize}
    \item Op——对源操作数S1 和S2执行的运算。
    \item Qi、Qk—将生成相应源操作数的保留站；当取值为0时，表明已经可以在Vj或Vk 中
    获得源操作数，或者不需要源操作数。
    \item Vj、Vk—源操作数的值。注意，对于每个操作数，V字段和Q字段中只有一个是有效
    的。对于载入指令，Vk字段用于保存偏移量字段。
    \item A——用于保存为载人或存储指令计算存储器地址的信息。在开始时，指令的立即数字
    段存储在这里；在计算地址之后，有效地址存储在这里。
    \item Busy—指明这个保留站及其相关功能单元正被占用。
\end{itemize}
寄存器堆有一个字段 Qi。
口Qi—
一个运算的结果应当存储在这个寄存器中，则Qi是包含此运算的保留站的编号。
如果 Qi 的值为空（或0），则当前没有活动指令正在计算以此寄存器为目的地的结果，
也就是说这个值就是寄存器的内容。

载人缓冲区和存储缓冲区各有一个字段A，一旦完成了第一个执行步骤，这个字段中就包含了
有效地址的结果。

在下一节，我们将首先看一些示例，说明这些机制是如何工作的，然后再详细研究具体算法。

\section{动态调度：示例和算法}
在详细研究 Tomasulo算法之前，让我们看几个示例，这些示例有助于说明这种算法的工作
方式。
例题
解答
对于以下代码序列，写出在仅完成了第一条载入指令并已将其结果写到CDB总线
时的信息表：

1.
2.
3.
4.
5.
L.D
F6,32 （RZ）
L.D
F2,44（R3）
MUL.D
FO,F2,F4
SUB.D
F8,F2,F6
DIV.D
F10,F0, F6
ADD.D
F6,F8,F2

表3-3用3个表显示了其结果。Add、Mult和 Load 之后附加的数字表示保留站的
标签
—Addl 是第一加法单元计算结果的标签。此外，我们还给出了一个指令状
态表。之所以列出这个表是为了帮助读者理解这一算法；它不是硬件的实际组成
部分，而是由保留站来保存每个已发射运算的状态。
表3-3

当所有指令都已经被发射，但只有第一条载入指令已经完成而且已将其结果写到
CDB 时的保留站与寄存骼标签。
指令状态
发射执行
指令
L.O
F6.32（R2）
L.D
F2,44（R3）
MUL.D
F0.F2.F4
SUB.D
F8,F2,F6
DIV.D F10,FO,F6
ADD.D F6,FB,F2
写结果
~
<
<
<
（续）
保留站
Qk
名称
Load1
Load2
Addl
Add2
Add3
Multl
Mult2
繁忙 Op
Vj
否
是
是
是
否
Vk
Qj
A
Load
SUB
ADD
44+Regs［R3］
Mem［32+ RegsCR2］］ Load2
Add1
Load2
是
MUL
DIV
Regs［F4］
Load2
Mem［32+ Regs［R2］］ Mult】
寄存器状态
宇段
FO
F2 F4 F6
F8
 F10
F12
F30
Qi
Multl
Load2
Add2 Addl
Mult2

*第二系載入指令已经完成有效地址的计算，但还在等待存储器单元。我们用数组 Regs［］引用寄存器
堆，用教组 MmL］引用存储器。记住，在任何时刻，操作数由Q字段或 V 字段指定。注意，ADD.D指
今已经发射（它在 WB阶段有一个WAR 冒险），可能在DIV.D开始之前完成。

与先前的较简单方案相比，Tomasulo方案有两点优势：（1）冒险检测逻辑的分布；（2）消除丁
可能产生 WAW 和 WAR冒险的停顿。

第一个优势源于分布式保留站和CDB的使用。如果多条指令正在等待同一个结果，而每条
指令的其他操作数均已准备就绪，那么在CDB上广播这一结果就可以同时释放这些指令。如果
使用集中式的寄存器堆，这些单元必须在寄存器总线可用时从寄存器中读取自己的结果。
第二个优势（消除 WAW 和 WAR冒险）的实现是利用保留站来重命名寄存器，并在操作数
可用时立即将其存储在保留站中。

例如，尽管存在涉及F6的 WAR 冒险，但表3-3中的代码序列发射了 DIV.D和 ADD.D。这一
冒险通过两种方法之一消除。第一种方法：如果为DIV.D 提供操作数的指令已经完成，则Vk中
会存储这个结果，使DIV.D 不需要 ADD.D 就能执行（表中所示的就是这种情况）。另一方面，如
果L.D还没有完成，则Qk将指向Load1 保留站，DIV.D指令不再依赖于 ADD.D。因此，在任一情
况下，ADD.D 都可以发射并开始执行。在用到 DIV.D 的结果时，都会指向保留站，使 ADD.D 能够
完成，并将其值存储在寄存器中，不会影响到 DIV.D。

稍后将会看到一个消除WAW冒险的例子。但先来看看前面的示例是如何继续执行的。在
这个例子以及本章后面的例子中，假定有如下延迟值：载入指令为1个时钟周期，相加指令为
2个时钟周期，乘法指令为6个时钟周期，除法指令为12个时钟周期。

例题
解答
对于上例中的同一代码段，给出当 MUL.D做好写出结果准备时的状态表。
其结果如表3-4中的3个表格所示。注意，在复制 DIV.D的操作数时 ADD.D已经完
成，所以克服了 WAR冒险问题。注意，既然F6的载人操作被延迟，在执行对 F6
的加法操作时也不会触发 WAW冒险。

表3-4只有乘法与除法指令还没有完成
指令
L.D
F6.32（R2）
L.D
F2.44（R3）
MUL.D FO.F2,F4
SUB.D F8,F2.F6
DIV.D F10.FO.F6
ADD.D F6,F8,F2
发
射
指令状态
执
行
写结果
<
名
称
繁忙
Op
Loadl
否
Load2
否
Addl
否
Add2
否
Add3
否
Multl
是
Multz
是
DIV
vj
保留站
Vk
Qj
Qk
A
MUL Mem［44 + Regs［R3］］
Regs［F4］
Mem［32 + Regs［R2］］ Muti
字
Qi
段
FO
Multl
F2
F4
F6
寄存器状态
F8
F10
F12
Mul2
…
F30
178
\subsection{Tomasulo 算法：细节}
表3-5给出了每条指令都必须经历的检查和步骤。前面曾经提到，载人指令和存储指令在
进入独立载人或存储缓冲区之前，要经过一个进行有效地址计算的功能单元。载人指令会进入
第二执行步骤，以访问存储器，然后进入“写结果” 阶段，将来自存储器的值写入寄存器堆以
及（或者）任何正在等待的保留站。存储指令在写结果阶段完成其执行，将结果写到存储器中。
注意，无论目标是寄存器还是存储器，所有写人操作都在“写结果”阶段发生。这一限制简化
了 Tomasulo算法，是其扩展到支持推测功能的关键（在3.6节将讨论这一扩展）。

\begin{verbatim}
    指令状态
    表3-5 算法步骤以及每个步骤需要的内容
    等待条件
    发射
    FP操作
    站倥空
    载人或存储
    缓仲区r空
    仅载人
    仅存储
    操作或记录工作
    if（RegisterStat［rsJ.0110）
    ｛RSLrJ.9
    个 Registerstat［rs］.Qi｝
    else ｛Rs［r］.vj个
    Regslrs」；RSLrJ.Qj个ol：
    if （Registerstat［rt］.Qi|o）
    ｛RS［r.Qk f RegisterStatirt」.9i
    else ｛RS［r］.Vk 个 Regs ［rt］；
    RSEr］.gk - 0｝；
    RS［rj.Busy f yes: Registerstat［rd］.0 个r；
    if RegisterStat_rs..Q110
    ｛RS［r］.Qj - Registerstat［rs］.Qi！
    Ise ｛RS［rJ.Vj f Regs［rs」； RSLrJ.0j 个 0｝
    S「ri.A f imm: RS［ri.Busy f yes
    Registerstat［rt］.q1 个r；
    if （Registerstat［rt］.0il0）
    ｛RS［rJ.Qk 个 Registerstat lrsJ.Q1！
    else ARS［r］.vk f Regs［rt］； RS［r］.Qk 个 o｝；
    计算结果：操作数在Vj和Vk中
    执行
    FP操作
    载入/存储步骤1
    载入步骤2
    写结果
    FP操作或载人
    （RS［r］.QJ - 0） 和《RS［r］.Ok-D）
    RS［r］.Qj -0或r是载入-存储序列的
    头栽人步骤1完成
    r处的执行完成且CDB可用
    RS［r］.A f RS［r］.Vj + RS［r］.A；
    从Mem［RS［r］.A］读取
    vx（if（Registerstat［x］.Qi=r）｛Regs［x］ f- result；
    Registerstat ［x］.Qi
    个
    0｝）；
    vx（if（RS［x］.Qj=r）［RS［x］.Vj f- resultsRs［x］.Qj 个
    P'fesix］. Ok=r） （RSIX］.WK T result:RS［X）.OK T
    O））：
    RS［r］.Busy 个 no：
    Mem［RS［r］.A］ f Rs［r］.vk；
    存储
    r处的执行完成且r&RS［rJQK -0
    RS［r］.Busy f no；
\end{verbatim}
*财于发射指令，rd是目的地、rS 和rt 是源寄存器編号、irm 是符号扩展立即数字段，『是为指令指定的保留站或缓
冲区。RS 是保留站数据结构。FP单元或载入单元返回的值称为 result。RegisterStat 是寄存器状态数据结构（不是
寄存器堆，寄存器堆应当是 Regs［］）。当发射指令，目标寄存器的Qi字段被设置沟向其发射该指令的缓冲区或保留
站编号。如果操作教已经存在于寄存器中，就将它们存储在V 字段中。否则，设置Q字段，指出将生成源操作数值
的保留站。指令将一直在保留站中等待，直到它的两个操作教都可用为止，当Q字段中的取值內0时即表示这一状
态。当指令已被发射，或者当这一指令所依赖的指令已经完成并写回结果时，这些Q字段被设置为 0。当一条指令
执行完毕，并且 CDB 可用时，它就可以进行写回操作。任何一个缓冲区、寄存器和保留站，只要其Qi或Qk值与完
成该指令的保留站相同，都会由 CDB 更新其取值，并标记Q字段，表明已经接收到这些值。因此，CDB可以在一
个时钟周期中向许多目标广播其结果，如果正在等待这一结果的指令已经有了其他操作数，那就都可以在下一个时
钟周期开始执行了。载入指令要经历两个执行步骤，存储指令在写结果阶段稍有不同，它们必须在这一阶段等待要
存储的值。记住，为了保持异常行为，如果按照排在程序顺序前面的分支还没有究成，就不应允许执行后面的指令。
由于在发射阶段之后不再保持任何有关程序顺序的概念，因此，了实施这一限制，在流水线中还有未完成的分支
时，通常不允许任何指令离开发射步骤。在3.6节中，我们将看到推测支持是如何消除这一限制的。
\subsection{Tomasulo算法：基于循环的示例}
为了理解通过寄存器的动态重命名来消除WAW 和 WAR 胃险的强大威力，我们需要看一个
循环。考虑下面的简单序列，将一个数组的元素乘以 F2中的标量：

Loop：
L.D
FO,0（R1）
MUL.D
F4,F0,F2
S.D
F4,0（R1）
DADDIU
R1,R1，-8
BNE
R1,R2, Loop;branches if R1|R2

如果我们预测会执行这些分支转移，那使用保留站可以同时执行这个循环的多条指令。不
需要修改代码就能实现这一好处——实际上，这个循环是由硬件使用保留站动态展开的，这些
保留站经过重命名获得，充当附加寄存器。

假定已经发射了该循环两个连续迭代中的所有指令，但一个浮点载人/存储指令或运算也没
有完成。表3-6显示了在此时刻的保留站、寄存器状态表和载人缓冲区与存储缓冲区。（整数
ALU运算被忽略，假定预测选中该分支。）一旦系统达到这一状态，如果乘法运算可以在4个
时钟周期内完成，则流水线中可以保持该循环的两个副本，CPI接近1.0。在达到稳定状态之前，
还需要处理其他一些迭代，延迟为6个时钟周期。这需要有更多的保留站来保存正在运行的指
令。在本章后面将会看到，在采用多指令发射对Tomasulo方法进行扩展时，它可以保持每个时
钟周期处理一条以上指令的速度。

表3-6 还没有指令完成时，循环的两个活动迭代
指令状态
指令
来自迭代
发射
执行
写結果
L.D
FO,O（R1）
1
<
MUL.D
F4,FO,F2
1
~
S.D
F4,0（RL）
1
L.D
FO.O（R1）
2
~
MUL.D
F4.F0.F2
2
S.D
F4.0（R1）
2
保留站
名称
繁
忙
Op
Vi
Vk
Loadl
Loed2
Addl
Add2
Add3
Mult1
Mult2
Storel
Store2
是
是
否
否
否
是
是
是
是
Load
Load
MIUL
MUL.
Store
Store
Regs［F2］
Regs［F2］
Qk
Regs［R1］-8
Loadl
Load2
［181
Regs［R1］
RegsTR1］-8
Mult1
Mult2
寄存髒状态
F8
字段
Qi
FO
Load2
F2
F4
Mult2
F6
F10
F12
……
F30
* 乘法器保留站中的项目指出尚未完成的栽入指令是操作数来源。存储保留站指出乘法运算的目标位置是待存储值的
来源。
只要载人指令和存储指令访问的是不同地址，就可以放心地乱序执行它们。如果载人指令
和存储指令访问相同地址，则会出现以下两种情况之一：
\begin{itemize}
    \item 根据程序顺序，载入指令位于存储指令之前，交换它们会导致WAR冒险；
    \item 根据程序顺序，存储指令位于载入指令之前，交换它们会导致RAW 冒险。
\end{itemize}
依此类似，交换两个访问同一地址的存储指令会导致WAW冒险。
因此，为了判断在给定时刻是否可以执行一条载人指令，处理器可以检查：根据程序顺序
排在该载人指令之前的任何未完成存储指令是否与该载入指令共享相同数据存储器地址。对于
存储指令也是如此，如果按照程序顺序排在它前面的载入指令或存储指令与它访问的存储器地
址相同，那它必须等到所有这些指令都执行完毕之后才能开始执行。在3.9节将考虑一种去除
这一限制的方法。

为了检测此类冒险，处理器必须计算出与任何先前存储器运算有关的数据存储器地址。为
了保证处理器拥有所有此类地址，一种简单但不一定最优的方法是按照程序顺序来执行有效地
址计算。（实际只需要保持存储及其他存储器引用之间的相对顺序，也就是说，可以随意调整载
人指令的顺序。）

首先来考虑载入指令的情况。如果按程序顺序执行有效地址计算，那么当一条载人指令完
成有效地址计算时，就可以通过查看所有活动存储缓冲区的A字段来确定是否存在地址冲察。
如果载入地址与存储缓冲区中任何活动项目的地址匹配，则在发生冲突的存储指令完成之前，
不要将载人指令发送到载入缓冲区。（有些实施方式将要存储的值直接传送给载入指令，减少了
因为这一RAW冒险造成的延迟。）

存储指令的工作方式类似，只是因为发生冲突的存储指令不能调整相对于载人或存储指令
的顺序，所以处理器必须在载人与存储两个缓冲区中检查是否存在冲突。

如果能够准确顶测分支（这是在上一节解决的问题），动态调度流水线可以提供非常高的性
能。这种方法的主要缺点在于 Tomasulo方案的复杂性，它需要大量硬件。具体来说，每个保留
站都必须包含一个必须高速运转的相关缓冲区，还有复杂的控制逻辑。它的性能还可能受到单
个 CDB的限制。尽管可以增加更多 CDB，但每个CDB都必须与每个保留站进行交互，必须在
每个保留站为每个 CDB配备相关标签匹配硬件。

在Tomasulo 方案中，可以组合使用两种不同技术：对体系结构寄存器重命名，提供更大的
寄存器集合；缓冲来自寄存器堆的源操作数。源操作数缓冲消除了当操作数在寄存器中可用时
出现的 WAR 冒险。后面将会看到，通过对寄存器重命名，再结合对结果的缓存，直到对寄存
器早期数据的引用全部结束，这样也有可能消除 WAR 冒险。在我们讨论硬件推测时将会用到
这一方法。

在360/91之后的许多年，Tomasulo方案一直没有得到应用，但从20 世纪90年代开始在多
发射处理器中采用，原因有如下几个。

（1）尽管 Tomasulo算法是在缓存出现之前设计的，但缓存的出现以及其固有的不可预测的
延迟，已经成为使用动态调度的主要动力之一。乱序执行可以让处理器在等待解决缓存缺失的
同时继续执行指令，从而消除了全部或部分缓存缺失代价。

（2） 随着处理器的发射功能变得越来越强大，设计人员越来越关注难以调度的代码（比
如，大多数非数值代码）的性能，所以诸如寄存器重命名、动态调度和推测等技术变得越来越
重要。

（3） 无需编译器针对特定流水线结构来编译代码，Tomasulo 算法就能实现高性能，在盒装
光盘套装、批量销售软件的时代，这是一个非常富有价值的性质。

\section{基于硬件的推测}
当我们尝试开发更多指令级并行时，控制相关的维护就会成为一项不断加重的负担。分支
预测减少了由于分支导致的直接停顿，但对于每个时钟周期要执行多条指令的处理器来说，仅
靠正确地预测分支可能不足以生成期望数量的指令级并行。宽发射处理器可能需要每个时钟周
期执行一个分支才能维持最高性能。因此，要开发更多并行，需要我们克服控制相关的局限性。

通过预测分支的输出，然后在假定猜测正确的前提下执行程序，可以克服控制相关问题。
这种机制对采用动态调度的分支预测进行了一种虽细微但很重要的扩展。具体来说，通过推测，
我们提取、发射和执行指令，就好像分支预测总是正确的；而动态调度只是提取和发射这些指
令。当然，我们需要一些机制来处理推测错误的情景。附录H讨论了各种由编译器支持推测的
机制。这一节研究硬件推測，它延伸了动态调度的思想。

基于硬件的推测结合了3种关键思想：（1）用动态分支预测选择要执行哪些指令；（2）利用推
测，可以在解决控制相关问题之前执行指令（能够撤消错误推测序列的影响）；（3）进行动态调
度，以应对基本模块不同组合方式的调度。（与之相对，没有推测的动态调度需要先解析分支才
能实际执行后期基本模块的操作，因为只能部分重叠基本模块。）

基于硬件的推测根据预测的数据值流来选择何时执行指令。这种执行程序的方法实际上是
一种数据流执行：操作数一旦可用就立即执行运算。

为了扩展Tomasulo 算法，使其支持推测，我们必须将指令结果的旁路（以推测方式执行指
令时需要这一操作）从一条指令的实际完成操作中分离出来。进行这种分离之后，就可以允许
执行一条指令，并将其结果旁路给其他指令，但不允许这条指令执行任何不能撤消的更新操作，
直到确认这条指令不再具有不确定性为止。

使用旁路值类似于执行一次推测寄存器读取操作，因为在提供源寄存器值的指令不再具有
不确定性之前，我们无法知道它是否提供了正确值。当一个指令不再具有不确定性时，允许它
更新寄存器堆或存储器；我们将指令执行序列中的这个附加步骤称为指令提交。

实现推测之后的关键思想在于允许指令乱序执行，但强制它们循序提交，以防止在指令提
交之前采取任何不可挽回的动作（比如更新状态或激发异常）。因此，当我们添加推测时，需要
将完成执行的过程与指令提交区分开来，这是因为指令执行完毕的时间可能远远早于它们做好
提交准备的时间。在指令执行序列中添加这一提交阶段需要增加一组硬件缓冲区，用来保存已
经完成执行但还没有提交的指令结果。这一硬件缓冲区称为重排序缓冲区，也可用于在可被推
测的指令之间传送结果。

重排序缓冲区（ROB）像 Tomasulo 算法通过保留站扩展寄存器集一样，提供了附加寄存器。
ROB会在一定时间内保存指令的结果，这段时间从完成该指令的相关运算算起，到该指令提交
完毕为止。因此，ROB 是指令的操作数来源，就像 Tomasulo算法中的保留站提供操作数一样。
两者之间的关键区别在于：在 Tomasulo 算法中，一旦一条指令写出其结果之后，任何后续发射
的指令都会在寄存器堆中找到该结果。而在采用推测时，寄存器堆要等到指令提交之后才会更
新（我们非常确定该指令会被执行）：因此，ROB 是在指令执行完毕到指令提交这段时间内提
供操作数。ROB 类似于 Tomasulo算法中的存储器缓冲区，为简单起见，我们将存储器缓冲区
的功能集成到 ROB中。

ROB 中的每个项目都包含4个字段：指令类型、目的地字段、值字段和就绪字段。指令类
型字段指定这个指令是分支（没有目的地结果）、存储指令（含有存储器地址目的地），还是寄
存器操作（ALU 运算或载入指令，它含有寄存器目的地）。目的地字段提供了应当向其中写入
指令结果的寄存器编号（对于载入指令和 ALU 运算）或存储器地址（对于存储指令）。值字段
用于在提交指令之前保存指令结果值。我们稍后将会看到 ROB项目的一个例子。最后一个就绪
字段指出指令已经完成执行，结果值准备就绪。

图3-5给出包含 ROB的处理器的硬件结构。ROB包含存储缓冲区。存储指令仍然分两步执
行，但第二步是由指令提交来执行的。尽管保留站的重命名功能由 ROB代替，但在发射运算之
后仍然需要一个空间来缓冲它们（以及操作数），直到它们开始执行为止。这一功能仍然由保留
站提供。由于每条指令在提交之前都在 ROB拥有一个位置，所以我们使用ROB 项目编号而不
是保留站编号来标记结果。这种标记方式要求必须在保留站中跟踪为一条指令分配的ROB。在
本节后面，我们将研究一种替代实施方式，它使用额外的寄存器进行重命名，使用一个臥列来
替代ROB，用于决定什么时候可以提交指令。

重排序缓冲区
来自指令单元
寄存器
编号
指令队列
上数据
FP寄存器
载人/存储运算
操作数总线
浮点运算
载入缓冲区
运算总线
存储地址
2
台
保留站
存储
数据
地址
鹽加法點
载人
公共数据总线（CDB）
数据
图 3-5
使用 Torasulo 算法的FP单元的基本结构，为处理推测而进行了扩展。将此图与实施 Tomasulo 算
法的图3-4对比，主要变化是添加了 ROB，去除了存储器缓冲区，后者的功能被集成到 ROB中。
如果拓宽 CDB，以允许每个时钟周期完成多条指令，则可以将这一机制扩展为支持多发射方案
在指令执行时涉及以下4个步骤。

\begin{enumerate}
    \item 发射—从指令队列获得一条指令。如果存在空保留站而且 ROB 中有空插槽，则发射
    该指令；如果寄存器或 ROB 中已经含有这些操作数，则将其发送到保留站。更新控制项，指明
    这些缓冲区正在使用中。为该结果分配的 ROB项目编号也被发送到保留站，以便在将结果放在
    CDB上时，可以使用这个编号来标记结果。如果所有保留站都被占满或者 ROB 被占满，则指
    令发射过程停顿，直到这两者都有可用项目为止。
    \item 执行—如果还有一个或多个操作数不可用，则在等待计算寄存器的同时监视 CDB。
    这一步骤检查RAW 冒险。当保留站中拥有这两个操作数时，执行该运算。指令在这一阶段可
    能占用多个时钟周期，载人操作在这一阶段仍然需要两个步骤。此时执行存储指令只是为了计
    算有效地址，所以在这一阶段只需要有基址寄存器可用即可。
    \item 写结果—当结果可用时，将它写在CDB上（还有在发射指令时发送的ROB标签），
    并从 CDB写到ROB并写到任何等待这一结果的保留站。将保留站标记为可用。对于存储指令
    需要执行一些特殊操作。如果要存储的值已经推备就绪，则将它写到 ROB项目的 Value 字段，
    以备存储。如果要存储的值还不可用，CDB必须进行监视，直到该数值被广播时再更新该存储
    指令ROB项目的Value 字段。为简单起见，我们假定这一过程在存储操作的写结果阶段进行；
    稍后将会讨论如何放松这一要求。
    \item 提交—这是完成指令的最后一个阶段，在此之后将仅留下它的结果。（一些处理器将
    这一提交阶段称为“完成”或“毕业”。）根据要提交的指令是预测错误的分支、存储指令，或
    是任意其他指令（正常提交），在提交时共有3种不同的操作序列。当一个指令到达 ROB的头
    部而且其结果出现在缓冲区中，则进行正常提交；此时，处理器用结果更新其寄存器，并从ROB
    清除该指令。提交存储指令与正常提交类似，但更新的是存储器而不是结果寄存器。当预测错
    误的分支到达 ROB 的头部时，它指出推测是错误的。ROB 被刷新，执行过程从该分支的后续
    正常指令处重新开始。如果对该分支的预测正确，则该分支完成提交。
\end{enumerate}

指令一旦提交完毕，它在 ROB的相应项将被收回，寄存器或存储器目的地被更新，不再需
要ROB项。如果ROB填满，那么只需要停止发射指令，直到有空闲项目为止。下面，我们研
究一下这-机制如何处理前面为 Torasulo算法所举的示例。

例题
假定浮点功能单元的延迟与前面示例中相同：加法为2个时钟周期、乘法为6个
时钟周期、除法为12个时钟周期。使用下面的代码段（也就是前面用于生成表3-4
的代码段），写出当MUL.D做好提交准备时的状态表。
解答

L.D
F6,32（R2）
L.D
F2,44（R3）
MUL.D
FO,F2,F4
SUB.D
F8,F2,F6
DIV.D
F10,FO,F6
ADD.D
F6,F8,F2

表3-7用3个表给出了结果。注意，尽管 SUB.D指令已经完成执行，但它不会在MUL.D
提交之前提交。保留站和寄存器状态字段中的基本信息与 Tomasulo 算法中相同（见
3.5 节中关于这些字段的描述）。区别在于，Qj和 Qk字段以及寄存器状态字段中的
保留站编号被 ROB 项目编号代替，我们已经将 Dest字段加到保留站中。Dest字段
指定一个 ROB项目，也就是这个保留站项目所生成结果的目的地。

\begin{verbatim}
    I.$y
    项目
    1
    2
    3
    4
    5
    6
    繁忙
    否
    否
    是
    是
    是
    悬
    表3-7 当MUL.D准备好提交时，尽管其他几个指令已经完成执行
    过程，但只有两个L.D指令已经提交
    重排序缓冲区
    指
    令
    L.D
    F6.32（R2）
    L.0
    F2.44（R3）
    MUL.D FO.F2.F4
    SUB.D F8.F2.F6
    DIV.D F10.F0, F6
    ADD.D F6.F8,F2
    状态
    提交
    提交
    写结果
    写结果
    执行
    写结果
    目的地
    F6
    F2
    FO
    F8
    F10
    F6
    #4+#2
    保留
    Op
    Vi
    Vk
    Qj
    Qk
    Mem［32 + Regs［R2］］
    Mem［44 + Regs［R3］］
    #2 × Regs［F4］
    #2-#］
    名称
    Load1
    Load2
    Addl
    Add2
    Add3
    Mult！
    Mult2
    Dest
    A
    否
    否
    否
    否
    否
    是
    MUL.D
    DIV.D
    Mem［44 + Regs［R3］］
    字段
    FO
    F1
    F2
    F3
    Regs［F4］
    Mem［32 + Regs［R2］］
    FP寄存譯状态
    F4
    #3
    #3
    #5
    F5
    F6
    F7
    F8
    F10
    重排序#
    3
    6
    繁忙
    是
    否
    否
    否
    否
    否
    是
    4
    s
    是
    是
\end{verbatim}
*MUL.D位于ROB的头部，此处两个L.D指令只是约了便于理解。尽管 SUB. D和ADD.D指令的结果已经可用，
而且可以用作其他指令的数据源，但它们在MUL.D指令提交之前不会提交。DIV.D正在执行过程中，但
由于它的延迟要比MUL.D长，所有不会独自究成。“值”列表示所保存的值；\#X格式表示 R0B项目X的
值字段。重排序缓冲区1和2实际上已经完成，但汐了提供更多信息，也一并列在表中。我们没有给出
载入/存储队列的项目，这些项目是按顺序保存的。

上面的例子说明了采用推测的处理器与采用动态调度的处理器之间的关键区别。对比表3-7
与表3-4中的内容，后者显示的是同一代码序列在采用 Tomasuo算法的处理器上的执行情况。
关键区别在于：在上面的例子中，MUL.D是排在最前面的未完成指令，它之后的所有指令都不允
许完成。而在表3-4中，SUB.D 和 ADD.D指令也已经完成。

这一区别意味着具有 ROB 的处理器可以在维持精确中断模式的同时动态执行代码。例如，
如果 MUL.D指令导致一个中断，我们只需要等待它到达 ROB 的头部并生成该中断，刷新ROB
中的任意其他未完成指令。由于指令提交是按顺序进行的，所以这样会生成一个精确异常。

而在使用 Tomasulo算法的例子中，SUB.D和 ADD.D指令都可以在MUL.D 激发异常之前完成。
结果就是寄存器 F8和 F6（SUB.D和 ADD.D指令的目的地）可能被改写，中断可能不准确。
一些用户和架构师认为不准确的浮点异常在高性能处理器中是可接受的，因为程序可能会
终止；关于这一主题的深入讨论请参阅附录J。而其他类型的异常，比如页面错误，由于程序
必须在处理此类异常之后透明地恢复执行，所以很难容忍这些异常出现不准确情况。

在循序提交指令时使用ROB，除了支持推测执行之外，还可以提供准确的异常，如下例所示。
例题
解答
考虑前面 Tomasulo算法使用的示例，表3-6显示了其执行情况：
\begin{verbatim}
    Loop：
    L.D
    FO,0（R1）
    MUL.D
    F4,FO,F2
    S.D
    F4,0（R1）
    DADDIU
    R1,R1，#-8
    BNE
    R1,R2,Loop
    ；branches if R1!R2
\end{verbatim}
假定这个循环中所有指令已经发射了两次。还假定第一次选代的L.D和MUL.D指
令已经提交，并且所有其他指令都已经完成执行。正常情况下，存储指令将在
ROB 中等待有效地址操作数（本例中为 R1）和值（本例中为F4）。由于我们只考
虑浮点流水线，所以假定存储指令的有效地址在发射该指令时计算。
表3-8用两个表给出了结果。

表3-8 尽管所有其他指令已经完成执行过程，但只有L.D和 MUL.D 指令已经提交。
因此，没有保留站处于繁忙状态，所以图中没有示出
重排序缓冲区
\begin{verbatim}
    项
    目
    繁
    忙
    揂
    令
    状：
    态
    目的地
    1
    2
    3
    4
    5
    -6
    7
    8
    9
    10
    否
    否
    是
    是
    悬
    是
    是
    悬
    是
    是
    L.0
    F0,0（RI）
    提交
    MUL.D
    F4.F0.F2
    提交
    S.0
    F4,0（R1）
    写结果
    DADDIU R1.R1.#-8
    写结果
    值
    FD
    Menf O+Regs［R1］］
    F4
    #】 × Regs［F2］
    0 + Regs［RI］
    #2
    R1
    Regs［R1］- 8
    ENE
    R1,R2,LOOp
    写结果
    LD
    F0.0（R1）
    写结果
    MUL.D
    F4.F0.F2
    写结果
    S.0
    F4.0（R1）
    写结果
    DADDIU RI,RI.#-8
    写结果
    FO
    F4
    0+#4
    RI
    Men［#4］
    #6 × Regs［F2］
    #
    #4-8
    BNE
    R1,R2,Loop
    写结果
    FP 寄存器状态
    字段
    重排序#
    繁忙
    FO
    F1
    F2
    F3
    F4
    F5
    F6
    F7
    F8
    6
    7
    是
    否
    否
    否
    是
    否
    否
    …
    否
\end{verbatim}
*剩下的指令将会尽可能快速地提交。前两个重排序缓冲区为空，但为了完整性也一并示出
由于在提交指令之前，寄存器值和存贮器值都没有实际写入，所以在发射分支预测错误时，
处理器可以很轻松地撤销其推测操作。假定在表3-8中第一次没有选中分支 BNE。当该分支之前
的指令到达 ROB的头部之后，直接提交即可；当分支到达缓冲区的头部时，将会清除缓冲区，
处理器开始从其他路径提取指令。

在实践中，进行推测的处理器会在错误预测一个分支后尽早恢复。将预测错误的分支之后
的所有 ROB项目清空，使该分支之前的ROB项目继续执行，并在后续的正确分支处重新开始
提取指令，从而完成恢复操作。在推测处理器中，由于错误预测的影响更大一些，所以性能对
分支预测也更敏感。因此，分支处理的各个方面（预测准确度、预测错误的检测延迟、预测错
误的恢复时间）都变得更重要。

在处理异常时，要等到做好提交准备时才会识别异常。如果推测的指令产生异常，则将异常
记录在ROB中。如果出现分支预测错误，而且指令还没有执行，则在清除 ROB时将异常连同指
令一直刷新。如果指令到达 ROB 的头部，我们就知道它不再具有不确定性，应当激发该异常。
我们还可以在异常出现之后、所有先前指令都已处理完毕的情况下立即处理异常，但异常要比分
支预测错误的处理更难一些，而且由于异常的发生概率要更低一些，所以其重要性也要低一些。
表3-9给出了一条指令的执行步骤，以及为了继续执行这些步骤和要采取的动作而必须满
足的条件。我们给出了到提交时才解决预测错误分支时的情景。尽管推测似乎只是对动态调度
添加了非常简单的一点儿内容，但通过对比表3-9和表3-5中 Tomasulo 算法的相应内容，可能
看出推测大大增加了控制复杂度。此外，还要记住分支预测也要更复杂些。

在推测处理器处理存储指令时与 Tomasulo 算法中有一点非常重要的不同。在Tomasulo 算.
法中，一条存储指令可以在到达“写结果”阶段（确保已经计算出有效地址）且待存储值可用
时更新存储器。在推测处理器中，只有当存储指令到达ROB 的头部时才能更新存储器。这一区
别可以保证当指令不再具有不确定性时才会更新存储器。

表3-9大幅简化了存储指令，在实践中不需要这一筒化。表3-9需要存储指令在写结果阶
段等待寄存器源操作数，它的值就是要存储的内容；随后将这个值从该存储指令的保留站的VK
字段移到该存储指令ROB项目的“值”字段。但在现实中，待存储值只需要在提交存储指令之
前到达即可，可以直接将源指令放到存储指令的ROB项目中。其实现方法为：用硬件来跟踪要
存储的源值什么时候在该存储指令的 ROB项目中推备就绪，并在每次完成指令时搜索 ROB，
查看相关存储指令。

状态
等待条件
发射
所有指令
表3-9 算法步骤及每一步骤需要满足的条件
操作或记录工作
i （RegisterStat［rs］.Busy）/*in-flight instr.writes rs*/
｛h - Registerstat［rs］.Reorder；
if （ROB［h］.Ready）/* 已完成指令 */
｛RS［r］.vj - ROBCh］.value: RS［r］.Qj - 0：｝
else ｛RS［r］.Qj - h：｝ /* 等待指令 */
｝ else ｛RS［r］.Vj - Regs［rs］：RSlr］.0j - 0：｝：
RS［r］.Busy  yes:RS［r］.Dest - b：
ROBrb］.Instruction + opcode: ROB［b］.Dest - rd:ROB［b］.Ready - no；
浮点运算
与存储
保留站（r）和 ROB
（b）都可用
浮点运算
载人
存储
1f （RegisterStat［rt］.Busy）/*in-flight instr writes rt*/
｛h -RegisterStat［rt］.Reorder：
1f （ROB［h］.Ready）/*已完成指令 */
｛RS［r］.Vk ROBCh］.value:Rs［r］.ok +0：｝
else ｛RS［r］.Qk h：｝ /* 等待指令*/
｝ else ｛RS［r］.Vk -Regs［rt］： RS［r］.Qk -0：｝：
Registerstat［rd］.Reorder +b:RegisterStat［rd］.Busy -yes：
ROBCb］.Dest -rd：
RS［r］.A - imm:RegisterStat［rt］.Reorder - b；
RegisterStat［rt］.Busy - yes: ROBCb］.Dest - rt；
RS［r］.A - imm：
．
190
14L
（续）
状态
执行浮点
运算
载人步骤1
载人步骤2
存储
写所有非
存储指令
的结果
等待条件
（RS［r］.Qj == 0）和
（RS［r］.Ok -= 0）
（RS［r］.Qj -= 0），而且队列
中没有更早的存储指令
载入步骤1完成，ROB 中所有
先前存储指令都有不同地址
（RS［r］.Qj-=0）且存储指令
位于队列头部
r中的措令执行完毕，
且CDB 可用
计算结果
操作或记录工作
-操作数位于 Vj和 Vk中
RS［r］.A - RS［r］.Vj +RSCri.A：
读取 Mem［RS［r］.A］
ROB［h］.Address - RS［r］.Vj + RSCr］.A；
b * RSCrI.Dest: RS［r］.Busy - no：
Vx（1f （RS［×］.QJ--b）｛RSLxJ.Vj - result:RS［x］.0j- 0｝）：
x（1f（RS［X］.Qkm=b）｛RSTX］.VK - result: RS［x］.QK - 0｝）；
ROB［b］.Value result:ROBLb］.Ready - yes：
ROB［h］.Value -RSLr］.Vk；
存储
r中的指令执行完毕，
日（RS［r］.Qk ==0）
提交
指令位于 ROB头部（项目h）
d ROBTh］.Dest；/* 寄存器目的地，如果存在的话*/
且 ROBCh］.ready ==yes
if （ROB［h］.Instruction==Branch）
｛if （branch is mispredicted）
｛clear ROB［h］. RegisterStat； fetch branch dest ：）：｝
else if （ROB［h］.Instruction-Store）
｛Mem［ROB［h｝.Destination］ROB［h］.Value：｝
else /* 将结果放在寄存器目的地 */
｛Regsid］ -ROBChJ.Value：｝：
ROB［h］.Busy -no: /*释放ROB 项目*/
/* 如果没有其他指令正在写目标寄存器，则释放该寄存器*/
1f （RegisterStat［d］.Reorder==h｝｛RegisterStat［d］.Busy -no：｝：
*对于发射的指令，rd 为目的地、rs 和rt 为源、r为分配的保留站、b是分配的ROB项目、h是 ROB的头项目。RS
是保留站数据结构。保留站返回的值被称为 result。RegisterStat 是寄存器数据结构，Regs 表示实际寄存器，R0B是
重排序缓冲区数据结构。

这一补充并不复杂，但添加之后有两个效果：需要向ROB 中添加一个字段，表3-9尽管已
经采用了小字体，但仍然会变得更长！尽管表3-9进行了简化，但在本示例中，我们将允许该
存储指令跳过写结果阶段，只需要在准备提交前得到要保存的值即可。

和 Tomasulo 算法一样，我们必须避免存储器冒险。用推测可以消除存储器中的 WAW 和
WAR冒险，这是因为存储器更新是循序进行的，当存储指令位于 ROB 头部时，先前不可能再
有尚未完成的载人或存储指令。通过以下两点限制来解决存储器中的RAW冒险。

（1） 如果一条存储指令占用的活动ROB 项目的“目的地”字段与一条载入指令的A字段取
值匹配，则不允许该载人指令开始执行第二步骤。

（2） 在计算一条载入指令的有效地址时，保持相对于所有先前存储指令的程序顺序。
这两条限制条件共同保证了：对于任何一条载人指令，如果它要访问由先前存储指令写人
的存储器位置，在这条存储指令写人该数据之前，该载入指令不能执行存储器访问。在发生此
类 RAW 冒险时，一些推测处理器会直接将来自存储指令的值旁路给载人指令。另一种方法是
采用值预测方式预测可能出现的冲突；我们将在3.9节考虑这一方法。

尽管这里对推测执行的解释主要是针对浮点运算的，但这些技术可以很容易地扩展到整
数寄存器和功能单元。事实上，推测在整数程序中可能更有用一些，因为这些程序中的代码
可能更难预测一些。此外，只要允许在每个周期内发射和提交多条指令，就可以将这些技术
扩展到能够在多发射处理器中工作。事实上，在这些处理器中，一些实用技术可能会在编译
器的支持下在基本模块中开发足够的指令级并行，所以对这些处理器来说，推测技术可能是
最有意义的。

\section{以多发射和静态调度来开发 ILP}
前面几节介绍的技术可以用来消除数据与控制停顿，使用CPI 到达理想值1。为了进步
提高性能，我们希望将 CPI 降低至小于1，但如果每个时钟周期仅发射一条指令，那CPI是不
可能降低到小于1的。

多发射处理器的目标（将在下面几节中讨论）就是允许在一个时钟周期中发射多条指令。
多发射处理器主要有以下3类。

（1） 静态调度超标量处理器。
（2） VLIW（超长指令字）处理器。
（3） 动态调度超标量处理器。

两种超标量处理器每个时钟发射不同数目的指令，如果它们采用静态调度则采用循序执行，
如果采用动态调度则采用乱序执行。

与之相对，VLIW 处理器每个时钟周期发射固定数目的指令，这些指令可以设置为两种格
式之一：一种格式是一个长指令；另一种是一个固定的指令包，指令之间具有一定的并行度，
由指令显式表示出来。VLIW处理器由编译器进行静态调度。Intel 和 HP 在创建1A-64体系结构
时（具体描述见附录H），它们还将这种体系结构命名为 EPIC（显式并行指令计算机）。
尽管静态调度超标量处理器在每个周期内发射的指令数是可变的，而不是固定的，但它
们在概念上实际与VLIW更接近一些，这是因为这两种方法都依靠编译器为处理器调度代码。
由于静态调度超标量的收益会随着发射宽度的增长而逐渐减少，所以静态调度超标量主要用
于发射宽度较窄的情况，通常仅有两条指令。超过这一宽度之后，大多数设计人员选择实现
VLIW 或动态调度超标量。由于两者的硬件要求和所需要的编译器技术是类似的，所以这一
节将主要介绍VLIW。深入理解这一节的内容之后，可以很轻松地将相关道理扩展到静态调
度超标量。

表3-10总结了多发射的基本方法和它们的突出特征，并给出了使用每一方法的处理器。
基本VLIW方法
VLIW使用多个独立功能单元。VLIW没有尝试向这些单元发射多条独立指令，而是将多
个操作包装在一个非常长的指令中，或者要求发射包中的指令满足同样的约束条件。由于这
两种方法之间没有本质性的区别，所以假定将多个操作放在一条指令中，原始 VLIW方法即
是如此。

由于 VLIW的收益会随着最大发射率的增长而增长，所以我们主要关注宽发射处理器。实际
上，对于简单的两发射处理器，超标量的开销可能是最低的。许多设计人员可能会说：四-发射
处理器的开销是可控的，但在本章后面将会看到，开销的增长是限制宽发射处理器的主要因素。
191
192
［93
194
144
常见名称
超标量（静态）
表3-10 多发射处理中使用的5种主要方法以及区分它们的主要特性
发射结构
动态
冒险检測
硬件
调
突出特征
静态
循序执行
示
例
大多属于嵌入式领
域：MIPS和ARM，
包括ARM Cortex-A8
目前还没有
超标量（动态）
动态
硬件
动态
一些乱序执行，但
没有推测
超标量（推测）
动态
硬件
带有推测的动态
具有推测的乱序执
Intel Core i3、 i5.i7，
行
AMD Phenom,IBM
Power 7
VLIW/LIW
静态
以软件 主
静态
所有冒险由编译器
大多数示例属于信
判断和指出（经常
号处理领城，比如T
是隐式的）
C6x
EPIC
以静态沩主 以软件为主
大多为静态
所有冒险由编译器
Itanium
隐式判断和指出

* 本章主要讨论硬件操作密集的技术，它们都采用某种超标量形式。附录H主要介紹基于編译器的方法。EPIC方法（在
IA-64 体系结构中实施）扩展了早期VLIW 方法的主要概念，将静态与动态方法结合在一起。

我们考虑一个 VLIW处理器，在上面运行包含5种运算的指令，这5种运算是：一个整数
运算（也可以是一个分支）、两个浮点运算和两个存储器引用。这些指令可能拥有与每个功能单
元相对应的一组字段，每个单元可能为16~24位，得到的指令长度介于80~120位之间。作为
对比，Intel Itanium 1 和2的每个指令包中包含6个运算（也就是说，它们允许同时发射两个3
指令包，如附录H所述）。

为使功能单元保持繁忙状态，代码序列必须具有足够的并行度，以填充可用操作插槽。这
种并行是通过展开循环和调度单个更大型循环体中的代码而展现的。如果展开过程会生成直行
代码，则可以使用局部调度技术，它可以对单个基本模块进行操作。如果并行的发现与开发需
要在分支之间调度代码，那就必须使用可能更为复杂的全局调度算法。全局调度算法不仅在结
构上更为复杂，而且由于在分支之间移动代码的成本很高，所以它们还必须进行非常复杂的优
化权衡。

在附录H 中，我们将讨论跟踪调度，它是专门为 VLIW 开发的全局调度技术之一；我们
还将研究可以消除条件分支的特殊硬件支持，扩展了局部谓度的用途，提高了全局调度的性能。
而现在，我们将依靠循环展开来生成一个长的直行代码序列，所以可以使用局部调度来构
建 VLIW指令，并集中研究这些处理器的运行情况。

例题
解答
假定有一个 VLIW，它可以在每个时钟周期中发射两个存储器引用、两个浮点运
算和整数运算或分支。写出针对这样一个处理器展开循环x［1］- x［i］+s （3.2.1
节例题中的 MIPS 代码）的版本。可进行任意次展开，以消除所有停顿。忽略延
迟分支。

表3-11 给出了这一代码。该循环被展开后，形成循环体的7个副本，消除了所有
停顿（即，全空发射周期），运行9个时钟周期。这一代码的运行速度9个周期
生成7个结果，也就是每个结果需要1.29个周期，与3.2节使用非展开调度代码
的两发射超标量相比，速度差不多是它的两倍。
3靜您 及米升友LL
145
存储器引用1
L.D FO.0（R1）
L.D F10，-16（RL）
L.D F18.-32（R1）
L.D F26，-48（R1）
表3-11 占用内层循环并替代未展开序列的 VLIW 指令
存储晟引用2
浮点运算1
浮点运算2
\begin{verbatim}
    L.D F6，-8（R1）
    L.D F14，-24（R1）
    L.D F22，-40（R1）
    整数运算/分支
    ADD.D F4.FO.F2
    ADD.0 F12.F10,F2
    ADD.D F20,F18.F2
    ADD.D F28,F26,F2
    ADD.D F8,F6,F2
    ADD.D F16,F14, F2
    ADD. D F24,F22.F2
    S.D F4.0（RI）
    S.D F12.-16（R1）
    1
    S.D F20,24（R1）
    S.D FB，-8（R1）
    S.D F16.-24（R1）
    S.D F24,16（R1）
    DADDUI R1,R1.#-56
    S.D F28,8（R1）
    BNE R1,R2,Loop
\end{verbatim}
*在假定没有分支延迟的情况下，这一代码需要9个周期；通常，分支延迟也需要进行调度。其发射迷率汐 9个时钟周期
发射23个运算，或者说每个周期2.5个运算。其效率为大约 60%（也就是包含操作的可用插槽比例）。为了实现这一发
射速率，需要更多寄存器，远远超过 MIPS通常在处理这一循环时使用的寄存器数目。上面的 VLIW 代码序列需要至少8个淨
点寄存器，而在基本 MIPS处理器上，同一代码序列可以仅使用2个浮点寄存器，在使用未展开調度时，也只需囊使用5个。
原始VLIW模块中既存在一些技术问题，也存在一些逻辑问题，从而降低了其效率。技术
问题包括代码大小的增大和锁步（clockstep）操作的局限性。有两个不同因素共同造成 VLIW
代码大小的增大。第一，要在直行代码段中生成足够操作，需要大量展开循环（如前面的示例
所示），从而增大了代码大小。第二，只要指令未被填满，那些没有用到的功能单元就会在指令
编码时变为多余的位。在附录日中，我们研究软件调度方法，比如软件流水线，它们可以在没
有明显增大代码规模的情况下获得循环展开的好处。

为了应对这种代码大小的增长，有时会使用能编码。比如，一条指令中可能只有一个很
大的立即数字段供所有功能单元使用。另一种技术是在主存储器中压缩指令，然后在到达缓存
或进行译码时再展开它们。在附录H 中，我们将介绍其他一些技术，并证明IA-64 中存在的代
码大幅扩展现象。

早期的VLIW是锁步工作的，根本就没有冒险检测硬件。在这种结构中，由于所有功能单
元都必须保持同步，所以任意功能单元流水线中的停顿都必然导致整个处理器停顿。尽管个
编译器也许能够调度起决定作用的功能单元，以防止停顿，但要想预测哪些数据访问会遭遇缓
存停顿，并对它们进行调度，那是非常困难的。因此，应当对缓存进行分块，并能导致所有功
能单元停顿。由于发射速度和内存引用数目都变得很大，所以这一同步限制变得不可接受。在
最近的处理器中，这些功能单元以更独立的方式工作，在发射时利用编译器来避免冒险，而在
发射指令之后，可以通过硬件检测来进行非同步执行。

二进制代码兼容性也是 VLIW的主要逻辑问题。在严格的VLIW方法中，代码序列既利用指
令集定义，又要利用具体的流水线结构，包括功能单元及其延迟。因此，当功能单元数目和单元
延迟不同时，就需要不同的代码版本。与超标量设计相比，由于这一要求而更难以在先后实施版
本之间或者具有不同发射带宽的实施方式之间移植代码。当然，要想通过新的超标量设计而提高
性能，可能需要重新编译。不过，能够运行|版本二进制文件是超标量方法的一个实际优势。
EPIC方法（IA-64体系结构是它的一个主要示例）解决了早期 VLIW 设计中遇到的许多问
题，包括扩展到更积极主动的软件推测与方法，在保证二进制兼容性的前提下克服硬件依赖的
局限性。

所有多发射处理器都要面对的重要挑战是尝试开发大量IP。这种并行是通过展开浮点程
序中的简单循环而实现的，而原来的循环很可能可以在向量处理器上高效地运行（向量处理器
在下一章介绍）。对于这类应用程序，目前还不清楚多发射处理器是否优于向量处理器；其成本
是类似的，向量处理器的速度可能与多发射处理器相同，或者还会更快一些。多发射处理器相
对于向量处理器的潜在优势在于它们能够从结构化程度较低的代码中提取某些并行，以及能够
很轻松地缓存所有形式的数据。因为这些原因，多发射方法已经成为利用指令级并行的主要方
法，而向量主要作为这些处理器的扩展。

\section{以动态调度、多发射和推测来开发 ILP}
到目前为止，我们已经看到了动态调度、多发射和推测等各种机制是如何单独工作的。本
节，我们将这三种技术结合在一起，得到一种非常类似于现代微处理器的微体系结构。为简单
起见，我们只考虑每个时钟周期发射两条指令的发射速率，但其概念与每个时钟周期发射三条
或更多条指令的现代处理器没有什么不同。

假定我们希望扩展 Tomasulo算法，以支持具有分离整数、载人/存储和浮点单元（包括浮
点乘和浮点加）的多发射超标量流水线，每个单元都可以在每个时钟周期后动一个操作。我们
不希望向保留站乱序发射指令，这样可能会违犯程序语义。为了获得动态调度的全部好处，允
许流水线在一个时钟周期内发射两条指令的任意组合，通过调度硬件问整数和浮点单元实际分
配运算。由于整数指令和浮点指令的交互非常关键，所以还会扩展 Tomasulo 方案，以处理整数
和浮点功能单元与寄存器，还能整合推测执行功能。如图36所示，其基本组织结构类似于每个
时钟周期发射一条指令、具有推测功能的处理器的组织结构，不过必须改进其发射和完成逻辑，
以允许每个时钟周期处理多条指令。

在动态调度处理器中（无论有无推测功能），每个时钟周期发射多条指令都非常复杂，原因
很简单，这些指令之间可能存在相关性。因此，必须为这些并行指令更新控制表；否则，这些
控制表中可能会出现错误，或者会丢失相关性。

在动态调度处理器中，已经采用两种方法在每个时钟周期内发射多条指令，这两种方法都
基于这样一个事实：要在每个时钟周期中发射多条指令，其关键在于保留站的分配和流水线控
制表的更新。一种方法是在一个时钟周期的一半时间内运行这一步骤，从而可以在一个时钟周
期内运行2条指令；遗憾的是，很难将这一方法扩展为每个时钟周期处理4条指令。

第二种方法是构建必要的逻辑，一次处理两条或更多条指令，包括指令之间可能存在的相
关性。可以在每个时钟周期发射四条或更多条指令的现代超标量处理器可能采用这两种方法：
都采用流水线方式并拓宽了发射逻辑。一个重要的事实是：仅靠流水线无法解决这一问题。使
指令发射占用多个时钟周期时，由于每个时钟周期都会发射新指令，所以必须能够分配保留站，
并更新流水线表，使下一个时钟周期进行的相关指令发射能够利用更新后的信息。

在动态调度超标量中，这一发射步骤是最基本的瓶颈之一。为了说明这一过的复杂性，
表3-12给出了一种情景下的发射逻辑：在发射载入命令之后执行一个相关浮点运算。这个逻辑
的基础是表3-9，但它仅代表一种情景。在现代超标量中，对于所有可以在同一时钟周期内发射
的相关指令的可能组合，都必须加以考虑。这种组合数与一个周期内可发射指令数的平方成正
比，所以在尝试突破每时钟周期执行4条指令的速度时，发射步骤可能会成为一个瓶颈。

、
14/
重排序缓仲区
来自指令单元
指令队列
寄存器
编号
数捃
整数和浮点寄存器
载入/存
储操作
浮点运算
操作数总线
载人缓仲区
操作数总线
32
存储地址
存储
数据，
保留站
地址
瀘加法
採点乘法
载入
数据立
公共数据总线（CDB）
图 3-6

具有推测功能的多发射处理器的基本组成。在本例中，这种组成结构允许同时发射浮点乘法、
浮点加法、整数运算和载人/存储指令（假定每个功能单元每个时钟周期发射一条指令）。注意，
为了支持多发射，必须拓宽几条数据路径：CDB、操作数总线，还是非常关键的指令发射逻辑，
本图中没有显示指令发射逻辑。正如正文中的讨论，最后一项是个难题

表3-12 一对相关指令（称为指令1 和指令2）的发射步骤，其中指令1为浮点载入，指令2为浮点运
算，它的第一个操作数是载入指令的结果，r1和r2是为这些指令指定的保留站，b1和b2是指
定的重排序缓冲区项目

操作与记录
if （RegisterStat［rs1］.Busy）/*正在执行的指令写 rs */
｛h f RegisterStat［rs1］.Reorder；
if （ROB［h］.Ready）/*指令已完成*/
｛RS［r1］.Vj 个 ROBCh］.value; RS［r1］.Qj 10：｝
注释
更新载人指令的保留表，载人指令只有一
个源操作数。由于这是发射包中的第一条
指令，所以看起来与载人指令的正常执行
没有什么不同
else｛RS［r1］.Qj -h；｝ /* 等待指令*/
｝ else ｛RS［r1］.Vj - RegsLrs］：RS［r1］.Qj - 0：｝：
RS［r1］.Busy 1 yes: RS［r1］.Dest 1 b1；
RO8［b1］.Instruction 1 Load; ROB［b1］.Dest f rd1；
R0B［b1］.Ready i no：
RS［r］.A 个 inml: RegisterStat［rt1］.Reorder f b1；
RegisterStat［rt1］.Busy -yes; ROB［bl］.Dest - rt1；
148
东 平
操作与记录
RS［r2］.Qj D1：｝/* 等待载入指令*/
（续）
注释
由于我们知道浮点运算的第一个操作数来
自载入指令，所以这一步只是更新保留站，
使其指向该载人操作。注意，在执行过程
中必须分析这种相关，在发射步骤期间必
须分配ROB项目，以正确地更新保留站
由于假定浮点运算的第二个操作数来自前
面的发射包，所以这一步骤看起来和单发
射情景中一样。当然，如果这条指令依赖
于同一发射包中的某些内容，那就需要使
用指定的保留缓冲区更新这些表
if （RegisterStat［rt2］.Busy）/*正在执行的指令写 rt */
｛h f Registerstat［rt2］.Reorder；
寸f （ROB［h］.Ready）/* 指令已完成*/
｛RS［r2］.Vk 1ROBCh］.Value:RS［r2］.Qk 10：｝
else ｛RS［r2］.Qk h：｝/* 等待指令*/
｝ else ｛RS［r2］.Vk Regs［rt2］；RS［r2］.Qk 10：｝；
RegisterStat［rd2］.Reorder fb2；
RegisterStat［rd2］.Busy - yes；
ROB［b2］.Dest 1rd2；
RS［r2］.Busy -yes: RS［r2］.Dest fo2：
ROB［b2］.Instruction  FP operation: ROB［b2］.Dest 1 rd2：
ROB［b2］.Ready f no；
198
199
这一部分只是浮点运算更新这些表，它
与载入操作无关。当然，如果这个发射包
中的其他指令依赖于浮点运算（比如在四
发射超标量中的情景），所以这一指令会
影响到对这些指令保留表的更新
*对于发射指令，rd1 和rd2是目的地，rSI、r52 和rt2是源（载入指令仅有一个源），rI 和r2是分配的保留站，bI
和b2是指定的ROB项目。RS是保留站数据结构。RegisterStat 是寄存器数据結构，Regs 表示实际寄存器，ROB是
重排序缓冲区数据结构。注意，这一逻拜的正常运行需要指定重排序缓冲区项目，还有，别忘了所有这些更新是在
单个时钟周期内并行完成的，不是顾序执行！

我们可以推广表3-12的细节，以描述在动态调度超标量中更新发射逻辑和保留表的基本策
略，可以在一一个时钟周期内发射多达n条指令，如下所示。

（1）为可能在下一个发射包中发射的每条指令指定保留站和重排序缓冲区。这一指定过程可
以在知道指令类型之前完成，只需要使用n个可用重排序缓冲区项依次为发射包中的指令预先
分配重排序缓冲区项目，并确保有足够的保留站可用于发射整个包（无论包中包含多少指令）
即可。通过限制一个给定类别的指令数目（比如，一个浮点运算、一个整数运算、一个载人指
令、一个存储指令），就可以预告分配必要的保留站。如果没有足够的保留站可用，（比如，当
程序中接下来的几条指令都是同一种指令类型时），则将这个包分解，仅根据原始程序顺序，发
射其中一部分指令。包中的其余指令可以放在下一个发射包中。
（2）分析发射包中指令之间的所有相关。
（3）如果包中的一条指令依赖于包中的先前指令，则使用指定的重排序缓冲区编号来更新相
关指令的保留表。否则，使用已有保留表和重排序缓冲区信息更新所发射指令的保留表项。
当然，由于所有这些都要在一个时钟周期中并行完成，所以使上述操作变得非常复杂。

在流水线的后端，必须能够在一个时钟周期内完成和提交多条指令。由于可以在同一时钟
周期中实际提交的多条指令必须已经解决了相关性问题，所以这些步骤要比发射问题稍容易一
些。后面将会看到，设计人员已经指出如何应对这一复杂性：在3.13 节研究的 Intel i7使用的方
案基本上就是我们前面描述的推测多发射方案，包括大量保留站、重排序缓冲区、载人与存储
缓冲区，后者也可用于处理非阻塞缓存鍊失。

从性能的角度来看，我们可以用一个示例来说明这些概念是如何结合在一起的。
x
羽和堆测 开及
14y
例题
解答
考虑以下循环在两发射处理器上的执行情况，它会使整数数组的所有元素递增，
一次没有推测，一次进行推测：
\begin{verbatim}
    Loop：
    LD
    R2,0（R1）
    ；R2=array element
    DADDIU
    R2,R2，#1
    ；increment R2
    SD
    R2,0（R1）
    ；store result
    DADDIU
    R1,R1，#8
    ；increment pointer
    BNE
    R2,R3,L00P
    ；branch if not last element
\end{verbatim}
假定有独立的整数功能单元用于有效地址计算、ALU 运算和分支条件求值。给出
这个循环在两种处理器上前3次迭代的控制表。假定可以在每个时钟周期内提交
2条任意类型的指令。

表3-13和表3-14给出了一个两发射动态调度处理器在有、无推测情况下的性能。
在本例中，分支是一个关键的性能限制因素，推测会很有帮助。推测处理器中的
第三分支在时间周期13中执行，而在非推测流水线中是在时钟周期19中执行。
由于非推测流水线上的完成速率很快就会落在发射速率的后面，所以在再发射儿
个迭代之后，非推测流水线将会停顿。如果允许载人指令在决定分支之前完成有
效地址计算，就可以提高非推测处理器的性能，但除非允许推测存储器访问，否
则这一改进只会在每次迭代中获得一个时钟周期。

表3-13 在没有推测的情况下，双发射流水线版本中发射、执行和写结果的时机
\begin{verbatim}
    发射指令
    执行指令
    迭代
    编号
    指
    的时钟周
    的时钟周
    期编号
    期编号
    1
    LD
    R2,0（R1）
    1
    2
    访问存储
    的时钟周期
    编号
    3
    写CDB的
    时钟周期
    注釋
    编号
    4
    第一次发射
    DADDIU
    R2.R2，#］
    1
    等待LW
    SD
    R2.0（R1）
    2
    DADDIU
    R1,R1，#8
    2
    1
    BNE
    R2,R3,LOOP
    3
    2
    LD
    R2,0（R1）
    4
    2
    DADDIU
    R2,R2，#1
    4
    2
    Sp
    R2.0（R1）
    s
    2
    DADDIU R1.R1，#8
    s
    2
    BNE
    R2.R3, LOOP
    6
    3
    LD
    R2.0（RL）
    7
    3
    DADDIU R2.R2，#］
    7
    3
    3
    7
    8
    11
    9
    8
    13
    14
    17
    7
    等待DADDIU
    4
    直接执行
    等待DADDIU
    9
    10
    12
    等待BNE
    等待LH
    13
    等待DADDIU
    9
    等待BNE
    等待DADDIU
    15
    16
    18
    等待BNE
    等待L
    3
    SD
    R2,0（R1）
    8
    19
    等待DADDIU
    3
    DADDIU R1.R1.#8
    8
    14
    等待BNE
    3
    BNE
    R2,R3,L0OP
    9
    19
    等待DADDIU
\end{verbatim}
*注意，跟在 BNE 后面的LD 不能提前开始执行，因为它必须等待分支结果的判断。这种类型的程序（带
有不能提前解决的数据相关分支）展示了推测的戚力。将用于地址计算、ALU运算和分支条件求值
的功能单元分离开来，就可以在同一周期中执行多条指令。表3-14显示的是这个例子带有推测功能
的版本。
200
IDU
201
202
迭代
编号
1
1
1
1
1
2
表3-14 在带有推测的情况下，双发射流水线版本中发射、执行和写结果的时机
指令
\begin{verbatim}
    LD
    R2.0（R1）
    DADDIU R2.R2，#］
    SD
    R2,0（R1）
    DADDIU R1,R1，#8
    BNE
    R2.R3,LOOP
    LD
    R2.0（R1）
    发射指
    令的时
    钟周期
    编号
    1
    I
    2
    2
    3
    执行指
    访问存
    令的时
    储罸的
    钟周期
    时钟周
    编号
    期编号
    2
    3
    写CDB
    的时钟
    周期编
    号
    4
    6
    3
    3
    7
    4
    提交指
    令的时
    钟周期
    编号
    5
    7
    7
    8
    8
    注释
    4
    5
    6
    7
    2
    
    2
    2
    2
    3
    3
    3
    3
    3
    *
    DADDIU R2,R2.#］
    SD
    R2,0（R1）
    4
    5
    DADDIU R1,R1，#8
    BNE
    R2.R3, L0OP
    LD
    R2,0（R1）
    6
    7
    DADDIU R2,R2，#1
    SD
    R2,0（R1）
    DADDIU R1,R1，#8
    BEN R2,R3,1oop
    8
    9
    8
    6
    6
    10
    8
    11
    9
    9
    13
    9
    注意，跟在 BME后面的LD可以提前开始执行，因为它是推测性的。
    9
    7
    10
    12
    10
    9
    10
    10
    11
    11
    12
    13
    13
    14
    14
    第一次发射
    等待L
    等待DADDIU
    循序提交
    等待DADDIU
    没有执行
    延迟
    等待LW
    等待DADDIU
    循序提交
    等待DADDIU
    尽可能最早
    等待LM
    等待DADDIU
    提前执行
    等待DADDIU
\end{verbatim}
这个例子清楚地表明，推测方法在存在数据相关分支时可以带来一些好处，而在没有这种
分支时会限制性能。但是，这种好处依赖于分支预测的准确性。错误预测不会提高性能，事实
上，它通常会有损于性能，而且后面将会看到，它会极大地降低能耗效率。

\section{用于指令传送和推测的高级技术}

在高性能流水线中，特别是在多发射流水线中，仅仅很好地预测分支还不够；实际上还得
能够提交高带宽的指令流。在最近的多发射处理器中，所谓高带宽发射流意味着每个时钟周期
要提交4~8条指令。我们首先研究提高指令提交带宽的方法，然后再转而研究在实现高级推测
技术中的一组关键问题，包括寄存器重命名的应用与重排序缓冲区、推测的积极性和一种称为
值预测的技术，它尝试预测计算的结果，可以进一步增强ILP。
\subsection{提高指令提取带宽}

多发射处理器需要每个时钟周期提取的平均指令数目至少等于平均吞吐量。当然，提取这
些指令需要有足够宽的路径能够连向指令缓存，但最重要的部分还是分支的处理。在本节，我
们将研究两种处理分支的方法，然后讨论现在处理器如何将指令预测和预取功能结合在一起。

1.分支目标缓冲区
为了减少这个简单的五级流水线以及更深流水线的分支代价，必须知道尚未译码的指令是
不是分支，如果是分支，则需要知道下一个程序计数器（PC）应当是什么。如果这条指令是一
个分支，而且知道下一个PC应当是什么，那就可以将分支代价降为零。分支预测缓存中存储
着一条分支之后下一条指令的预测地址，这一缓存被称为分支目标缓冲区或分支目标缓存。
图3-7给出了一个分支目标缓冲区。

待提取指令的PC
查询
预测PC
分支目标
缓冲区中
的项数
否：指令未被预测
为分支，正常执行
是：该指令为分支指令，预测的PC应当用作下一个PC
被选中或未被选中的预测分支

图3-7 分支目标缓冲区。将所提取指令的PC与第一列中存储的一组指令地址进行匹配，这组地址代表
的是已知分支的地址。如果 PC与其中一项匹配，则所提取的措令为被选中的分支，第二个字
段—-预测的PC包含了对该分支之后下一个 PC的预测值。会立即在该地址处开始提取措令。第
三个字段是可选字段，可用于附加的预测状态位

由于分支目标缓冲区中预测下一条指令地址，并在对该指令译码之前把它发送出去，所以必须
知道所提取的指令是否被预测为一条选中分支指令。如果所提供指令的PC与预测缓冲区中的一个
地址匹配，则将相应的预测PC用作下一个PC。这种分支目标缓冲区的硬件基本上与缓存硬件相同。
如果在分支目标缓冲区中找到一个匹配项，则立即在所预测的 PC处开始提取指令。注意，
与分支预测目标不同的是，由于在知道一条指令是否为分支之前就要将预测到的PC发送出去，
所以预测项必须与这一指令匹配。如果处理器没有查看这一项是否与这个PC匹配，那么就会为
不是分支的指令发送错误的PC，导致性能恶化。我们只需要在分支目标缓冲区中存储预测选中
的分支，这是因为未被选中的分支应当直接提取下一条顺序指令，就好像它不是分支指令一样。
图3-8显示了在为简单的五级流水线使用分支目标缓冲区时的步骤。从这个图中可以看出，
如果在缓冲区中找到了分支预测项，而且预测正确，那就没有分支延迟。否则，至少存在两个
时钟周期的代价。我们在重写缓冲区项目时通常会暂停指令提取，所以要处理错误预测与缺失
是一个不小的难题。因此，我们希望快速完成这一过程，将代价降至最低。

为了评估一个分支目标缓冲区的工作情况，必须首先判断所有可能情景中的代价。表3-15
给出了一个简单五级流水线的相关信息。

203
204
124
指令級升 "
将PC发送到存储器
和分支目标缓冲区
FF
否
在分支目标緩
冲区中找到匹
配项目？
是
发送预
测的PC
否
指令是一个
选中分支？
是
ID
否
选中分支？
是
正常执
行指令
EX
将分支指令地址和
下一个PC输人到分
支目标缓冲区中
预测错误的分支，删
除提取的指令，重新
在其他目棕位置开始
提取，从目标缓冲区
中删除项目
正确预测分支，
继续无停顿执
行指令
图3-8 在使用分支目标缓冲区处理指令时涉及的步骤
表3-15一个分支是否在级冲区中以及它实际完成何种任务，所有这些可能组合的代价，假定仅在缓冲
区中存在选中分支
缓冲区中的指令
是
是
否
否
预测
选中
选中
实际分支
选中
未选中
选中
未选中
代价周期数
0
2
2
0
*如果一初都预测正确，而且在目标缓存中找到该分支，那就没有分支代价。如果分支预测错误，那代价就等于使用
正常信息更新缓冲区的一个时鈡周期（在此期间不能提取指令），在需要时，还有一个时钟周期用于重新开始该
分支提取下一个正确指令。如果这个分支没有找到，或未被选中，那代价就是两个周期，在此期间会更新缓冲区。
：送和推测的高级技术
153
例题

假定各个错误预测的代价周期如表3-15所示，判断一个分支目标缓冲区的总体分
支代价。关于预测准确率和命中率作以下假设：
\begin{itemize}
    \item 预测准确率为 90%（对于缓冲区中的指令）；
    \item 缓冲区中的命中率为90%（对于预测选中的分支）。
\end{itemize}
解答
通过研究两个事件的概率来计算代价，一个事件是预测分支将被选中但最后未被选
中，另一个事件是分支被选中，但未在缓冲区中找到。这两个事件的代价都是两个
周期。
概率（分支在缓冲区中，但未被选中）-缓冲区命中率 ×错误预测比例
-90% ×10%=0.09
概率（分支不在缓冲区中，但被实际选中）=10%
分支代价=（0.09+0.10）×2
分支代价=0.38
这一代价略低于延迟分支的分支代价，我们在附录C中计算了后者，大约为每个
分支0.5个时钟周期。记住，当流水线长度增加从而导致分支延迟增加时，通过动
态分支预测得到的性能改善也会随之增加；此外，使用更准确的预测器也会获得更
大的性能优势。现代高性能处理器的分支错误预测代价大约为15个时钟周期量级，
显然，准确预测是非常关键的！

分支目标缓冲区的一种变体是存储一个或多个目标指令，用于作为预测目标地址的补充或
替代。这一变体有两个潜在好处。第一，它允许分支目标缓冲区访问花费的时间长于连续两次
指令提取之间的时间，从而可能允许采用更大型的分支目标缓冲区。第二，通过缓存实际目标
指令可以让我们执行一种称为分支折合（branch folding）的优化方法。分支折合可用于实现。
时钟周期的无条件分支，有时可以实现O时钟周期的条件分支。

考虑一个分支目标缓冲区，它缓冲来自预测路径的指令，可以用无条件分支的地址来访问。
无条件分支的唯一作用就是改变PC。因此，当分支目标缓冲区发出命中信号并指出该分支是无
条件分支时，流水线只需要将分支目标缓冲区中的指令代替从缓存中的返回的指令（它是一个
无条件分支）。如果处理器在每个周期发射多条指令，那么缓冲区需要提供多条指令，以获得最
大好处。在一些情况下，有可能消除条件分支的成本。

2. 返回地址预测器
当我们试图提高推测的机会和准确性时，就面临着预测间接跳转的挑战，也就是说跳转到那
些在运行时变化的目标地址。尽管高级语言程序会为间接过程调用、选择或 case 语句、FORTRAN
计算的goto语句等生成此类跳转，但大多数间接跳转都源于过程的返回操作。例如，对于 SPEC95
基准测试，过程返回操作平均占全部分支的15%以上，占到间接跳转的绝大部分。对于诸如C++
和Java之类的面向对象的语言，过程返回操作甚至还要频繁一些。因此，将重点放在过程返回
操作上似乎是恰当的。

尽管过程返回操作可以用分支目标缓冲区预测，但如果从多个地方调用这个进程，而且来
自一个地方的多个调用在时间方面比较分散，那这种预测方法的准确性会很低。例如，在SPEC
CPU95中，一个主动分支预测器对于此类返回分支所能达到的准确率不足 60%。为了解决这一
问题，一些设计使用了一个小型的返回地址缓冲区，它的工作方式相当于一个栈。这种结构缓
存最近的返回地址：在调用时将返回地址压入栈中，在返回时弹出一个地址。如果缓存足够大
（也就是与最大调用深度相等），它就能准确地预测过程返回操作。图3-9给出了这样的返回缓
冲区在进行许多 SPEC CPU95 基准测试时的性能，缓冲区的元素数目为0~16个。在3.10节研
究ILP时将使用一个类似的返回预测器。Intel Core处理器和 AMID Phenom处理器都有返回地址
预测器。

70%
60%
50%
- Go
-0 m88ksim
- ccl
-0 Compress
Xlisp
- Jjpeg
Perl
 Vortex
40%
30%
20%
10%
0%
207
2
4
16
返回地址缓冲区项目
图 3-9

作为栈运行的返回地址缀冲区在进行大量 SPECCPU95 基准测试时的预测准确率。这一准确率
是正确预测返回地址所占的比例。若缓冲区中有0项，意味着使用标准分支预测。由于调用深度
通常不是很大（当然也有一些例外），所以中等大小的缓冲区就可以取得很好的效果。这些数据来
自Skadron 等人［1999，使用一种改进机制来防止缓存返回地址出现错误

3. 集成指令提取单元

为了满足多发射处理器的要求，近来的许多设计人员选择实现一个集成指令提取单元，作
为独立的自主单元，为流水线的其余部分提供指令。实际上，这是因为他们意识到：由于多发
射的复杂性，不能再将取指过程视为简单的单一流水级。

最近的设计已经开始使用集成了多种功能的集成指令提取单元，包括以下这些功能。

（1）集成分支预测—分支预测器变为指令提取单元的组成部分，它持续预测分支，以驱动
提取流水线。
（2） 指令预取——为了在每个时钟周期内提交多条指令，指令提取单元可能需要提前提取指
令。这一单元自主管理指令的预取（见第2章对这一技术的讨论），把它与分支预测结合在一起。
（3） 指令存储器访问与缓存—在每个时钟周期提取多条指令时会遇到不同的复杂性，包括：
提取多条指令可能需要访问多个缓存行，这是一个难题。指令提取单元封装了这一复杂性，尝
试使用预取来隐藏跨缓存模块的成本。指令提取单元还可以提供缓存功能，大体充当一个按需
单元，用于根据需要向发射级提供相应数量的指令。

几乎所有高端处理器现在都使用了一个独立的指令提取单元，通过一个包含未完成指令的
缓冲区与流水线的其余部分连接在一起。
\subsection{推测：实现问题与扩展}

本节，我们将研究涉及推测设计权衡的4个问题，首先从寄存器重命名开始，这一方法经
常被用来替代重排序缓冲区。然后讨论控制流推测的一个重要扩展：一种被称为值推测的思想。
1.推测支持：寄存器壹命名与童排序缓冲区

ROB（重排序缓冲区）的一种替代方法是明确使用更大的物理寄存器集，并与寄存器重命
名方法结合在一起。这一方法以 Tomasulo算法中使用的重命名为基础，并对其进行了扩展。在
Tomasulo 算法中，在执行过程的任意时刻，体系结构可见的寄存嚣（RO，，R31和FO，，
F31）都包含在寄存器集和保留站的某一组合中。在添加了推测功能之后，寄存器值还会临时保
存在ROB中。在任一情况下，如果处理器在一段时间内没有发射新指令，所有现有指令都会提
交，寄存器值将出现在寄存器堆中，寄存器堆直接与在体系结构中可见的寄存器相对应。

在寄存器重命名方法中，使用物理寄存器的一个扩展集来保存体系结构可见寄存器和临时
值。因此，扩展后的寄存器取代了 ROB 和保留站的大多数功能；只需要一个队列来确保循序完
成指令。在指令发射期间，一种重命名过程会将体系结构寄存器的名称映射到扩展寄存器集中
的物理寄存器编号，为目的地分配一个新的未使用寄存器。WAR和 WAR 冒险通过目标寄存器
的重命名来避免，在指令提交之前，保存指令目的地的物理寄存器不会成为体系结构寄存器，
所以也解决了推测恢复问题。重命名映射是一种简单的数据结构，它提供当前与某个指定体系
结构寄存器相对应的寄存器的物理寄存器编号，在 Tomasulo算法中，这一功能由寄存器状态表
完成。在提交指令时，重命名表被永久更新，用于指示一个物理寄存器与实际体系结构寄存器
相对应，从而有效地完成对处理器状态的更新。尽管在采用寄存器重命名时并不需要ROB，但
硬件仍然必须在一个类似于队列的结构中跟踪信息，并严格按照顺序来更新重命名表。

与ROB 方法相比，重命名方法的一个优点是简化了指令提交过程，它只需要两个简单操作：

（1） 记录体系结构寄存器编号与物理寄存器编号之间的映射不再是推测结果；（2）释放所有用于
保存体系结构寄存器“旧”值的物理寄存器。在采用保留站的设计中，当使用一个保留站的指
令完成执行后，该保留站会被释放，与一个 ROB项目对应的措令提交之后，该 ROB项目也被
释放。

在采用寄存器重命名时，撒消寄存器分配的工作要更复杂一些，这是因为在释放物理寄存
器之前，必须知道它不再与体系结构寄存器相对应，而且对该物理寄存器的所有使用都已完成。
物理寄存器与体系结构寄存器相对应，直到该体系结构寄存器被改写为止，此时将使重命名表
指向其他位置。也就是说，如果没有重命名项指向一个特定的物理寄存器，那它就不再对应于
体系结构寄存器。但是，对该物理寄存器的使用可能仍未结束。处理器可以通过查看功能单元
队列中所有指令的源寄存器说明符。如果一个给定物理寄存器没有显示为源寄存器，而且它也
没有被指定为体系结构寄存器，那就可以收回该寄存器，重新进行分配。

或者，处理器也可以一直等待，直到对同一体系结构寄存器执行写人操作的另一指令提交
为止。此时，对旧值的使用可能都已经完成了。尽管这种方法对物理寄存器的绑定日
能要

稍长于必要时间，但它的实现非常容易，在最近的超标量中得到了应用。
读者可能会问到的一个问题是：如果寄存器一直都在变化，那要如何知道哪些寄存
系结构寄存器呢？在程序运行的大多数时间内，这是无所谓的。当然，在某些情况下，
进程（比如操作系统）必须知道特定的体系寄存器的内容到底在什么位置。为了理解如何提供
这一功能，假定处理器在一段时间内没有发射指令。流水线中的所有指令最终都会提交，体系
结构可见寄存器与物理寄存器之间的映射变得稳定。这时，物理寄存器的子集包含体系结构可
见寄存器，任何未与体系结构寄存器关联的物理寄存器的都不再需要。从而可以很轻松地将体
系结构寄存器移到物理寄存器的一个固定子集中，从而可以将这些值发送给另一进程。

寄存器重命名和重排序缓冲区都继续在高端处理器中使用，这些高端处理器现在能够同时
运行40或50条指令（包括在缓存中等待的载人指令和存储指令）。无论是使用重命名还是重排
序缓冲区，动态调度超标量的关键复杂性瓶颈仍然在于所发射的指令包中包含相关性的情景。
具体来说，在发射一个发射包中的相关指令时，必须使用它们所依赖指令的指定虚拟寄存器。
在采用寄存器重命名发射指令时，所部署的策略可以类似于采用重排序缓冲区（见3.8节）进行
多发射时使用的策略，如下所示。

（1）发射逻辑预先为整个发射包保留足够的物理寄存器（比如，当每个指令最多有一个寄存
器结果时，为四指令包预留4个寄存器）。
（2）发射逻辑判断包中存在什么样的相关。如果包中不存在相关，则使用寄存器重命名结构
来判断哪个物理寄存器保存着（或将会保存）指令所依赖的结果。如果包中指令都不依赖于先
前发射包中的结果，寄存器重命名表中将拥有正确的寄存器编号。
（3） 如果一条指令依赖于在该发射包中排在前列的某条指令，那么将使用在其中存放结果的
预留物理寄存器来为发射指令更新信息。

注意，就像在重排序缓冲区中一样，发射逻辑必须在一个周期内判断包内相关性，并更新
重命名表，而且和前面一样，当每个时钟处理大量指令时，这种做法的复杂度就会成为发射宽
度中的一个主要限制。

2.推测的代价

推测的重要优势之一是能够尽早发现那些本来会使流水线停顿的事件，比如缓存缺失。但
是，这种潜在优势也带来一个潜在的重大不利条件。推测不是免费的，它需要时间和能量，错
误预测的恢复过程还会进一步降低性能。此外，为了从推测中获益，需要支持更高的指令执行
速率，为此，处理器必须拥有更多的资源，而这些资源又会占用硅面积、消耗功率。最后，如
果推测导致异常事件的发生，比如缓存缺失或转变旁视缓冲区（TLB）缺失，而没有推测时本
来不会发生这种事件，那推测造成重大性能损失的可能性就会增大。

为了在最大程度上保持优势、减少不利因素，大多数具有推测的流水线都仅允许以推测模
式处理低成本的异常事件（比如，第一级缓存缺失）。如果发生成本高昂的异常事件，比如第二
级缓存缺失或 TLB 缺失，处理器将会一直等待，等引发该事件的指令不再具有推测性时再来处
理这一事件。尽管这样会使一些程序的性能稍有降低，但对于其他一些程序，尤其是会频繁出
现此类事件且分支预测效果不佳的程序，可以避免性能大幅降低。

在20世纪90年代，推测的潜在不利因素还不是特别明显。随着处理器的发展，推测的
实际成本变得越来越明显，宽发射和推测的局限性也变得更为突出。稍后我们会再次讨论这
一主题。

3. 多分支预测
在本章已经研究过的示例中，在必须推测一个分支之前，已经有可能解决另一个分支。
有三种情景可以通过同时推测多个分支获益：（1）分支出现频率非常高；（2）分支高度汇集；
（3） 功能单元中的延迟很长。在前两种情况下，要实现高性能可能意味着对多个分支进行推
测，每个时钟周期甚至可能处理一条以上的指令。数据库程序和其他结构化程度较低的整数
计算经常呈现这些特性，使多个分支的预测变得非常重要。同样，功能单元中的延迟很长时，
也会增加对多个分支进行推测的重要性，用于避免因为流水线延迟过长而造成的停顿。
对多个分支进行推测会使推测恢复过程变得稍微复杂，但在其他方面比较简单。到2011年，
还没有处理器能够将推测与每个时钟周期内处理多条分支完全结合在一起，从性能与复杂性、
功率的对比来看，这样做的成本可能有些过高了。

4. 推测与能耗效率的挑战
推测对能耗效率有什么影响呢？乍看起来，有人可能会说推测的使用总是降低能耗效率，
因为只要椎测错误，就会以下面两种方式消耗更多的性能。

（1）对某些措令进行了推测，但劫不需要它们的结果，这些指令会为处理器生成多余工作，
浪费能量。
（2）撤销推测，恢复处理器的状态，以便在适当的地址处继续执行，这些操作都会多消耗一
部分能量，在没有推测时是不需要消耗这部分能量的。

当然，推测的确会增大功率消耗，如果我们能够控制推测，那就有可能对成本进行测量（至
少可以测量动态功率成本）。但是，如果推测过程缩短的执行时间多于它增加的平均功耗，那消
耗的总能量仍然可能减少。

因此，为了了解推测对能耗效率的影响，我们需要研究推测生成非必要任务的频繁程度。
如果会执行非常大量的非必要指令，那推测就不大可能大幅缩短运行时间！图3-10给出了由于
错误预测而执行的指令比例。可以看到，在科技代码中，这一比例很小，而在整数代码中则很
高（平均为大约30%），因此，对于整数应用程序来说，推测的能耗效率不会很高。设计人员可
以避免推测，尝试减少错误预测，或者考虑采用新方法，比如仅对那些已经知道可预测性很强
的分支进行推测。

45%

40%，
35%
30% -
誤
25% -
20% -
15% -
10%
5%
0% ~
164,zi
181.mncf
186.crafty
168.wupwise
171.swim
173.appls
17.mesa
图3-10 整数程序因为错误预测而执行的指令比例（前5个）通常要远大于浮点程序的这一比例（后5个）
211
212
213
L.O
邪 平 佴今然万 ~
P 。

5.值预测
一种提高程序中可用 LP数目的技术是值预测。值预测尝试预测一条指令可能生成的值。
显然，由于大多数指令在每次执行时都生成一个不同值（至少是一组取值中的一个不同值），所
以值预测的成功率可能非常有限。但是，也有一些特定的指令，可以很轻松地预测它们的结果
值，比如从常数池中进行载人的载人指令，或者载人一个不经常变化的取值。此外，如果一条
指令只是从一组很少的取值中选择一个，那就有可能结合其他程序行为来预测结果值。

如果值预测能够显著提高可用 ILP的数量，那它就是有用的。当某个值被用作一串相关运
算的源数据时（比如一个载人操作），这种可能性就很大。因为值预测是用来提高推测能力的，
而且错误预测会有不利的性能影响，所以预测的准确性非常关键。

尽管在过去十年里，许多研究人员都致力于值预测的研究，但其成果一直觖乏足够的吸引
力，未能在实际处理器中得到应用。不过有一种比较简单的与值预测相关的较早思想已经得到
了应用，那就是地址别名预测。地址别名预测是一种非常简单的技术，用来预测两个存储指令
或者一个载人指令与一个存储指令是否引用同一存储器地址。如果这样两条指令没有引用同一
地址，那就可以放心地交换它们的顺序。否则，就必须等待，直到知道这些指令访问的存储器
地址为止。因为我们不需要实际预测地址值，只需要知道这些值是否冲突即可，所以这种预测
更稳定，也更简单。这种有所限制的地址值预测形式已经在几种处理器中得到应用，可能会在
将来普遍采用。

\section{ILP 局限性的研究}
在：20世纪60年代出现第一批流水化处理时，就开始通过开发 TLP来提高性能。在20世纪
80年代和90年代，这些技术成为快速提高性能的关键。如果我们希望性能提升速度能够长期
快于基础集成电路的增长速度，有一个问题是非常关键的：存在多少 ILP。要开发更多 ILP 都
需要些什么？在短期范围内，这关键问题对计算机设计人员和编译器编写人员都非常关键。
这一节的数据还为我们提供了一种方法，用来验证本章所讨论思想的价值，这些思想包括存储
器消歧、寄存器重命名和推测。

在这一节，我们将回顾围绕这些问题所做的一部分研究（基于 Wall 在1993年所做的研究）。
所有这些针对可用并行进行的研究都会作出一组假定，然后求出在这些假定条件下有多少并行
可用。这里给出的数据是由一项假设条件最少的研究得出的；事实上，最终的硬件模型可能是
无法实现的。不过，所有这些研究都假定采用一种特定级别的编译器技术，尽管这些研究使用
了过于强劲的硬件，但其中一些假定还是可能会影响到结果。

我们将会看到，对于一些成本合理的硬件模型来说，过多采用推测的成本可能会得不偿失：
在功率与硅面积使用方面的效率过于低下。尽管许多研究团体和主流处理器制造商都认为大量
开发 ILP是有利的，最初不愿意接受这种可能性，但到了2005年，他们不得不改变自己的观点。

\subsection{硬件模型}

为了了解ILP可能有哪些局限性，我们首先需要定义一种理想处理器。在理想处理器中，
去除了对ILP的所有约束条件。在这样一个处理器中，对ILP仅有的一些限制是由通过寄存器
或存储器的实际数据流带来的。

对理想或完美处理器作出以下假设。
（1）无限寄存器重命名——有无限个虚拟寄存器可供使用，因此避免了所有 WAW和 WAR
冒险，可以有无数条指令同时执行。
（2）完美分支预测—分支预测非常完美。所有条件分支都被准确预测。
（3） 完美跳转预测——所有跳转（包括用于返回和计算跳转的跳转寄存器）都被完美预测。
与完美分支预测相结合，这相当于拥有了一种处理器，它可以进行完美预测，并拥有一个极大
的可执行指令缓冲区。
（4） 完美存储器地址别名分析—所有存储器地址都已确切知道，如果载入指令与存储指令
的地址不同，可以将载人指令移到存储措令之前。注意，这就实现了完美的地址别名分析。
（5）完美缓存—所有存储器访问都占用一个时钟周期。在实践中，超标量处理器通常会使
用大量ILP，隐藏了缓存缺失，使这些结果变得非常乐观。

假设（2）与假设（3）消除了所有控制相关。而假设（1）和假设（4）消除了除真数据相关之外的所
有数据相关。这4条假设结合在起来，就意味着：对于程序执行中的任何一条指令，在它所依
赖的先前指令执行完毕之后，可以将该指令调度到紧随其后的时钟周期上。根据这些假设，甚
至有可能将程序中最后一条动态执行的指令调度到最前面的时钟周期上！因此，这一组假设同
时包含了控制推测与地址推测，在实现时把它们当作是完美的。

我们首先研究一个可以同时发射无数条指令的处理器，能够提前看到运算过程中的任意指
令。在我们研究的所有处理器型号中，对于一个时钟周期能够执行哪些类型的指令没有限制。
在可以发射无限条指令时，这意味着在一个时钟周期中可能有无数条载人指令或存储指令。此
外，所有功能单元的延迟都假定为一个时钟周期，所以任何相关指令序列都可以在连续周期上
发射。如果延迟长于一个周期，尽管不会降低任意时刻正在执行的指令数目，但可能会降低每
个周期发射的指令数目。（任意时刻正在执行的指令通常被称为是在 in flight。）

当然，这种理想处理器很可能是无法实现的。例如，IBM Power7（见 Wendell 等人［2010］）
是日前所发布的最高级超标量处理器。Power7一个时钟周期最多可以发射6条指令，最多在12
个执行单元的8个单元上开始执行（其中只有两个是载人/存储单元），支持大型重命名寄存器
集（允许数百条指令同时执行），使用大型主动分支预测器，采用动态存储器消歧。Power7 继
续向前发展，使用更多的线程级并行，增大所支持的同时多线程（SMT）数目（达到每个核心
4个线程），将每个芯片的核心数目增大到8个。在研究了完美处理器的可用并行之后，我们将
研究在近期可能设计出的处理器中能够实现什么功能。

为了测量可用并行，可以使用标准 MIPS优化编译器来编译和优化一组程序。对这些程序
交付运行，生成一个指令与数据引用踪迹。然后尽早调度踪迹中的所有指令，仅受数据相关的
限制。由于使用了踪迹，所以很容易实现完美分支预测和完美别名分析。利用这些机制，可以
大大提前对这些指令的调度，在没有数据相关的大量指令之间进行移动，由于可以完美预测分
支，所以这些指令也包括分支指令在内。

图3-11显示了6个SPEC92基准测试的平均可用并行度数目。本节中，始終以平均指令发
射率为指标来测试并行。注意，所有指令的延迟为一个时钟周期；延迟较长时会减少每个时钟
的平均指令数。这些基准测试中有3个（fpppp、doduc 和 tomcatv）是浮点操作密集的基准测试，
另外3个为整数程序。浮点基准测试中有两个（fpppp 和 tomcatv）有大量并行，可供向量计算
机或多处理器开发（不过，由于已经对代码进行了一些人工转换，所以 fpppp 中的结构十分杂
乱）。doduc程序拥有大量并行，但这些并行不会在简单的并行循环中出现，这一点与 fpppp 和
tomcatv 中不同。程序li是一个拥有许多短相关的LISP 解释程序。

gcc
espresso
li
fpppp
doduc
tomcatv
18
R 55
75
119
150
140 160
0
20
4060 80 100 120
、
每个周期发射的指令数
图 3-11 一个完美处理器中运行6个 SPEC92基准测试时的可用|LP。前3个程序是糙数程序，后3个
是浮点程序。浮点程序中循环数量很多，有大量循环级并行

\subsection{可实现处理 上IP的局限性}

本节中，我们将研究一些处理器的性能，这些处理器的硬件支持水平非常强大，不低于2011
年所能达到的水平，或者是考虑到过去十年发生的事件与教训，可能在近期达到的水平。具体
来说，我们将假定以下固定属性。

\begin{enumerate}
    \item 每个时钟周期最多发射64条指令、没有发射限制，或者是2011年最宽处理器总发射宽
    度的10倍以上。后面将会讨论，超大发射宽度对时钟频率、逻辑复杂度和功率产生的实际影响
    可能才是对ILP 开发的最重要限制。
    \item  一个竞赛预测器，拥有1000项和一个16项返回预测器。这个预测器可以与2011年的
    最佳预测器相媲美；这个预测器不是主要瓶颈。
    \item  对于动态完成的存储器引用能够完全消除歧义—这项要求是比较高的，但当窗口较
    小时（因此，发射速度和载人/存储缓冲区也较小），或者通过地址别名预测，还是有可能做
    到的。
    \item 具有64个附加整数寄存器和64个浮点寄存器的寄存器重命名，这一数目要略小于2011
    年的最强劲处理器。Intel Core i7的重排序缓冲区中有128项，不过它们没有划分为整数与浮点
    寄存器，而IBMPower7差不多有200个寄存器。注意，我们假定流水线延迟为1个周期，它显
    著降低了对重排序缓冲区项的需要。Power7 和i7 延迟都不低于10个时钟周期。
\end{enumerate}

图3-12给出了这一配置在窗口大小变化时的结果。这一配置比任何已有实现方式都要复
杂和昂贵，特别是在指令发射数方面，它要比2011 年任意处理器上的最大可用发射数大10
倍以上。不过，它对未来实施方式所能生成的内容给出了一个非常有用的范围。由于另一个
原因，这些图形中的数据可能是非常乐观的。在64条指令中没有发射限制：它们可能都是存
储器引用。在不远的将来，甚至没有人会在处理器中设计这一功能。遗憾的是，用合理的发
射限制来界定处理器的性能是十分困难的，这不仅是因为存在各种各样的可能性，而且发射
限制的存在需要用准确的指令调度器来评估并行，在研究具有大量发射指令的处理器时，其
成本会非常昂贵。

另外还请记住，在解读这些结果时，没有考虑缓存缺失和长于1个时钟周期的延迟，这两
个因素都可能产生严重影响！
\begin{verbatim}
    gcc
    espresso
    li
    10
    $10
    10
    9
    8
    13
    10
    12
    12
    11
    11
     ILP 局限性的研究
    窗口大小
    无限大
    烟 256
    128
    64
    32
    161
    9
    1$2
    fipppp
    35
    222
    doduc
    14
    117
    116
    15
    156
    tomcatv
    「34
    14
    \
    0
    20
    30
    40
    50
    60
\end{verbatim}
每个时钟周期发射的指令数
團3-12 对于各种整数与浮点程序，每个时钟周期发射64个任意指令时，可用并行数随窗口大小的变化
情况。尽管重命名寄存器的数目少于窗口大小，但所有操作的延迟为一个时钟周期、重名寄存
器的数目等于发射宽度，这一事实使处理器能够在整个窗口中开发并行。在实际实现中，必须平
衡窗口大小和重命名寄存器的数目，以防止这些因素中的某一个过度限制发射速率

图3-12中最令人吃惊的观测结果是：考虑到以下所列的实际处理器约束条件，窗口大小对
整数程序的影响不像对浮点程序那么严重。这一结果指向了这两种程序之间的关键区别。两个
浮点程序中能够利用循环级并行，这意味着可以开发的 ILP数目较高，而对于整数程序，其他
因素（比如分支预测、寄存器重命名、并行较少，等等）都是重要的限制情况。从万维网和云
计算于20世纪90年代中期开始爆发式发展以来，人们增加了对整数性能的重视，所以这一观
察结果非常关键。事实上，在过去10年里，大多数市场增长（事务处理、Web 服务器等）都依
赖于整数性能，而不是浮点性能。在下一节将会看到，对于2011年的真实处理器，实际性能要
远低于图3-12显示的数据。

由于在实际硬件设计中，提高指令速率具有一定的难度，所以设计人员面临着一项挑战：
决定如何更好地利用集成电路上有限的可用资源。是采用具有更大缓存和更高时钟速率的较简
单处理器，还是将重点放在具有较慢时钟和较小缓存的指令级并行卜、汶最重要的设计权衡
之一。下面的例子演示了这些挑战，在第4章，我们将会看到一种以 GPU形式开发细粒度并行
的替代方法。

例题
解答
考虑以下3种假设的非典型处理器，我们将在上面运行 SPECgec 基准测试。

\begin{enumerate}
    \item 一个简单的 MIPS双发射静态流水线，其时钟速率为4 GHz，所实现的流水线
    CPI 为0.8。这一处理器的缓存系统每条指令发生0.005次缺失。
    \item 一个双发射MIPS 处理器的深度流水线版本，缓存稍小一些，时钟速率为5GHZ。
    处理器的流水线CPI为1.0，缓存较小，平均每条指令生成0.0055次缺失。
    \item 一个推测超标量理器，具有一个64项窗口。它能实现的发射率这一窗口大
    小理想发射率的一半。（使用图3-12中的数据）这一处理器的缓存最小，每条
    指令产生0.01次缺失，但通过动态调度可以隐藏每次缺失25%的缺失代价。这
    个处理器的时钟为2.5 GHz。
\end{enumerate}

假定主存储器时间（这一时间决定了缺失代价）为50 ns。判断这3种处理器的相
对性能。

首先，我们使用缺失代价和缺失率信息计算每一种配置中缓存敏失对CPI 的影响。
计算公式如下：

缓存 CPI=每条指令的缺失数×缺失代价
我们需要为每个系统计算觖失代价：
存储器访问时间
缺失代价=
时钟周期
这3种处理器的时钟周期时间分别为250p、200ps 和 400ps。因此，觖失代价是：
缺失代价，=元
S0 ms -200周期
250 ps
缺失代价，=
50 ns -250周期
200 ps
缺失代价s=
0.75xS0 n8-94周期
400 ps
为每一缓存应用此公式：
缓存 CPI，=0.005 ×200=1.0
缓存 CPI，=0.0055 ×250=1.4
缓存 CPI；=0.01 x 94=0.94
除了处理器3之外，我们知道了其他处理器的流水线 CPI 影响；它的流水线CPI
给出如下：
流水线CPL，=爱射速率
1==0.22
9×0.5
4.5
现在可以通过添加流水线和缓存CPI因素来求出每个处理器的 CPI：
\begin{verbatim}
    CPI，=0.8+1.0=1.8
    CPI=1.0+1.4=2.4
    CPI；=0.22+0.94=1.16
    ） ILP 局限性的研究
    163
    以确定相对性能：
    CR
    指令执行速度-
    CPI
    指令执行速度，=4000MHz _2222 MIIS
    指令执行速度，=
    5000MH
    2.4
    =2083 MIPS
    指令执行速度。-2500MIH -21SS MIPS
\end{verbatim}
在这个例子中，简单的双发射静态超标量看起来是最好的。在实践中，性能取决
于CPI和时钟频率两项假设。
\subsection{超越本研究的局限}
和所有极限研究一样，我们在本节分析的研究内容也有其自己的局限性。我们将这些局限
性分为两类：即使在完美推测处理器中也会存在的局限性；在一或多种现实模型中存在的局限性。
当然，第一类中的所有局限性也适用于第二类。适用于完美模型的最重要局限性包括以下几个。

\begin{enumerate}
    \item 访问存储器的 WAW 和WAR 冒险—-这一研究通过寄存器重命名消除了 WAW和 WAR
    冒险，但却没有消除存储器使用中的冒险。尽管乍看起来，此类情况很少会出现（特别是 WAW
    冒险），但它们的确会因为栈帧分配而出现。某种被调用过程重复利用栈中上一过程使用的存储
    器位置，这样可能会导致WAW和 WAR冒险，造成不必要的限制。Austin 和 Sohi 在1992年研
    究了这一问题。
    
    \item 不必要的相关—在有无数个寄存器时，就可以消除真寄存器数据相关之外的所有其他
    数据相关。但是，由于递归或代码生成约定而造成的相关仍然会引人一些不必要的真数据相关。
    其中一个例子就是在一个简单的 for 循环中对于控制变量的相关。由于控制变量在每次循环选
    代时都会递增，所以循环中包含至少一个相关。在附录H 中可以看到，通过展开循环和进行积
    极的代数优化可以消除此类相关计算。Wall的研究中包含了数量有限的一些此类优化，但更积
    极地应用这些优化方式有可能增加 ILP的数目。此外，特定的代码生成约定也会引入一些不必
    要的相关，特别是在使用返回地址窗口和栈指针寄存器时（它会在调用/返回序列中递增和递
    减）。Wall消除了返回地址寄存器的影响，但在链接约定中使用规模措针可能会导致“不必要的”
    相关。Postiff等人［1999］研究了消除这一约束条件的益处。
    \item 克服数据流限制—如果值预测的精度很高，那就可能克服数据流限制。但到目前
    止，在关于这一主题的 100 多篇论文中，还没有一篇能够使用一种现实预测方案来显著提高
    ILP。显然，完美的数据值预测可以得到高效的无限并行，因为每个指令的每个值都可能提前预
    测得出。
\end{enumerate}

对于不够完美的处理器，已经提出了几种可以发现更多ILP 的思想。其中一个例子是沿
多条路径进行推测。Lam 和 Wilson［1992］讨论了这一思想，在本节介绍的研究内容中进行了
探讨。通过在多条路径上进行推测，可以降低错误恢复的成本、发现更多的并行。由于所需
硬件资源呈指数增长，所以只有对有限个分支评估这一方案才有意义。Wall ［1993］提供了用
于在最多8路分支卜讲行双向推测所需要的数据、考虑到双向推测的成木 而日已还知道甘
余一个分支方向会被丢弃（在多条路径上执行这样一个过程会增加无数计算的数量），因此所
有商用设计都没有在双向路径上进行太多投人，而将更多的硬件用于在正确路径上进行更准
确的推测。

这一节介绍的所有限制都不是根本性的限制，因为克服它们并不需要改变什么物理定律，
理解这一点非常重要。它们只是在实践中遇到的一些限制，意味着在开发更多 ILP 的过程中存
在一些难以逾越的障碍。这些限制（无论是窗口大小、别名检测，还是分支预测）都是设计人
员和研究人员要应对的挑战。

在21世纪的前5年中，为突破这些限制所做的许多尝试都遭到了失败。一些技术取得了
一点点改进，但通常会大幅提高复杂度、增加时钟周期、使功率的增加不合比例。总而言之，
设计人员发现，在尝试开发更多 ILP 时，其效率非常低下。在本章的结语部分会再次讨论这一
主题。

\section{交叉问题：ILP 方法与存储器系统}
\subsection{硬件推测与软件推测}
本章介绍的这些硬件密集的推测方法与附录H中的软件方法为开发 ILP 提供了不同选择。
下面列出这些方法的一些权衡与局限性。

\begin{itemize}
    \item 为了能够大范围进行推测，必须能够消除存储器引用的歧义。对于包含指针的整数程序，
    很难在编译时实现这一功能。在基于硬件的方案中，存储器地址的动态运行时消歧是使
    用前面介绍的Tomasulo算法的技术完成的。这一消歧功能可以在运行时把载入指令移到
    存储指令之后。对推测存储器引用的支持可以帮助克服编译器的保守性，但如果使用这
    些方法时不够仔细，那恢复机制的开销可能会大于它们所能带来的收益。
    
    \item 当控制流不可预测时，当基于硬件的分支预测优于在编译时完成的软件分支预测时，基
    于硬件的推测效果较佳。这些特性对于许多整数程序都是成立的。例如，一个好的静态
    预测器，对4个主要整数 SPEC92 程序的错误预测率大约为 16\%，而硬件预测器的错误
    预测率低于10\%。因为当预测不正确时，推测错误的指令可能会拖慢计算速度，所以这
    一差别非常明显。因为这一差别而导致了一个结果：即使是静态调度的处理器中通常也
    会包含动态分支预测器。
    
    \item 即使对于被推测的指令，基于硬件的推测也能保持完全精确的异常模型。最近的基于软
    件的方法也添加了这一特殊支持，同样可以做到这一点。
    \item 基于硬件的推测不需要补充或记录代码，而那些雄心勃勃的软件推测机制则需要这一
    条件。
    \item 基于编译器的方法能够深人了解代码序列，从中获益，从而在代码调度方面要优于纯硬
    件驱动的方法。
    \item 对于一种体系结构的不同实现方式，采用动态调度的硬件推测不需要采用不同代码序列
    就能实现好的性能。尽管这一收益很难量化，但从长期来看，这一收益可能是最重要的。
\end{itemize}

有意思的是，它曾经是设计IBM360/91的动机之一。另一方面，最近的显式并行体系结
构（比如IA-64）已经增加一定的灵活性，可以减少代码序列中固有的硬件相关。

在硬件中支持推测的主要缺点是需要更多、更复杂的硬件资源。必须针对两个方面对这一
硬件成本进行评估，一是与软件方法中编译器的复杂性相对比，一是与依赖此类编译器的处理
器简化程度相对比。

一些设计人员已经尝试将动态方法和基于编译器的方法结合起来，以期达到两种方法的最
佳效果。这种组合方式可以产生一些有趣但不够明确的交互。例如，如果将条件移动与寄存器
重命名结合起来，就会出现一种微妙的副作用。由于之前已经在指令流水线中更改了目标寄存
器的名称，所以一个被撒消的条件移动操作仍然会向目标寄存器中复制一个值。这种微妙的交
互使设计与验证过程都变得非常复杂，还可能会降低性能。

迄今为止，在采用软件方法支持 ILP和推测的计算机中，Intel Itanium处理器是最强大的。
它没有像设计人员所希望的那样提供硬件支持，对于通用、非科学代码尤为如此。意识到3.10
节讨论的困难之后，设计人员开发 ILP 的热情已经减退，因此，在大多数体系结构最终采用的
硬件方案中，发射速率为每个时钟周期发射3~4条指令。
\subsection{推测执行与存储器系统}
在一个支持推测执行或条件指令的处理器中，自然可能生成一些在没有推测执行时就不会
用到的无效地址。如果激发了保护异常，那这不仅是一种错误行为，而且推测执行的收益还可
能会被错误异常的开销抵消。因此，存储器系统必须识别推测执行的指令和条件执行的指令，
并抑制相应的异常。

此类指令可能会导致缓存因缺失而停顿，这些不必要的停顿仍然可能超过推测带来的收益，
出于和前面类似的原因，我们不能允许这种现象的发生。因此，这些处理器必须与非阻塞缓存
相匹配。

在实际中，由于 L.2 缺失的代价非常大，所以编译器通常都仅对L.1 缺失进行推测。图2-5
表明：对于一些表现优异的科学程序，编译器可以承受多个未能命中的L2缺失，从而有效地降
低1.2 觖失代价。同样，为使这一方法奏效，缓存背后的存储器系统必须能够满足编译器在存储
器同时访问数量方面的要求。
\section{多线程：开发线程级并行提高单处理器吞吐量}
我们在这一节讨论的主题—多线程，是一个真正的交叉主题，它同流水线与超标量相关、
与图形处理器（第4章）相关，还与多处理器（第5章）有关。我们将在这里介绍这一主题，
并开发多线程的用途，利用多线程来隐藏流水线和存储器延迟，从而提高单处理器的吞吐量。
在下一章，我们将会看到多线程是如何在GPU 中提供相同好处的，最后，第5章将研究多线程
与多处理的组合使用。由于多线程是向硬件展示更多并行的主要技术，所以这些主题相互紧密
地交织在一起。严格来说，多线程使用线程级并行，因此也正是第5章的主题，但考虑到它在
改进流水线应用中以及 GPU中扮演的角色，都促使我们在这里介绍这一概念。

尽管使用ILP来提高性能具有很大的优势：它对编程人员是适度透明的，但我们已经看到，
在某些应用程序中，IP 可能受到很大的限制或者难以开发。具体来说，当指令发射率处于合
理范围时，那些到达存储器或片外缓存的缓存缺失不太可能通过可用TLP 来隐藏。当然，当处
理器停顿下来等待缓存缺失时，功能单元的利用率会激剧下降。

由于人们在试图通过更多的ILP来应对很长的存储器停顿时，效果非常有限，所以很自然
地会问，一个应用程序中是否有其他形式的并行可用来隐藏存储器延迟呢？例如，在联机事务
处理系统中，根据请求的多个查询和更新操作之间就存在着自然并行。当然，许多科学应用程
序中也包含自然并行，这是因为它们经常是对自有并行特性的三维结构进行建模，可以使用相
互分离的线程来开发这种结构。即使是使用基于 Windows 的现代操作系统的桌面应用程序，也
经常会同时运行多个活动应用程序，提供了并行源。

多线程技术支持多个线程以重叠方式共享单个处理器的功能单元。而与之相对的是，开发
线程级井行（TLP）的更一般方法是使用多处理器，它同时并行运行多个独立线程。但是，多
线不会像多处理器那样复制整个处理器。而是在一组线程之间共享处理器核心的大多数功能，
仅复制私有状态，比如寄存器和程序计数器。在第章将会看到，许多最新处理器既在一个芯
片上集成多个处理器核心，又在每个核心中提供多线程。

要复制一个处理器核心中每个线程的状态，就要为每个线程创建独立的寄存器堆、独立的
PC和独立的页表。存储器本身可以通过虚拟存储器机制共享，这些机制已经支持多重编程了。
此外，硬件必须支持对不同线程进行较快速的修改；具体来说，线程切换的效率应当远远高于
进程切换，后者通常需要数百个到数干个处理器周期。当然，为使多线程硬件实现性能改进，
一个程序中必须包含能够以并发形式执行的多个线程（有时说这种应用程序是多线的）。这些
线程既可由编译器识别（通常是来自具有并行结构的语言），也可能由程序员识别。

实现多线程的硬件方法主要有3种。细粒度多线程每个时钟周期在线程之间进行一次切
换，使多个线程的指令执行过程交织在一起。这种交织通常是以轮询方式完成的，当时发生停
顿的所有进程都会被跳过。在细粒度多线程情况下，当一个线程停顿时，哪怕这一停顿只有几
个周期，也可以执行其他线程中的指令，所以这种多线程的一个重要好处是它能够隐藏因为长、
短停顿而导致的吞吐量损失。细粒度多线程的一个主要不足是它会减缓个体线程的执行速度，
因为一个做好执行准备、没有停顿的线程可能会被其他线程的执行延迟。它用单个进程的性能
损失（这里所说的性能是以延迟来衡量的）来换取多线程吞吐量的一致性。我们稍后将会研究
Sun Niagara处理器，它采用了简单的细粒度多线程，Nvidia GPU也是如此，我们将在下一章
介绍。

粗粒度多线程的设计目的就是用来作为细粒度的替代选项。粗粒度多线程仅在发生成本较
高的停顿时才切换线程，比如第2级或第3级缓存敏失时。通过这一变化，只有当一个线程週
到成本高昂的停顿时才会发射其他线程的指令，这样就不再严格要求线程切换操作必须是无成
本的，同时也大大降低了减缓任一线程执行速度的可能性。

不过，粗粒度多线程也有一个严重不足：克服吞吐量损失的能力非常有限，特别是由于较
短停顿导致的损失。这一局限性源于粗粒度多线程的流水线启动成本。由于采用粗粒度多线程
的CPU仅发现来自单个线程的指令，所以当流水线发生停顿时，在新线程开始执行之前会出现
“气泡”。由于这一启动开销，粗粒度多线程更多是用来应对那些成本超高的停顿，当发生此类
停顿时，重新填充流水线的时间与停顿时间相比可以忽略不计。已经有几个研究项目对粗粒度
多线程进行了探索，但现在的主流处理器中都还没有使用这一技术。

最常见的多线程实施方式称为同时多线程（SMT）。同时多线程是细粒度多线程的一种变体，
它是在多发射、动态调度处理器的顶层实现细粒度多线程时自然出现的。和其他形式的多线程
一样，SMT利用线程级并行来隐藏处理器中的长延迟事件，从而提高功能单元的利用率。SMT
的关键在于认识到通过寄存器重命名和动态调度可以执行来自独立线程的多个指令，而不用考
虑这些指令之间的相关性；这些相关性留给动态调度功能来处理。

图3-13从概念上给出了处理器在以下不同配置中开发超标量源的能力差异：
\begin{itemize}
    \item 不支持多线程的超标量；
    \item 支持粗粒度多线程的超标量；
    \item 支持细粒度多线程的超标量；
    \item 支持同时多线程的超标量。
\end{itemize}

执行槽—
超标量
粗MTT
细MT
SMT

图313 4种不同方法在应用一个超标量处理功能单元执行槽的表现状况。水平维度表示每个时钟
周期中的指令执行能力。垂直维度代表时间周期序列。空白框（白色）表示该时钟周期的相
应执行槽未被使用。灰色和黑色的阴影框对应多线程处理器中的4个不同线程。黑色框表示
在不支持多线程的超标量中被占用的发射槽。Sun T1 和 T2 （aka Niagara）处理器是细粒度
多线程处理器，而 Intel Core i7和 IBM Power7 处理器使用 SMT。T2有8个线程、Power7
有4个、Intel i7 有2个。在所有现有SMT中，每次只发射一个线程中的指令。SMT的区别
在于：在后面决定执行哪条指令时不需要考虑相互之间的影响，可以在同一个时钟周期执行
来自几个不同指令的操作

在不支持多线程的超标量中，由于缺乏 ILP（包括用子隐藏存储器延迟的ILP），所以发
射槽的使用非常有限。由于L2和L3缓存“失的长度原因，处理器在大多数时间内可能保持
空闲。

在粗粒度多线程超标量中，通过切换到另一个利用处理器资源的线程来部分隐藏长时间
的停顿。这一切换减少了完全空闲的时钟周期数。但是，在粗粒度多线程处理器中，仅当存
在停顿时才会进行线程切换。由于新线程有一个启动时间，所以仍然可能存在一些完全空闲
的周期。

在细粒度情况中，线程的交织可以消除全空槽。此外，由于每个时钟周期都会改变发射线
程，所以可以隐藏较长延迟的操作。由于指令发射和执行联系在一起，所以线程所能发射的指
令数目仅限于准备就绪的指令。当发射宽度较窄时，没有什么问题（某个时钟周期要么被占用，
要么不被占用），这就是细粒度多线程在单发射处理器中能够完美运行的原因，SMT没有什么
意义。事实上，在 SunT2 中，每个时钟周期会有两次发射，但它们来自不同线程。这样就不再
需要实施复杂的动态调度方法，而是依靠更多线程来隐藏延迟。

如果在多发射动态调度处理器的顶层实现细粒度线程，所得到的结果就是SMT。在所有现
有SMT实现方式中，尽管来自不同线程的指令可以在同一时钟周期内开始执行，但所有发射都
来自一个线程，使用动态调度硬件来决定哪些指令已经准备就绪。尽管图3-13极大地简化了这
些处理器的实际操作，但它仍然能够说明在发射宽度较宽的动态调度处理器中，一般多线程和
SIMT 的潛在性能优势。

同时多线程的出现是因为深刻地认识到：动态调度处理器已经拥有支持这一方案所需要的
大量硬件方案，包括大量虚拟寄存器。通过为每个线程添加专用的重命名表、保持独立的PC、
支持提交来自多个不同线程的指令，也可以在乱序处理器上实现多线程。

\subsection{细粒度多线程在Sun T1上的效果}

在这一节，我们利用 Sun T1 处理器来研究多线程隐藏延迟的能力。T1 是 Sun公司在2005
年发布的一种细粒度多线程多核微处理器。人们之所以特别关注T1，是因为它几乎将全部重心
都放在开发线程级并行（TLP）上，而不是用于开发指令级并行（ILP）。T1不再强调对ILP 的
调度（就在此前不久，刚刚发布了更积极的ILP处理器），回归一种简单的流水线策略，着力开
发TLP，使用多核和多线程技术来提高吞吐量。

每个T1处理器包含8个处理器核心，每个核心支持4个线程。每个处理器核心包括一个简
单的六级、单发射流水线（类似附录 C中介绍的五级 RISC流水线，还添加了用于线程切换的
流水级）。T1使用细粒度多线程（但不是SMT），每个时钟周期切换到一个新的线程，在调度
过程中，会跳过那些因为流水线延迟或缓存缺失而处于等待状态的空闲线程。只有在所有4个
线程全部空闲或停顿时，处理器才会空闲。载人指令和分支指令都会导致一个长度为3个时钟
周期的延迟，这一延迟只能由其他线程水隐藏。由于浮点性能不是T1 的重点，所以它只提供了
一组浮点功能单元，由所有8个核心共享。表3-16总结了TI处理器的各个特性。

表3-16 T1处理器小结
特性
Sun T1
多处理器和多线稞支持
每个芯片8个核心，每个核心4个线程。细粒度线程调度。8个核心共用一个浮点单元。
仅支持片上多处理
流水线结构
L1緩存
L2缓存
简单的循序六级流水线，载人指令与分支指令的延迟为3个时钟周期
16 KB指令，8KB数据。块大小为64个字节。在没有争用时，L2觖失为23个时钟周期
4个独立的L2缓存，每个大小为750 KB，与一个存储器组相联。块大小为64个字节。在
没有争用时，主存储器缺失110个时钟周期
初步实现
90nm工艺，最大时钟速率为1.2GHz，功率79W，3亿个晶体，晶片大小379mm2
T1 多线程单核性能
T1把自己的重点放在TLP上，既在各个核心上实施了多线程，又在单个晶片上使用了多个
简单核心。在这一节，我们将研究T1通过细粒度多线程提升单核心性能的效果。在第5章，我
们将研究将多线程与多核心结合在一起的效果。
为了研究T1 的性能，我们使用3种面向服务器的基准测试：TPC-C、SPECJBB（SPEC Java
业务基准测试）和SPECWeb99。由于多个线程会增大单个处理器对存储器的需求，所以可能会
使存储器系统过载，从而降低多线程的潜在收益。图3-14是TPC-C基准测试中，在每个核心执
行1个线程和每个核心执行4个线程时缺失率及所观测到的缺失延迟的相对增长情况。由于存
储器系统的争用增加，缺失率和缺失延迟都会增大。缺失延迟的增幅较小，表示存储器系统仍
然有未用空间。

從岡平处埋奋谷吐工
10y
1.7-
加 1.6-
/1.2-
L11
LI D
L2
LI1缺失 LID缺失 L2缺失
觖失率
缺失率
缺失率
延迟
延迟
延迟
图314
在 TPC-C 基准测试中，每个核心执行1个线程和每个核心执行4 个线程时缺失率与缺失延迟
的相对增长情况。这些延迟是指在一次缺失之后返回所请求数据的实际时间。在4线程情况中，
其他线程的执行可能会隐藏这一延迟的大部分时间
通过研究一个一般线程的行为，可以了解线程之间进行交互以及它们使核心保持繁忙状态
的能力。图3-15给出了3种时钟周期所占的百分比：一种是有线程正在执行，一种是有线程准
备就绪，但尚未执行，还有一种是线程没有准备就绪。注意，没有准备就绪并不意味着拥有该
线程的核心处于停顿状态，只有当所有4个线程都未准备就绪时，该核心才会停顿。
100%
90%
未就緒
圖 就緒但未被选中
正在执行
0%
类TPC-C
SPECJBB00
SPECWeb99
图 3-15 一般线程的状态细分。“正在执行”是指该线程在该时钟周期内发射了一条指令。“就绪但
未被选中”是指它可以发射指令，但另一线程已被选中；“未就绪”是指该线程正在等待一个事
件（例如，一次流水线延迟或缓存缺失）的完成
线程未准备就绪可能是因为缓存缺失、流水线延迟（由于一些延迟较长的指令导致，比如
分支、载人、浮点或整数乘/除）以及各种影响较小的因素。图3-16显示了这些不同原因的发生
频率。在50%~70%的时间里，线程未准备就绪是由缓存原因造成的，L.1指令缺失、L1 数据缺
失和L.2 缺失造成的影响大致相同。在SPECJBB 中，由于流水线造成的潜在延迟（称为“流水
线延迟”）是最严重的，可能是由于它的分支频率较高所致。
227
228
LJU
100%
90%
80%
70% -
比
60% -
50%-
40% -
其他
豳 流水线延迟
L2缺失
關LI D缺失
LII鉠失
30%-
20%-
10%-
0%
类TPC-C
SPECJBB
SPECWeb99
图 316 线程的未就绪原因细分。“其他”类别的原因是变化的。在 TPC-C中，存储器缓冲区满是最主
要的因素；在SPEC-JBB 中，原子指令是最主要的因素；而在 SPECWeb99中，这两个因素都有影响
表3-17显示了每个线程的CPI和每个核心的CPI。由于 T1 是一种细粒度多线程处理器，
每个核心有4个线程，当有足够的并行时，每个线程的理想有效CPI 为4，这意味着每个线程
占用每4个时钟周期中的1个周期。每个核心的理想CPI 为1。2005年，在积极采用 ILP的核
心上运行这些基准测试的 IPC就已经可以达到 T1核心上观测到的类似数据。但是，与2005年
更积极的 ILP 核心相比，TI核心的大小非常合适，这就是为什么 T1拥有8个核心，而同一时
期的其他处理器只提供了2~4个核心。因此，在2005年发布Sun T1处理器时，它在处理TLP
密集、存储器性能需求较高的的整数应用程序和事务处理工作负载时，具有最佳性能。
表3-17 8核心TI处理器中每个线程的CPI、每个核心的CPI、有效8核心CPI和有效IPC（CPI的倒数）
基准测试
每个线程的CP1
每个核心的CPI
TPC-C
7.2
1.80
SPECJBB
5.6
1.40
SPECWeb99
6.6
1.65
\subsection{同时多线程在超标量处理器上的效果}
一个关键问题是：通过实施 SMT 可以使性能提高多少？在2000~2001年研究这一问题时，
研究人员认为动态超标量会在接下来的5年里大幅改进，每个时钟周期可以支持6~8次发射，
处理器会支持推测动态调度、许多并行载入和存储操作、大容量主缓存、4~8种上下文，可以
同时发射和完成来自不同上下文的指令。到目前为止，还没有处理器能够接近这一水平。
因此，那些认为多编程工作负载可以使性能提高2~3倍的模拟研究结果是不现实的。实际
中，现有的SMT实现只能提供2~4个带有取值的上下文，只能发射来自一个上下文的措令，
每个时钟周期最多发射4条指令。其结果就是：由SMT获得的收益是非常有限的。
例如，在 Pentium 4 Extreme 中（（在HP-Compaq服务器中实现）使用SMT时，运行 SPECintRate
基准测试时可以使性能提高 1.01，运行 SPECfpRate 基准测试时可以使性能提高1.07。Tuck 和
Tuillsen ［2003］报告：在进行 SPLASH并行基准测试时，他们发现单核心多线程加速比的范围为
229

伙何千八任的他以里
1/1
1.02~1.67，平均加速比大约为1.22。
由于 Esmaeilzadeh 等人［2011］最近提供了大量包含丰富信息的测量数据，所以我们可以使
用一组多线程应用程序来研究在单个 订7核心中使用SMT 时获得的性能与能耗收益。我们使用
的基准测试包括一组并行科学应用程序和一组来自 DaCapo 和 SPEC Java套件的多线程 Java程
序，在表3-18中对其进行了总结。Intel i7 支持拥有两个线程的SMIT。图3-17 给出了 SMT分别
为关闭与开启状态时，在i7的一个核心上运行这些基准测试的性能比与能耗效率比。（我们绘
制了能耗效率比曲线，能耗效率是能耗的倒数，所以和加速比一样，这个比值越大越好。）
表3-18 此处用于研究多线程、第5章用于以j7研究多处理的并行基准测试
blackscholes
用Black Scholes PDE为一组期权定价
bodytrack
跟踪一个无标记的人体
cannea1
用感知缓存模拟退火法将一个芯片的路由成本降至最低
facesim
模拟人脸的动作，用于可视目的
ferret
搜索引擎，查找一组与查询图像类似的图像
fluidanimate
用SPH算法模拟流体动画的物理规则，在动画中应用
raytrace
使用物理模拟奕现可视化
streamcluster
为最佳数据点群集计算近似值
Swaptions
用Heath-Jarrow-Morto框架为一组互换期权定价
vips
对某个图像应用一系列变换
x264
MPG-4 AVC/H.264视频编码器
eclipse
集成开发环境
Tusearch
文本搜索工具
sunflow
相片真实渲染系统
toncat
tomcat servlet容器
tradebeans
Tradebeans Daytrader基准测试
xalan
用于转换XMIL文档的XSLT处理器
Pjbb2005
SPEC JBB2005的版本（但固定的是问题规模而不是时间长短）
*上半部分包含由Biena 等人［2008］收集的 PARSEC 基准测试。PARSEC 基准测试是用来代表那些违于多核处理器的计
算密集、并行应用程序。下半部分包含来自 DaCapo集含的多线程Java 基准测试（见 BlackBu 等人［2006］）和SPEC
的pibb2005。所有这些基准测试都包含一些并行；DaCapo 中的Java 基准测试和 SPEC Java 工作负載使用多个线程，
但真正的并行很少，甚至没有，因此这里没有使用。除了这里及第5章中给出的测量结果，请参阔 Esmaeilzadeh 等
人［2011］的文献，了解有关这些基准测试特性的更多信息。
尽管这两个Java 基准测试的性能增益较小，但其加速比的调和均值为1.28。在采用多线程
时，两个基准测试（pjbb2005 和 tradebeans）的并行非常有限。之所以包含这些基准测试是因为
它们是典型的多线程基准测试，可以在一个指望提高性能的SMT处理器上运行，它们提升效果
非常有限。PARSEC 基准测试的加速比要比全套Java 基准测试好一些（调和均值为 1.31）。如
果省略 tradebeans 和 pjbb2005，Java 工作负载的实际加速比（1.39）要比 PARSEC 基准测试好
得多。（在图3-18的图题中讨论了使用调和均值来汇总结果的含义。）
能耗由加速比与功耗的增加值共同决定。对于 Java 基准测试，SMT 的能耗效率与非 SMT
相同（平均为 1.0），但有两个执行状况不佳的基准测试拉低了这一数值；如果没有 tradebeans
和pjbb2005,Java基准测试的平均能耗效率为1.06，几乎与PARSEC基准测试一样好。在PARSEC
基准测试中，SMT 的能耗降低了1-（1/1.08）-7%。这种在降低能耗方面的性能改进是非常罕见
230
11L
的。当然，在两种情况下，都会因为 SMT 而需要增大静态功率，所以这些结果在能耗性能收益
方面可能稍有夸大。
2.00
加速比一一能耗效率
1.75
1.50
门SMT性能与能耗效率比
1.25
1.00
0.75 +
Lusearch
Tradebeans
Blackscholes
Bodytrack
Canneal
Facesim
Fluidanimate
Raytrace
Streamcluster
Swaptions
留 3-17
在i7 处理的一个核心中使用多线程时，Java 基准测试的平均加速比为1.28，PARSEC 基准
测试为1.31（使用非加权调和均值，在这种工作负载中，执行单线程基本集中每个基准测试的总
时间相同）。能耗效率平均值分别为0.99和1.07（调和均值）。回想一下，能耗效率高于1.0就意
味着这一特性在缩短执行时间方面的收益高于增大平均功率方面的不足。两个 Java 基准测试的加
速比很小，因此，对能耗效率的负面影响非常严重。在所有情景中都关闭了Turbo Boost。这些
数据由 Esmaeilzadeh 等人［2011］使用 Oracle（Sun） HotSpot build 16.3-b01 Java 1.6.0 虚拟机和 gcc
v4.4.1 原始编译器进行收集和分析
FO
F1 F2 DO D1 D2 D3 D4 E0 El E2 E3 E4 ES
分支错误预测代价=
13个时钟周期
指令执行和载人/存储
指令提取
ALU/MUL管道0
BTB
興
嫩队列
GHUE
指令译码
ALU管道1
LS管道O或1
BP
更新
部
更新
BP
更新
图3-18 A8 流水线的基础结构为13级。3个时钟周期用于指令提取，4个用于指令译码，还有一个5周
期的整数流水线。这样，分支预测错误的代价就是13个周期。指令提取单元会尝试保持包含12
项的指令队列处于填满状态
1/ 和 AKM COIteX-A8
1/
这些结果清楚地显示了在广泛支持 SMT的积极推测处理器中，SMT 可以采用一种高能耗
效率的方式来提高性能，这是更积极的 ILP方法无法做到的。是提供多个较简单核心，还是提供
较少的更高级核心，这两者之间的天平在2011年倾向了提供多个核心，每个核心通常是了~4发
射超标量的，其SMT支持2~4个线程。事实上，Esraeilzadeh 等人［2011］表明：在Intel is（一种
类似于17的处理器，但其缓存较少，时钟频率较低）和 Intel Atom（一种为上网本市场设计的
80x86处理器，在3.14节介绍）上，通过 SMT获得的能耗效能改进还要更大一些。

\section{融会贯通：Intel Core i7 和 ARM Cortex-A8}
本节，我们研究两种多发射处理器的设计：一种是 ARM Cortex-A8核心，它是 iPad 中Apple
A9处理器、Motorola Droid 和 iPhone 3GS、4中处理器的基础，另一种是 Intel Core i7，一种高
端、动态调度、推测处理器，主要为高端桌面应用程序和服务器应用程序设计。我们首先从较
简单的处理器开始。

\subsection{ARM Cortex-A8}
A8 是一种双发射、静态调度超标量处理器，具有动态发射检测功能，允许处理器在每个时
钟周期内发射一条或两条指令。图3-18显示了13级流水线的基本流水线结构。

A8使用一种动态分支预测器，具有一个512项2路组相联分支目标缓冲区和一个4K 项全
局历史缓冲区，由分支历史和当前 PC 进行索引。当出现分支目标缓冲区缺失时，则在全局历
史缓冲区中进行预测，然后用预测值计算分支地址。此外，还维护一个8项返回栈，用于跟踪
返回地址。一次错误预测会导致13个时钟周期的代价，用于刷新流水线。

图3-19显示了指令译码流水线。利用循序发射机制，每个时钟周期最多可以发射两条指令。
可以使用一种简单的记分板结构来跟踪何时能够发射一条指令。通过发射逻辑可以处理一对相
关指令，当然，除非它们的发射方式能使转发路径消除两者之同的相关，否则会在记分板上对
它们进行序列化。
DO
DI
D3
D4
D2
指令译码
231
232
一译码/序列
旱期译码
译码队翗
读/算
记分板
发射逻搏
奇存器堆
四重映剃
图 3-19
早期译码
译码
A8 的5级指令译码。在第一级中，使用取指单元生成的PC（或者来自分支目标缓冲区，或者
来自 PC递增器）从缓存中提取大小为8字节的块。最多对两条指令进行译码，并将它们放在译
码队列中；如果两条指令都不是分支，则将PC递增，为下一次取指做准备。一旦进入译码队列，
则由记分板逻辑决定何时可以发射这些指令。在发射时，读取寄存器操作数；回想在简单的记
分板中，操作数总是来自寄存器。寄存器操作数和操作码被发送到流水线的措令执行部分

图3-20显示了A8处理器的执行流水线。指令1或指令2可以进人这个载人/存储流水线。
在这些流水线之间支持完全旁路。ARM Cortex-A8流水线使用简单的双发射静态调度超标量，
可以在较低功率下实现相当高的时钟频率。与之相对，i使用一种相当积极的4发射动态调度
推理流水线结构。
EO
E1
Shft
MUL
INST O
INST 1
Shft
E2
E3
指令执行
整数寄存器写回
ALU
标记
MUL
2
ALU
标记
Sat
MUL
3
Sat
E4
ES
BP
更新
ACC
WB
WB
BP
更新
WB
ALU
LS 流水线
WB
图3-20 A8 的一级指令译码。乘法运算总是在 ALU 流水线0中执行
233
234
235
A8 流水线的性能
由于 A8采用双发射结构，所以它的理想CPI为0.5。可能会因为以下3种来源而产生流水
线停顿。
（1） 功能冒险，如果被选择同时发射的两个相邻指令使用同一功能流水线，就会出现功能冒
险。由于A8 是静态调度的，所以避免此类冲突是编译器的任务。如果不能避免此类冲突，A8
在这个时钟周期内最多只能发射一条指令。
（2） 数据冒险，在流水线的早期进行侦测，可能使两条指令停顿（如果第一条指令不能发
射，第二条总是会被停顿），也可能是一对指令中的第二条指令停顿。编译器负责尽可能防止
此类停顿。
（3）控制冒险，仅在分支预测错误时发生。
除了流水线停顿之外，L.1和L2 缺失都会导致停顿。
图3-21是影响 Minnespec 基准测试实际CPI 的各项因素的估计值，我们在第2章曾经见过
这些基准测试。可以看到，这一CPI 的主要影响因素是流水线延迟，而不是存储器停顿。出现
这一结果的部分原因是 Minnespec 的缓存印记要小于全套SPEC 或其他大型程序。

流水线停顿会造成性能大幅下降，深刻认识到这一点，可能对于决定将 ARM Cortex-A9设
计为动态调度超标量处理器起到了重要作用。A9和A8相似，每个时钟最多发射两条指令，但
它使用了动态调度和推测。在一个时钟周期内可以开发执行多达4条未完成指令（2个 ALU、1
个载人/存储或浮点/多媒体指令、1个分支指令）。A9使用一种功能更为强劲的分支预测器、指
令缓存预取和非阻塞L1 数据缓存。图3-22 表明，在使用相同时钟频率和几乎相同的缓存配置
时，A9的平均性能是A8的1.28倍。

图 3-21
图 3-22
1/ 和 AKM LOrTex-A8
四L2 停顿/指令
L1 停顿/指令
流水线停顿/指令
口理想CPI
每个指令的时钟周期
0+
Bzip
vpr
gcc
mcf
crafty
parser
eon perlbmk gap
vortex bzip2

对ARM A8上CPI 各组成分量的估计值表明：流水线停顿是增大基本CPI 的主要因索。eon值
得专门一提，它完成基于整数的图形计算（光线跟踪），而且缓存峡失很少。由于大量使用乘法，
计算非常密集，所以单个乘法流水线可能会成为主要瓶颈。这一估计值是利用LI和L2钟失率与
代价来计算每个指令中因为L1 和L2生成的停顿而获得的。从具体模拟器测得的CPI中减去这些
估计值即可获得流水线停顿。流水线停顿包含所有这3种冒险再加上一些次要影响，比如路预测
错误等
2.25-
A9性
能
1.5-
1.25-
l.ll
gzip vpr gcc mcf crafty parser eon perlbmk gap vortex bzip2 twolf
0.75-
在时钟频率均为1 GHZ、L1 与L2缓存大小相同时，A9与A8 的性能比表明：A9大約快 1.28
倍。两者都使用32KB主缓存和1 MB次级缓存，A8采用8路组相关，A9使用16路组相联。
A8处理器缓存中的块大小为64字节，A9为32字节。在图3-21 的图题中曾经提及，eon 大量使
用了整数乘法，动态调度与快速乘法流水线的组合使用显著提高了A9的性能。由于A9的L.I
块较小，所以 twoif的缓存表现不佳，可能是由于这一因素，twoif的速度略有减缓
110
邪J平

\subsection{Intel Core i7}
i7采用一种非常积极的乱序推测微体系结构，具有较深的流水线，目的是通过综合应用多
发射与高时钟速率来提高指令吞吐量。图3-23显示了i7流水线的整体结构。我们在研究流水线
时，按照如下步骤，首先从指令提取开始，接下来是指令提交。
存储与薮入
图 3-23
Intel Core i7 流水线结构，一同给出了存储器系统组件。总流水线深度为14级，分支错误预测
成本为17个时钟周期。共有48个载入缓冲区和32个存储缓冲区。6个独立功能单元可以在同
一时钟周期分别开始执行准备就绪的微操作
（1） 指令提取——处理器使用一个多级分支目标缓冲区，在速度与预测准确度之间达到一种
平衡。还有一个返回地址栈，用于加速函数返回。错误预测会损失大约15个时钟周期。利用预
测地址，指令提取单元从指令缓存中提取16个字节。
（2） 16 个字节被放在预译码指令缓冲区中—在这一步，会执行一个名为微指令融合的进
程。微指令融合接收指令组合（比如先对比后分支），然后将它们融合为一个操作。这个预译码
过程还将16个字节分解为单独的x86指令。由于x86指令的长度可能是1~17字节中的任何一237
种长度，所以这一预译码非常重要，预译码器必须查看许多字节才能知道指令长度。然后将单
独的x86指令（包括一些整合指令）放到包含18项的指令队列中。
（3） 微指令译码 一各个x86指令被转换为微指令。微指令是一些类似于 MIIPS的简单指令，
可以直接由流水线执行；这种方法将 x86指令集转换为更容易实现流水化的简单操作，1997年
在 Pentium Pro 中引入，一直使用至今。3个译码器处理可以直接转换为一个微指令的x86指令。
1/和 AKM Cortex-A8
177
对于那些语义更为复杂的 x86 指令，有一个微码引擎可供用于生成微指令序列；它可以在每个
时钟周期中生成多达4条微指令，并一直持续下去，直到生成必要的微指令序列为止。按照 x86
指令的顺序，将这些微指令放在一个包含28项的微指令缓冲区中。
（4）微指令缓冲区执行循环流检测和微融合—如果存在一个包含循环的小指令序列（长度
少于28条指令，或不足 256个字节），循环流检测器会找到这个循环，直接从缓冲区中发射微
指令，不再需要启动指令提取与指令译码级。微整合则合并指令对，比如载A/ALU 运算和ALU
运算/存储，并将它们发射到单个保留站（在保留站仍然可以独立发射这些指令），从而提高了
缓冲区的利用率。在对 Intel Core 体系结构的一项研究中（这种结构也合并了微整合和宏融合），
Bird 等人［2007］发现微整合几乎对性能没有什么影响，而宏融合则对整数性能有一定的下面影
响，对浮点性能也几乎没有什么影响。
（S）执行基本指令发射——在寄存器表中查看寄存器位置，对寄存器重命名、分配重排序缓
冲区项，从寄存器或重排序缓冲区中提取任意结果，然后向保留站发送微指令。
（6） i7使用一个包括36项的集中保留站，供6个功能单元共享。每个时钟周期最多可以向
这些功能单元分发6个微指令。
（7）微指令由各个功能单元执行，然后将结果发送给任何正在等待的保留站以及寄存器退回
单元，一旦知道指令不再具有推测之后，将在这里更新寄存器状态。重排序缓冲区中与该指令
相对应的数目被标记 完成。
（8） 当重排序缓冲区头部的一条或多条指令被标记为完成之后，则执行寄存器退回单元中的
未完成写人操作，并将这些指令从重排序缓冲区中删除。
i7的性能
在前面几节中，我们研究了i7分支预测器的性能和 SMT 的性能。在这本节，我们将研究
单线程流水线性能。由于积极推测与非阻塞缓存的存在，所以很难准确描述理想性能与实际性
能之间的差距。我们将会看到，因为指令不能发射而导致的停顿很少。例如，只有大约3%的载
人指令是因为没有可用保留站而导致的。大多数损失不是来自分支错误预测就是来自缓存缺失。
分支预测错误的成本为15个时钟周期，而L1 缺失的成本大约为10个时钟周期；L2缺失的成
本比L1缺失的3倍略多一些，而L3缺失的成本大约是L1 缺失成本的13倍（130~135个时钟
周期）！尽管在发生L3缺失和某些L.2 缺失时，处理器会尝试寻找一些替代指令来执行，但有
些缓冲区会在映失完成之前填满，从而导致处理器停止发射指令。

为了研究错误预测和错误推测的成本，图3-24给出了未退回工作（即它们的结果未被取消）
相对于所有微指令分发指令所占的比例（根据分发到流水线中的微指令数目来测量）。比如，对
sjeng来说，由于在所分发的微指令中，有25%从来未被退回，所以浪费了25%的工作。

注意，在某些情况下，被浪费的工作与图 3-3所示的分支错误预测率吻合，而在几种实例
中，比如 mcf中，被浪费的工作似乎要高于错误预测率。从存储器行为的角度也许能够解释这
些情况。当数据缓存缺失率非常高时，只要有足够的保留站可供停顿存储器引用使用，mcf 就
将在错误的推测期间分发许多指令。在检测到分支预测错误时，与这些指令相对应的微指令将
被刷新，但当推测存储器引用试图完成时，可能会产生缓存争用。对处理器来说，在启动缓存
请求之后，没有一种简单方法可以使其停止。

图3-25显示了19个 SPECCPU2006 基准测试的总 CPI。整数基准测试的CPI为1.06，方差
很大（标准偏差为 0.67）。MCF和 OMNETPP是两个主要例外，它们的CPI 都大于2.0，而其他
基准测试都接近或小于 1.0（gcc是第二高，为1.23）。这种偏差是由于分支预测准确度和缓存缺
失率方面的差别造成的。对于整数基准测试，L2 缺失率CPI 的最佳预测值，L3觖失率（非
常小）几乎没有什么影响。

40%
3$%-
30%-
柞
H 25%-
总
作 20%-
2180-
10%-
$%-
0%+
Perlbench
1里
Libquantum
Omnctpp
Xalancbmk
图3-24 通过计算所有已分发微指令中未退回微指令所占的比值，绘制了“被浪费工作”的数量。例如，
sjeng 的比值为25%，也就是说在已分发、执行的微指令中有25%被抛弃。本节的数据由路易斯
安那州大学的 Lu Peng教授和 Ying Zhang 博士生收集
3
2.5
2-
GH-5-
0.5-
0+
Libqjuantum
Ometpp
Xalancbmk
图3-25 19个 SPECCPU2006的 CPI 表明，尽管行为表现有很大不同，但浮点与整数基准测试的平均
CPI都是0.83。整数基准测试的CPI值变化范围为0.44~2.66，标准偏差为0.77，而浮点基准测
试的变化范围为0.62~1.38，标准偏差为0.25。本节的数据由路易斯安那州大学的 Lu Peng教授
和 Ying Zhang 博士生收集

浮点基准测试的性能较高：平均CPI较低（0.89）、标准偏差较低（0.25）。对于浮点基准测
试来说，L.1和L.2 对于确定CPI是同等重要的，而L3则扮演着小而重要的角色。尽管 i7的动
态调度和非阻塞功能可以隐藏一些缺失延迟，但缓存存储器表现仍然是一个重要因素。这进一
步强化了多线程作为另一种方法来隐藏存储器延迟的作用。

\section{谬论与易犯错误}
这里介绍的几点谬论主要集中在根据单一测量值（比如时钟频率或 CPI）来预测性能、能
耗效率以及进行推断的难度。我们还将表明：对于不同基准测试，不同体系结构方法可能会有
截然不同的表现。
谬论 如果能够保持技术的稳定，可以很容易地预测同一指令集体系结构两个不同版本的性能
与能耗效率。
Intel 为低端上网本和PMD制造了一种名为Atom230的处理器，它的微体系结构与ARMA8
非常相似。有趣的是，Atom 230和 Core i7 920都是用相同的45 nm Intel 技术制造的。表3-19
对 Intel Core i7、ARM Cortex-A8和 Intel Atom 230进行了总结。这些相似性提供了一个非常宝
贵的机会，可以在保持基础制造工艺一致的情况下，直接针对同一指令集对比两种截然不同的
微体系结构。在我们进行这一对比之前，需要再对 Atom 230多说两句。
表3-19
4 核 Intel 7 920、一种典型 Ar A8 处理器芯片（256 MBL2, 32KL1，无浮点运算）和 Intel ARM
230 的概述清楚地显示了处理器 PMD（ARM）或上网本处理器（Atom〉与服务語、高端桌面处
理器在设计原理方面的区别
\begin{verbatim}
    领域
    特定厲性
    物理芯片属性
    存储器系统
    时钟频率
    热设计功率
    包装
    TLB
    缓存
    流水线结构
    峥值存储器带宽
    峰值发射速率
    Intel i7 920
    四个核心，每个核心
    都有浮点功能
    2.66 GHz
    130W
    1366管脚BGA
    两级全四路组相联
    128 1/64 D 512 L2
    三级
    32 KB/32 KB
    256KB
    2~8 MB
    17GB/$
    4操作/时钟周期
    带有融合功能
    乱序推测
    两级
    ARMA8
    一个核心，没有浮点功能
    1 GHz
    2W
    522管脚BGA
    一組，全相联32 1/32D
    两级
    16/16或32/32 KB
    128 KB~1 MB
    12 GB/8
    2操作/时钟周期
    Intel Atom 230
    一个核心，没有
    浮点功能
    1.66 GHz
    4W
    437管脚BGA
    两级全四路组相
    联16 1/16D 64 L2
    两级
    32/24 KB
    512 KB
    8 GB/
    2操作附钟周期
    流水线调度
    分支预测
    循序动态发射
    两级
    循序动态发射
    两级
    512项BTB
    4K全局历史8项返回栈
\end{verbatim}
*记住，i7包括4个核心，每个核心的性能都要比单械心A8或 Atom 快几倍。所有这些处理器都是用相差不大的45nm
工艺实现的。
．
241
242
243
180
弟3平 指令级开 "™
Atom处理器实现x86体系结构，使用标准技术将x86 指令转换为类似于 RISC的指令（自
20世纪90年代以来，所有 x86实现都已完成。）Atom 使用了一种功能要稍强一点的微运算，可
以将算术运算与载人指令或存储指令结为一对。这意味着：对于典型的指令混合体来说，这些
指令中只有平均4%需要一个以上的微运算。然后在一个深度为16的流水线中执行这些微运算，
能够在每个时钟周期循序发射两条指令，和 ARMA8一样。这种处理器包含双整数ALU、用于
浮点加法和其他浮点运算的分离流水线，还有两个存储器运算流水线，与ARM A8相比，支持
更具一般性的双执行，但仍然受循序发射功能的限制。Atom 230有一个32KB 的指令缓存和一
个24 KB 的数据缓存，在同一晶片上由一个共享512 KB L2 提供后援。（Atom 230 还支持双线
程的多线程技术，但我们仅考虑单线程对比。）表3-20对i7、A8、Atom处理器及其关键特性进
行了总结。
表3-20 3种变化幅度很大的不同 Intel 处理
处理：
骰
时钟频率
SPECCInt2006 base
Intel Pentium 4 670
3.8 GHz
11.5
Intel Itanum -2
1.66 GHz
14.5
Intel i7
3.3 GHz
35.5
SPECCFP2006 baseline
12.2
17.3
38.4
* 尽管 Itanium 处理器有2个核心，i有4个，但在这些基准测试中仅使用一个核心。
我们可能会预期，这两种用相同工艺实现、具有相同指令集的处理器在相对性能与能耗方
面的表现是可预测的，也就是说功率和性能接近线性。我们使用三组基准测试来检验这一假设。
第一组是 Java、单线程基准测试，选自 DaCapo 基准测试和 SPEC JVM98 基准测试（见
Esmaeilzadeh 等人［2011］关于基准测试和测量结果的讨论）。第二、第三组基准测试选自 SPEC
CPU2006，分别由整数和浮点基准测试组成。

在图3-26中可以看出， 的性能明显优于 Atom。所有基准测试在17上都至少快4倍，两
个 SPECFP 基准测试快 10倍以上，一个 SPECINT 基准测试的运行速度要快8倍以上。
由于这两个处理器的时钟频率比为1.6，所以大多数优势体现在i7的CPI要低得多：对于
Java 基本测试为2.8，对于 SPECINT基准测试为3.1,SPECFP 基准为4.3。

但是，i的平均功耗略低于43W，而Atom的平均功耗为4.2W，为前者的十分之一！将性
能与功率结合起来，可以看出Atom在能耗效率方面通常有1.5倍以上的优势，有时会达到2倍
以上！通过对比这两种采用相同底层技术的处理器，可以清楚地看到，一种采用动态调度与推
测的积极超标量的性能优化是以能耗效率的显著降低为代价的。

\textbf{谬论 CPI较低的处理器总是要更快一些。}
谬论 时钟频率较快的处理器总是要更快一些。
要点在于：性能是由CPI与时钟频率的乘积决定的。在通过实现CPU的深度流水化获得高
时钟频率后，还必须保持较低的 CPI，才能全面体现快速时钟频率的优势。同理，一个时钟频
率很高、CPI很低的简单处理器也可能更慢一些。

在前面讨论的谬论中已经看到，在为不同环境设计的处理器中，即使它们采用相同的 ISA，
也可能在性能与能耗效率方面有很大不同。事实上，即使是同一公司为高端应用程序设计的同
一处理器系列，在性能方面也会有很大差异。表3-20显示的是 Intel公司对x86体系结构两种不
同实现方式的整数与浮点性能，还有一个是 Itanium 体系结构，也是 Intel 出品。

在2000年前期，人们大多把注意力都放在构建更积极的处理器，用于开发 ILP，其中就包
括 Pentium 4体系结构（它在一个微处理器中使用了当时最深的流水线）和 Intel Itanium（它每
谬论 有时越大、越被动就越好。

Pentium 4是Intel 公司生成的最积极的流水线处理器。它使用深度超过20级的流水线，有
7个功能单元，还有缓存微指令，而不是x86 指令。在这种积极的实施方式中，它的性能相对
较差一些，这清楚地表明它在开发更多 ILP 方面的努力失败了（很容易就会同时有50条指令正
在执行）。Pentium的功耗与i相似，不过它的晶体管数较少，主存储器大约是17的一半，包括
仅有2MB的次级缓存，没有第三级缓存。

Intel Itanium 是一种VLIW 风格的体系结构，尽管调度超标量相比，它的复杂度可能增加，
但它的时钟频率从来都不能与主流 x86 处理器相提并论（尽管它的总CPI 与17类似）。在研究
这些结果时，读者应当明白它们不同的实现技术，对于同等流水线的处理器来说，i7在晶体管
速度上具有优势，从而在时间频率方面也占据上风。不过，性能方面的巨大变化（Pentium 和 i7
之间相差3倍以上）还是令人吃惊的。下面的谬论部分将解释这一优势主要来自何处。

244
图 3-26
一组单线程基准测试的相对性能与功耗效率表明，i7 920 比 Atom 230快10倍以上，而功率系
数平均只有它的二分之一。柱形条中显示的性能是i7与 Atom 的比值，即执行时间（i7）/行
时间（Atom）。能耗以曲线显示，为能耗（Atom）/能耗（i7）。i7 在能耗效率方法从来都没有
打麻 Atom，不过在4个基准测试方面的性能基本相当，其中有3个是浮点。这里显示的数据由
Esmaeilzadeh 等人［2011］收集。SPEC基准测试是使用标准Intel编译器在打开优化的情况下编泽
的，Java 基准测试使用 Sun （Oracle） Hostpot Java VM。i7上只有一个核心是活动的，其余核心
处于深度节能模式。i7上使用了 Turbo Boost，这一功能可以提高其性能优势，但相对的能耗效
率会略有降低

i7 920与Atom 230性能与能耗比
\begin{verbatim}
    7-
    6
    5-
    2
    8
    9
    10-
    11、
    Luindex
    antlr
    Bloat
    -201_compress
    _202 .jess
    209_db
    213_javac
    _228_jack
    400.perlbench
    401.bzip2
    403.gcc
    429.mcf
    445.gobmk
    456.hmmer
    458.sjeng
    462.libquantum
    464.h264ref
    470.omnetpp
    473.astar
    483.xalancbmk
    416.gamess
    433.milc
    434.zeusmp
    435.gromacs
    436.cactus ADM
    437.leslie3d
    444.namd
    447.dealll
    450.soplex
    453.povray
    454.calculix
    459.gams FDTD
    465.tonto
    470.ibm
    482.sphinx3
\end{verbatim}
个时钟周期的峰值发射率是当时最高的）。后来人们很快发现在开发 ILP 时，主要限制因素是存
储器系统造成的。尽管推测乱序流水线可以很好地隐藏第一级缺失中10~15个时钟周期的大部
分缺失代价，但它们在隐藏第二级缺失代价方面几乎是无能为力的，由于涉及主存储器访问，
所以第二级缺失代价可能达到50~100个时钟周期。

结果就是，尽管使用了数目庞大的晶体管和极为高级、聪明的技术，但这些设计从来未能
接近峰值指令吞吐量。下一节将讨论这一两难选择，并从更积极的 IP方案转向多核技术，但
过去还出现了另外一个变化，放大了这一缺陷。设计人员不再尝试用 ILP来隐藏更多的存储器
延迟，而是直接利用晶体管来创建更大的缓存。Itanium 2和 i7使用三级缓存，而Pentium 4使
用了两级缓存，三级缓存为9MB 和 8MB，而Pentium 4的二级缓存为2 MB。不用说，构建更
多的缓存要比设计20多级的 Pentium 4流水线容易得多，而且从表3-20中的数据也可以看出，
这种方法也更有效一些。
\section{结语：前路何方}
在2000年初，人们对开发指令级并行的关注达到顶峰。Intel 当时要发布 Itanium，它是一
种高发射率的静态调度处理器，依靠一种类似于 VLIW的方法，支持强劲的编译器。采用动态
调度推测执行的 MIPS、Alpha 和IBM处理器正处于其第二代，已经变得更宽、更快。那一年还
发布了 Pentium 4，它采用推测调度，具有7个功能单元和1个深度超过20级的流水线，然而
它的发展前景浮现出一些鸟云。

诸如3.10节介绍的研究表明，要想进一步推动 ILP 是极为困难的，大约三到五年前的第一
代推测处理器已经实现了峰值指令吞吐量，而持续指令执行速度的增长要慢得多。

接下来的五年真相大白。人们发现Itanium 是一个很好的浮点处理器，但在整数处理方面表
现泛泛。Intel仍在生成这一产品，但它的用户不是很多，时钟频率要落后于主流 Intel 处理器，
微软不再支持其指令集。Intel Pentium 4实现了很好的性能，但在性能/瓦特（也就是能量利用）
方面的效率很低，这种处理器的复杂程度也使它很难通过提高发射率来进一步提高性能。这条
通过开发 ILP来进一步提高处理器性能的20年之路已经走到尽头。人们普遍认为 Pentium 4已
经超越了回报递减点，积极、复杂的 Netburst微体系结构被放弃。

到2005年，Intel 和所有其他主要处理器制造商都调整了自己的方法，将重点放在多核心上。
往往通过线程级并行而不是指令级并行来实现更高的性能，高效运用处理器的责任从硬件转移
到软件和程序员身上。从流水线和指令级并行的早期发展以来（大约是25年之前），这是处理
器体系结构的最重大变化。

在同一时间，设计人员开始探索利用更多数据级并行来作为提高性能的另一方法。SIMD
扩展使桌面和服务器微处理器能够适当地提高图形功能及类似功能的性能。更重要的是，GPU
追求更积极地使用 SIMD，用大量数据级并行来实现应用程序的极大性能优势。对于科学应用
程序，这些方法可以有效地替代在多核心中开发的更具一般性但效率较低的线程级并行。下一
章将研究数据级并行应用方面的这些发展。

许多研究人员预测ILP 的应用会大幅减少，预计未来会是双发射超标量和更多核心的天下。
但是，略高的发射率以及使用推测动态调度来处理意外事件（比如一级缓存缺失）的优势，使
适度ILP成为多核心设计的主要构造模块。SMT 的添加及其有效性（无论是在性能方面还是在
能耗效率方面）都进一步巩固了适度发射、乱序、推测方法的地位。事实上，即使是在嵌人市
场领域，最新的处理器（例如 ARM Cortex-A9）已经引人了动态调度、推测和更宽的发射速率。
未来处理器几乎不会尝试大幅提高发射宽度。因为从硅利用率和功率效率的角度来看，它
的效率太低了。考虑一下表3-21中的数据，这个表中给出了IBM Power 系列的4种最新处理器。
在过去10年里，Power处理器对LP 的支持已经有了一定的改进，但所增加的大部分晶体管（从
Power 4到Power7增加了差不多7倍）用来提高每个品片的缓存和核心数目。甚至对 SMT 支持
扩展的重视也多于TLP吞吐量的增加：从 Power4到Power7的LP结构由5发射变为6发射，
从8个功能单元变为12个（但最初的2个载人/存储单元没有变化），而 SMT 支持从零变为4
个线程/处理器。显然，即使是2011年最高级的IP处理器（Power7），其重点也超越了指令级
并行。下面两章将重点介绍开发数据级和线程级并行的方法。

表3-21 4种 IBM Power 处理器的特性
Power4
Powers
Power6
Power7
发布时间
2001
2004
2007
2010
最初时钟频率（GHz）
1.3
1.9
4.7
3.6
晶体管数目（百万）
174
275
790
1200
每时钟周期的发射数
s
s
6
功能单元
8
8
9
12
每芯片的核心数
2
2
2
8
SMT线程
0
2
2
4
总片上缓存（MB）
2
4.1
32.3
* 除 Powerf 之外的所有处理器都是动态调度的，Powert 是静态、循序的，所有处理器都支持载入/存储流水线。除十
进制单无之外，Powert的功能单元与 Power5相同。Power7使用 DRAM作汐L3缓存。

\section{历史回顾与参考文献}
附录 L.5节讨论了流水线和指令级并行的发展。我们为深人阅读和探讨此类主题提供了大
量参考文献。附录L.5 节涵盖了第3章和附录H 的内容。
案例研究与练习 （Jason D.Bakos 和 Robert P.Colwell设计）
案例研究：探讨微体系结构技术的影响
本案例研究说明的概念
\begin{itemize}
    \item 基本指令调度、重排序、分发
    \item 多发射和冒险
    \item 寄存器重命名
    \item 乱序和推测执行
    \item 乱序资源花费在哪里
\end{itemize}
你受命设计一种新的处理器体系结构，正在尝试找出分配硬件资源的最佳方式。你应当运用在第3
章学到的哪些硬件与软件技术？我们已经拥有功能单元、存储器以及某些代表性代码的延迟列表。对于这
种新设计的性能要求，你的老板有些含糊不清，但你从经验中知道，在其他条件相同的情况下，速度越快
通常就会越好。让我们从基础傲起，表3-22 提供了一个指令序列和延迟列表。
246
247］
104
3.1
3.2
3.3
248
3.4
3.5
3.6
［10］<1.8、3.1、3.2>如果在先前指令执行完毕之前，不会开始执行新的执行，那表3-22 中代码
序列的基准性能如何（用每次循环迭代的时钟周期表示）？忽略前端提取与译码过程。假定执
行进程没有因为缺少下一条指令而停顿，但每个周期只能发射一条指令。假定该分支被选申，
而且存在一个时钟周期的分支延迟槽。
［10］<1.8、3.1、3.2>思考一下延迟数目到底意味着什么——它们表示一个给定函数生成其输出
结果所需要的时钟周期数，没有别的意思。如果整个流水线在每个功能单元的延迟周期中停顿，
那么至少要保证任何一对“背靠背”指令（生成结果的指令后面紧跟着使用结果的指令）正确
执行。但并非所有指令对具有这种“生成者/使用者”的关系。有时，两条相邻指令之间没有任
何关系。如果流水线检测到真正的数据相关，而且只会因为这些真数据相关而停顿，而不会仅
仅因为有某个功能单元繁忙就盲目停顿，那表3-22代码序列中的循环体需要多少个时钟周期？
在代码中需要容纳所述延迟的时候插入sstal1>。（提示：延迟为+2 的措令需要在代码序列中
插人两个<Sta11>时钟周期。可以这样来考虑：一条需要一个时钟周期的指令的延迟为1+0，也
就是不需要额外的等待状态。那么延迟1+1 就意味着1个停顿周期，延迟I+N有 N个额外停顿
周期。
表3-22练习3.1至练习3.6的代码与延迟
\begin{verbatim}
    Loop：
    I0：
    11：
    12：
    T3：
    I4：
    I5：
    I6：
    17：
    18：
    19：
    LD
    DIVD
    MULTD
    LD
    ADDD
    ADDD
    ADDI
    ADDI
    SD
    SUB
    BNZ
    F2,O（RX）
    F8,F2,F0
    F2.F6.F2
    F4,0（Ry）
    F4,F0,F4
    F10.F8,F2
    Rx,RX，#8
    超过一个时钟周期的延迟
    存储器LD
    +4
    存储器SD
    +1
    整数ADD,SUB
    +0
    分支
    +1
    ADDD
    +1
    MULTD
    +5
    DIVD
    +12
    Ry.Ry.#8
    F4,0（Ry）
    R20.R4,RX
    R20,Loop
\end{verbatim}
［15］ <3.6、3.7>考虑一种多发射设计。假定有两个执行流水线，每个流水线可以在每个时钟周
期开始执行一条指令，前端有足够的取指/译码带宽，所以它不会造成执行停顿。假定可以马上
将结果从一个执行单元转发给另一个单元。进一步假设执行流水线停顿的唯一理由就是观察到
真正的数据相关。现在这一循环需要多少个周期？
［10］<3.6、3.7>在练习3.3的多发射设计中，你可能已经发现一些微妙的问题。尽管这两个流水
线的指令表完全相同，但这两个流水线既不相同，也不能互换，因为它们之间存在一个隐含顺
序，必须反映原程序中的指令排序。如果指令N在管道0上开始执行的同时，指令N+1 也开始
在执行管道1上执行，而 N+1碰巧需要的执行延迟要比 N短，那么 N+1 会在 N之前完成（而
程序排序隐含的情况并非如此）。给出至少两个理由，说明为什么可能存在冒险，为什么在微
体系结构中需要特考虑。从表3-22的代码中选出这样两条指令，作为说明这一冒险的示例。
［20］ <3.7>调整指令顺序，提高表3-22 中代码的性能。假定采用练习3.3中的双管道机器，而且
练习3.4中的乱序执行问题已经成功解决。现在只需要考虑观察到真正的数据相关和功能延迟
的情景即可。重排序后的代码需要多少个时钟周期？
［10/10/10］<3.1、3.2>从硬件发挥潜力的角度来看，任何一个未在管道中启动新操作的时钟周期
都是一次机会的丧失。
a.［10］<3.1、3.2>在练习3.5重新排序后的代码中，按两个管道进行计数，被浪费的时钟周期（也
3.7
3.8
）bert H.Colwell 攻 ）
185
就是没有启动新操作的时钟时期》占总时钟周期的比例是多少？
b.［10］<3.1、3.2>循环展开是在代码中查找更多并行的一种标准编译器技术，尽量避免浪费提
高性能的机会。手工展开练习3.35 中重新排序后代码循环的两个迭代。
c［10］<3.1、3.2>所实现的加速比为多少？（对于这个练习，仅将 N+1次迭代的指令设为绿色，
将它们与第 N次选代的指令区分开来；如果你正在实际展开这个循环，必须重新安排寄存器，
以防止迭代之间产生争用。）
［15］<2.1>计算机将大多数时间都花费在循环上，因此，为了使 CPU 资源保持繁忙，在多个
循环选代中进行推理执行是大有所为的。但没有什么事情是轻而易举的；编译器只是省略了
循环代码的一个副本，所以即使多个选代正在处理不同数据，但它们仍然会使用相同寄存器。
为避免多个选代出现寄存器争用情况，我们对它们的寄存器进行重命名。表3-23给出了一段
希望硬件进行重命名的示例代码。编译器就是展开循环，使用不同的寄存器来避免冲突，但
如果我们希望硬件来展开循环，它也必须进行寄存器重命名。怎么做呢？假定硬件有一个临
时寄存器池（将这个寄存器称为T寄存器，假定共有64个此类寄存器，即TO~T63），它们
可以代替编译器指定的寄存器。这一重命名硬件按Src（源）寄存器目标索引，表中的值是
上一个指向该寄存器的目的地的T寄存器。（可以把这些值看作“生产者”，把src 寄存器
看作“使用者”；生产者将其结果放在哪里并不重要，.只要它的使用者能够找到它就行。）
考虑表3-23中的代码序列。每次看到代码中的目标寄存器时，就用从T9开始的下一个可用
T来代替。然后相应更新所有src 寄存器，从而保持真正数据相关。给出最终得到的结果。
（提示：见表3-24。）
表3-23 寄存器重命名实践的示例代码
Loop： LD
I0：
MULTD
11：
DIVD
12：
LD
I3：
ADDD
I4：
SUBD
15：
SD
F4.0（Rx）
F2.F0,F2
F8,F4,F2
F4.D（Ry）
F6,FO,FA
F8.F8,F6
F8,0（Ry）
表3-24 提示：寄存器的期望输出
10：
I1：
LD
MULTD
T9,0（R×）
T10,F0,T9
［20］<3.4>练习3.7研究了简单的寄存器重命名：当硬件寄存器重命名程序看到一个源寄存器时，
它会代替上一条指向该源寄存器的指令的目标「寄存器。当重命名表看到目标寄存器时，它会
为其代入下一个可用T，但超标量设计需要在计算机的每一级的每一个时钟周期处理多条指令，
包括寄存器重命名在内。简单的标量处理器会为每一条指令搜索 src 寄存器映射，并在每个时
钟周期分配一个新的 dest 映射。超标量处理器也必须能够做到这一点，它们还必须确保正确地
处理两个并发指令之间的 dest-src 关系。考虑表3-25 中的示例代码序列。另外假定，在对两
条指令进行重命名的时钟周期开始时，已经知道了下面将要使用的两个可用「寄存
从概念
上来说，我们希望为第一条指令进行重命名表查询，然后根据其目标的T寄存器来更新重命名
表。然后第二条指令会做完全相同的工作，从而可以正确处理指令之间的所有相关。但
个时钟周期内，没有足够的时间将T寄存器目标写到重命名表中，然后再为第二条指令进行查
249
250
186
乐 平
询。寄存器替换工作必须实时完成（与寄存器重命名表更新并行完成）。图3-27显示了一个路
线图，它使用多工器和比较器来完成必要的实时寄存器重命名。你的任务是对于表3-25中所示
代码中的每一条指令，给出重命名表在每个时钟周期的状态。假定这个表的每个开始项目与其
索引相同 （T0=0:T1=1，.）。
表3-25 超标量寄存帮重命名的示例代码
I0: SUBD
T1: ADDD
I2:MULTD
13:DIVOD
F1.F2.F3
F4,F1,F2
F6.F4,FI
FO.F2,F6
下一个可用T寄存器
—0
重命名表
21
19-
38
这个9出现在下
一个时钟周期的
重命名表中
125 ］
..8
9
dst =FI
-srcl -F2
src2 =F3
dst =T9
- srcl =T19
 Src2 =T38
62
63
（根据instr 1）
Y
I dst =12src？
12
dst =F4
stcl =F1
src2 =F2
（类似于srC2的mux）
dst =T10
-STCl =T9
--sTc2 -T19
图3-27 超标量计算机的重命名表和实时寄存替换。（注意 src 为源，dest 为目的地。）
3.9 ［5］<3.4>如果你不清楚寄存器重命名程序必须做哪些工作，可以回过头来看看正在执行的汇编
代码，问问自己，必须具备哪些条件才能获得正确结果。例如，考虑一个3路超标量机器，同
时对下面这3条指令进行重命名：
ADDI R1.R1.R1
ADDI R1. R1, R1
ADDI RL, R1, RI
如果R1的值在初始为5，那么执行这一序列之后，它的值应当是多少？
3.10
［20］<3.4、3.9>超长指令字（VLIW）设计人员在为寄存器的使用制定体系结构方面的规则时有
几种基本选项。假定一种VLIW 设计有自排水执行流水线：一旦启动了一个操作，它的结果在
目标寄存器中最多存在L个时钟周期（其中是该操作的延迟）。从来没有足够的寄存器，所
以人们希望能够将现有寄存器发挥到极致。考虑表3-26。如果负载的延迟为1+2个时钟周期，
将此循环展开一次，并说明一个能够在每个时钟周期内完成两次载人和两次加法操作的VLIW
如何使用最少数目的寄存器，假定没有任何流水线中断或停顿。在使用自排水流水线的情况下，
给出一个事件示例，它能够破坏流水线、生成锚误结果。
pDert KLolwell攻竹）
18/
表3-26
具有两次加法、两次载入和两次停顿的示例VLIW代码
\begin{verbatim}
    Loop:LH
    R4,0（RO）；
    ADDI
    R11.R3，#1
    LH
    R5.8（R1）；
    ADDI
    R20.RO，#］
    <stal1>
    ADDI
    R10,R4，#］；
    SH
    R7,0（R6）：
    SH
    R9.8（RB）
    ADDI
    R2.R2.#8
    SUB
    R4,R3.R2
    BNZ
    R4,Loop
\end{verbatim}
3.11 ［10/10/10］<3.3>假定一个五级单流水线微体系结构（取指、译码、执行、访阿存储器、写回）
以及表3-27中的代码。除了LW、SW 和分支指令之外，所有操作的执行时间都是一个时钟周
期，LW和SW为1+2个时钟周期，分支指令为1+1个时钟周期。不进行转发操作。针对该循
环的一次迭代，说明每个时钟周期内每条指令的各个阶段。
a.［10］<3.3>每个循环选代有多少时钟损失在分支开销上？
b.［L0］<3.3>假定一个静态分支预测器，能够在译码阶段识别出反向分支。现在，有多少个时钟
周期浪费在分支开销上？
c.［10］ <3.3>假定一个动态分支预测器。有多少时钟周期损失在正确预测上？
表3-27 练习3.11的代码循环
\begin{verbatim}
    Loop：LW
    LW
    ADDI
    SUB
    SH
    BNZ
    R3.0（RO）
    R1,0（R3）
    R1,RI，#1
    R4.R3,R2
    R1,0（R3）
    R4.Loop
    252］
    ALUO
    来自译码
    器的指令
    1
    2——
    4
    ALU1
    保留站
    LD/ST
    -存储器
\end{verbatim}
图3-28 一种乱序微体系结构
3.12 ［15/20/20/10/20］＜3.4、3.7、3.14>让我们考虑一下动态调度可以实现什么。假定如图3-28所示
的微体系结构。定算术逻辑单元（ALU）可以完成所有算术运算（MULTD、DIVD、ADDD、ADDI、
SUB）和分支指令，而且保留站（RS）在每个时钟周期最多可以向每个功能单元分配一个运算
（向每个 ALU 分配一个运算，再加上向 LD/ST分配一个存储器访问指令）。
a. ［15］<3.4>假定表3-22 序列中的所有指令都存在于保留站中，还没有进行重命名。突出标示
出此代码中可以通过寄存器重命名提高性能的所有指令。（提示：查找“写后读”和“写后
写”冒险。假定功能单元的延迟与表3-22中相同。）
b.［20］ <3.4~假定（a）部分中代码的寄存器重命名版本在时钟周期 N 中存储于保留站中，延迟如
表3-22所示。说明保留站应当如何以每个时钟周期为单位乱序分配这些指令，以优化此代码
的性能。（假定保留站约束条件与（a）部分相同。还假定这些结果必须写回保留站后才能供其
他指令使用—没有旁路。）这个代码序列会占用多少个时钟周期？
c.［20］<3.4~（b）部分让保留站尝试优化调度这些指令。但在实际中，所关注的整个指令序列通常
不会存在于保留站中。各种事件会清除保留站，当新的代码序列流入、流出译码器时，保留
站必须选择如何分配它拥有的内容。假定保留站是空的。在周期0中，这个序列前两个经过
寄存器重命名的指令出现在保留站中。假定分配任何指令都需要一个时钟周期，并假定功能
单元的延迟与练习3.2中相同。进一步假定前端（译码器/寄存器重命名器）将持续在每个时
钟周期中提供两条新指令。给出 RS逐个时钟周期的分配顺序。这一代码序列现在需要多少
个时钟周期？
d. ［10］<3.14>如果我们希望改进（c）部分的结果，以下哪种方法最有帮助：（1）采用另一种 ALU？
（2）采用另-一个LD/ST单元？（3）将 ALU结果完全旁路给后续操作？或者（4）将最长的延迟截为
两段？加速比为多少？
e.［20］<3.7>现在让我们考虑推理，在超越一或多个条件分支时的取指、解码和执行过程。我们
这样做是有双重动机的：我们在（c）部分中提供的分配表中有许多“无指令”；我们知道计算
机把大多数时间花费在执行循环上（这也就意味着返回循环顶部的分支具有很强的可预测
性）。循环告诉我们到哪里去找更多的工作来做；稀疏分配表提醒我们有机会提前做点工作。
在部分（d）中，我们发现了贯穿这个循环的关键路径。设想一下将这个路径的第二副本迭入部
分（b）中获得的分配表中。要完成两个循环的工作，需要增加多少个时钟周期（假定所有措令
都在保留站中）？（假定所有功能单元都完全实现了流水化。）
练习
［25］<3.13>在这个练习中，我们将研究三种处理器之间的性能权衡，这三种处理器采用了不同
类型的多线程技术。每个处理器都是超标量、使用循序流水线，在所有载人与分支指令之后需
要固定停顿三个时钟周期，它们的L2 缓存相同。在同一周期中由相同线程发射的指令按程序
顺序读取，不能包含任何数据相关或控制相关。
\begin{itemize}
    \item 处理器A是一种超标量SMT体系结构，能够在每个周期内从两个线程发射最多2条指令。
    \item 处理器B是一种精细 MT体系结构，能够在每个周期内从一个线程发射最多4条指
    令，并在任意流水线停顿时切换线程。
    \item 处理器C是一种粗放 MT 体系结构，能够在每个周期内从一个线程发射最多8条指令，并在
    L1缓存缺失时切换线程。
\end{itemize}
我们的应用程序是一个列表搜索程序，它对一个存储器区域进行扫描，在由R16和R17指定
的地址范围之间搜索 R9中存储的特定值。这一搜索过程是平行完成的：将搜索空间平均分
为4个同等大小的连续区块，并为每个块指定一个搜索线程（产生4个线程）。每个线程的
大多数运行时间花费在下面已经展开的循环体上：
1oop: LD R1,0（R16）
LD R2,8（R16）
LD R3,16（R16）
LD R4,24（R16）
LD R5,32（R16）
LD R6,40（R16）
DDert r.VOIWell YxTT/
18y
LD R7,48（R16）
LD R8,56（R16）
BEQAL R9,R1,matcho
BEQAL R9,R2,matchl
BEQAL R9,R3,match2
BEQAL R9,R4,match3
BEQAL R9.，R5,match4
BEQAL R9,R6,matchs
BEQAL R9,R7,match6
BEQAL R9,R8,match7
DADDIU R16,R16，¥64
BLT R16,R17,100p
作出以下假定：
\begin{itemize}
    \item 使用一个屏障来确保所有线程同时开始；
    \item 在该循环迭代两次之后出现第一次L.1缓存缺失；
    \item BEQAL 分支都未被选中；
    \item BLT总是被选中；
    \item 所有3个处理器都以轮询方式调度线程。
\end{itemize}
判断每个处理器完成该循环的前两次选代需要多少个周期。
［25/25/25］<3.2、3.7>在这个练习中，我们研究如何利用软件技术从一个常见的向量循环中提取
指令级并行（ILP）。下面的循环是所谓的 DAXPY循环（双精度 aX加 Y），它是高斯消元法
的核心运算。下面的代码实现DAXPY运算 Y=aX+Y，向量长度为100。最初，RI 被设置为数组
X的基地址，R2被设置Y的基地址：
\begin{verbatim}
    DADDIU
    R4,R1，#800 ； R1 upper bound for X
    foo：
    L.D
    F2,0（R1）
    ；（F2） = X（i）
    MUL.D
    F4,F2,FO
    ；（F4） = a*X（i）
    L.D
    F6,0（R2）
    ； （F6） = Y（i）
    ADD.D
    F6,F4,F6
    ；（F6） = a*x（i）+ Y（i）
    S.D
    F6,0（R2）
    ：Y（i） = a*x（i）+ Y（i）
    DADDIU
    R1,R1，#8
    ；increment X index
    DADDIU
    RZ,RZ，#8
    ；increment Y index
    DSLTU
    R3,R1,R4
    ；test：continue 100p？
    BNEZ
    R3,f00
    ；1oop if needed
\end{verbatim}
假定功能单元的延迟如下表所示。假定在ID 阶段解决一个延迟为1周期的分支。假定结果被
完全旁路。
产生结果的指令
使用结果的指令
浮点乘
浮点ALU运算
浮点加
浮点ALU运算
浮点乘
浮点存储
浮点加
浮点存储
整数运算和所有载人
任何指令
延迟（单位：时钟周期）
6
4
s
4
2
a.［25］<3.2>假定一个单发射流水线。说明在编译器未进行调度以及对浮点运算和分支延迟进
-
255
256
257
行调度之后，该循环是什么样的，包括所有停顿或空闲时间周期。在未调度和已调度情况
下，结果向量Y中每个元素的执行时间为多少个时钟？为使处理器硬件独自匹配调度编评
器所实现的性能改进，时钟频率应当为多少？（忽略加快时钟速度会对存储器系统性能产
生的影响。）
b.［25］<3.2>假定一个单发射流水线。根据需要对循环进行任意次展开，使调度中不存在任何停
顿，消除循环开销指令。必须将此循环展开多少次？给出指令调度。结果中每个元素的执行
时间为多少？
c.［25］<3.7>假定一个 VLIW处理器，其指令中包含5个操作，如表3-11所示。我们对比两种
程度的循环展开。首先，将该循环展开6次以提取 ILP，并对其进行调度，使其没有任何停
顿（所谓停顿就是完全空闲的发射周期）、消除循环开销指令，然后重复该进程，将循环展
开10次。忽略分支延迟槽。给出两个调度表。对于每个调度而言，结果向量中每个元素的
执行时间为多少？每个调度中，所使用的操作槽占多大比例？两种调度中的代码相差多少？
两种调度的总共需要多少寄存器？
3.15
［20/20］<3.4、3.5、3.7、3.8>在这个练习中，我们将研究 Tomasulo算法的各种变体在执行练习
3.14中的循环时的表现。功能单元（FU）如下表所述。
功能单元类型
EX中的循环数
整数
1
浮点加法器
10
浮点乘法嚣
15
功能单元数
1
1
1
保留站数
5
3
2
作出如下假设：
\begin{itemize}
    \item 功能单元未实现流水化；
    \item 功能单元之间不存在转发，结果由公共数据总线（CDB）传送；
    \item 执行级（EX）既进行有效地址计算，又进行存储器访问，以完成载人和存储指令。
\end{itemize}
因此，这个流水线为 IFAID/IS/EX/WB；
\begin{itemize}
    \item 载入指令需要一个时钟周期；
    \item 发射（IS）和写回（WB）结果级各需要一个时钟周期；
    \item 共有5个载人缓冲区槽和5个存储缓冲区槽；
    \item 假定“等于/不等于0时转移”（BNEZ）指令需要一个时钟周期；
\end{itemize}
a.［20］<3.4~3.5>对这个问题来说，使用图3-4的单发射 Tomasulo MIPS 流水线，流水线延迟如
上表所示。对于该循环的3个迭代，给出每个指令的停顿周期数以及每个指令在哪个时钟周
期中开始执行（即，进入它的第一个 EX 周期）。每个循环迭代需要多少个时钟周期？以表
格方式给出你的答案，表中应当具有以下列标头：
\begin{itemize}
    \item 迭代（循环选代数）；
    \item 指令；
    \item 发射（发射指令的周期）；
    \item 执行（执行指令的周期）；
    \item 存储器访问（访问存储器的周期）；
    \item 写 CDB（将结果写到 CDB 的周期）；
    \item 注释（对指令正在等待的事件的说明）。
\end{itemize}
在表中给出这个循环的3次迭代，可以忽略第一条指令。
b.［20］ <3.7、3.8>重复（a）部分，但这一次假定双发射 Tomasulo 算法和完全流水化的浮点单元（FPU）。
3.16 ［10］<3.4>Tomasulo的算法有以下缺点：每个CDB每个时钟周期仅能计算一个结果。使用上一
IUSI CUIWEI以
1 1
个问题的硬件配置与延迟，并找出一段不超过10 个指令的代码序列，其中 Tomasulo 算法必须
因为 CDB争用而停顿。在序列中指出发生这一停顿的位置。
3.17
［20］<3.3>（m, n）相关分支预测器利用最近执行的m个分支的行为从 2“个预测器中作出选择，这
些预测器都是n位预测器。两级局部预测器以类似方式工作，但仅跟踪每个独立分支过去的行
为来预测未来的行为。
这些预测器中涉及一种设计折中：相关预测器几乎不需要存储器来进行历史记录，使它们能够
针对大量独立分支来维持2位预测器（降低了分支指令重复利用同一预测器的概率），而本地
预测器则需要相当多的存储器来记录历史，因此只能跟踪较少数量的分支指令。对于这一练习
来说，考虑一个（1，2）相关预测器，它可以根据4个分支（需要16位），而一个（1，2）局
部预测器使用相同数量的存储器只能跟踪两个分支。对于下面的分支结果，提供每次预测、用
于作出预测的表项以及根据预测结果对表的更新，还有每个预测器的最终错误预测率。假定到
这一点的所有分支都已经选定。如下表所示对预测器进行初始化。
相关预测髒
项
目
分
支
上一个结果
T
NT
T
NT
T
NT
T
NT
258
项
7
局部预测醬
目
分
支
0
2
6
7
0
0
1
3
3
前两个结果（右边的是最近的）
TT
T,NT
NT,T
NT
TT
TNT
NT,T
NT,NT
0
0
1
1
分支PC（字地址）
454
543
777
543
777
454
777
454
543
输
预
測
T（一次错误预测）
NT
NT
亇
T
T
NT（一次错误预测）
NT
预测
T〔一次错误预测）
NT
NT
T
T
T（一次错误预测）
NT
NT
出
T
NT
NT
NT
NT
T
NT
T
T
..
174
3.19
259
㓁。干
【10］<3.9>假定有一个深度流水线处理器，为其实现分支目标缓冲区，仅用于条件分支。假定错
误预测的代价都是4个周期，缓冲缺失代价都是3个周期，假定命中率为90%、准确率为90%、
分支频率为15%。与分支代价固定为两个周期的处理器相比，采用这一分支目标缓冲区的处理
器要快多少？假定每条指令的时钟周期数（CPI）为基本CPI，没有分支停顿。
［10/5］<3.9>考虑分支目标缓冲区，正确条件分支预测、错误预测和缓存缺失的代价分别为0、2
和2个时钟周期。考虑一种区分条件与无条件分支的分支目标缓冲区设计，而条件分支存储目
标地址，对于无条件分支则存储目标指令。
2. ［10］<3.9>当缓冲区中发现无条件分支时，代价为多少个时钟周期？
b.［10］<3.9>判断对于无条件分支进行分支折合所获得的改进。假定命中率为90%，无条件分支
频率为 5%，缓冲区缺失的代价为两个时钟周期。这样可以获得多少改进？对于这一改进来
说，必须达到多高的命中率才能提供性能增益？