\chapter{量化设计与分析基础}
个人计算机是人类迄今创造的最强大工具，我认为这种说法
并无偏颇。它们是通信工具，是创造工具，是可以由用户定制的
工具。
—比尔盖茨，
2004年2月24日

\section{引言}
自从第一台通用电子计算机问世以来，计算机技术在大约65年间取得了令人难以置信的发
展。今天，花费不到500美元购买的一台便携计算机，在性能、主存储器和磁盘存储方面都要
优于 1985年花费100万美元购买的计算机。这种快速发展既得益于计算机生产技术的发展，也
得益于计算机设计的创新。

生产技术的进步一直都相当稳定，而计算机体系结构的改进对这一快速发展的贡献就远没
有那么稳定了。在电子计算机前 25年的发展中，这两种力量都作出了巨大贡献，使计算机的性
能每年提高大约25\%。20世纪70年代后期出现了微处理器。依靠集成电路技术的进步，微处
理器也使计算机性能进入快速发展期—每年大约增长35\%。

这种高增长速度，再加上微处理器大量生产带来的成本优势，提高了微处理器业务在计算
机行业内所占的份额。另外，计算机市场的两个重大变化也使新体系结构更容易在商业上获得
成功。第一个重大变化是人们几乎不再使用汇编语言进行编程，从而降低了对目标代码兼容性
的要求。第二个重大变化是出现了独立于厂商的标准化操作系统（比如 UNIX 和它的克隆版本
Linux），降低了引人新体系结构的成本和风险。

正是由于这些变化，人们才有可能在20世纪80年代早期成功地开发了一组指令更为简单的
新体系结构—RISC（精简指令集计算机）体系结构。设计人员在设计 RISC计算机时，将主要
精力投注在两种关键的性能技术上，即指令级并行的开发（最初是通过流水线，后来是通过多指
令发射）和缓存的使用（最初采用一些很简单的形式，后来使用了更为复杂的组织与优化方式）。

基于 RISC的计算机抬高了性能指标，过去的体系结构要么快速跟上，要么就被淘汰。Digital
Bquipment Vax 未能跟上时代的脚步，所以被一种 RISC体系结构替代。Intel 则接受挑战，主要
是在内部将80x86指令转换为类似于 RISC的指令，使它能够采用许多最初由 RISC设计得导的
新技术。20世纪90年代后期，晶体管的数目飞速增长，所以在转换更复杂x86体系结构时的硬
件开销可以忽略不计。在低端应用中，比如在手机中，由于x86转换开销所带来的功耗与硅面
积成本，促使一种 RISC体系结构逐渐成为主流，这就是 ARM。

图1-1表明，体系结构与组织方式的发展起促成了计算机性能以超过50\%的年增长率持
续增长17年，这一速率在计算机行业内是空前的。

20世纪的这一飞速发展共有四重效果。第一，它显著增强了可供计算机用户使用的功能。
对许多应用来说，当今性能最高的微处理器比不到10年前的超级计算机还要优秀。

第二，性价比的这种大幅提高导致了新型计算机的出现。20世纪80年代出现了个人计算
机和工作站，这是因为有微处理器可供使用。在刚刚过去的10年里，人们见证了智能手机和平
板电脑的崛起，许多人把它们作为自己的主要计算平台，代替了个人计算机。这些移动客户端
设备越来越多地通过因特网来访问包含数万个服务器的仓库，这些仓库的设计使它们看起来就
像单个巨型计算机一样。

第三，根据摩尔定律的预测，半导体制造业的持续发展已经使基于微处理器的计算机在整
个计算机设计领域中占据了主导地位。传统上使用现成逻辑电路或门阵列制造的小型机已经被
使用微处理器制造的服务器所取代，甚至大型计算机和高性能的超级计算机也都是由微处理器
组合而成。

\begin{figure}[!htb]
    \centering
	\includegraphics[width=0.7\textwidth]{imgs/sam.png}
	\caption{自20世纪70年代后期以来处理器性能的增长。这个图表绘制了相对于 VAX 11/780 的性能曲线，
            测试数据由SPEC 基准测试测得（见1.8节）。在20世纪80年代中期之前，处理器性能的增长主
            要由技术驱动，平均大约每年增长25\%。在此之后的年增长速度为大约52\%，这一高速增长应当
            归功于更高级的体系结构和组织思想。这样持续发展到2003年时，如果一直以25\%的速度增长，
            处理器性能要比实际性能低25倍。2003年之后，功耗和可用指令级并行的限制减慢了单核处理
            器性能的增长速度，年增长速度不超过22\%，到2010年，如果仍然保持每年52\%的增长速度，
            处理器性能要比实际性能高出大约5倍。（从2007年起，单个芯片上的核心数目每年都在增加，
            最快速的SPEC性能测试已经启用了自动并行，所以很难再测试单核处理器的速率。这些结果仅
            限于单套接字系统，以降低自动并行造成的影响。）图1-4给出了时钟速率在上述三个时期的增长
            速度。由于 SPEC这些年也发生了变化，所以在评估新机器的性能时，对测试数据进行了換算，
            换算因数与两种不同SPEC版本（比如SPEC89、SPEC92、SPEC95、SPEC2000和 SPEC2006）的
            性能有关}
\end{figure}

硬件方面的上述创新导致了计算机设计的复兴，既强调体系结构方面的创新，也重视技术
改进的高效运用。实际增长速度中已经包含了这两方面的因素，所以到2003年，高性能微处理
器大约要比仅依靠技术改进（包含电路设计的改进）快7.5倍；实际年增长速度为52\%，仅依
靠技术改进的年增长速度为35\%。

这一硬件复兴还有第四个影响，那就是对软件开发的影响。自 1978年以来，硬件性能提高
了25 000倍（见图1-1），这样就允许今天的程序员以性能换取生产效率。今天，绝大多数的编
程是使用诸如Java 和\verb|C#|之类的托管编程语言来完成的，代替了以提高性能为目的的C语言和
C++语言。此外，Python 和Ruby 之类的脚本语言（它们的生产效率可能更高），连同Ruby Rails
之类的编程框架，也正在日益普及。为了保持生产效率并尝试缩小性能差距，采用即时
（Just-In-Time）编译器和跟踪编译（Trace-based Compiling）的解释器正在取代过去的传统编译
器和链接器。软件部署也在发生变化，因特网上使用的“软件即服务”（Software as a Service，
Saas）取代了必须在本地计算机上安装和运行的盒装光盘套装（shink-wrapped）软件。

应用程序的本质也在变化。语言、音效、图像、视频正在变得愈加重要，响应时间对于提
供良好的用户体验非常关键，使其保持在可预测范围之内也同样变得愈加重要。Google Goggles
就是一个激动人心的例子。当用户拿起手机，把手机上的镜头对准物体时，这个应用程序可以
通过因特网将图像无线传送到一个仓库级计算机（warechouse-scale computer）上，这个计算机
会识别物体，告诉用户它的一些有趣信息。它可以将物体上的文字翻译为另一种语言；读取书
籍封面上的条码，告诉用户这本书在网上是否有售，价格多少；或者，如果用户播动镜头，拍
摄周围的全景，它还会告诉用户附近有什么商店以及它们的网站、电话号码和方位。

遗憾的是，图1-1还表明这一长达17年的硬件复兴结束了。从2003年开始，由于风冷芯
片最大功耗和无法有效地开发更多指令级并行这两大李生瓶颈，单处理器的性能提高速度下降
到每年不足22\%。事实上，Intel 在2004年取消了自己的高性能单核处理器项目，转而和其他公
司一起宣布：为了获得更高性能的处理器，应当提高一个芯片上集成的核心数目，而不是加快
单核处理器的速度。

这是一个标志着历史性转折的里程碑信号，处理器性能的提高从单纯依赖指令级并行（ILP）
转向数据级并行（DLP）和线程级并行（TLP），ILP是本书前三个版本的重点，第4版开始
重点介绍 DLP 和 TLP，第5版进一步加以扩展。这一版还增加了仓库级计算机和请求级井行
（RLP）的内容。编译器和硬件都是隐式开发IP的，不会引起程序员的注意，而DLP、TLP 和
RLP则是显式并行的，需要调整应用程序的结构才能开发显式并行。在某些情况下，这一调整
比较容易，但在大多数情况下，它会成为程序员的主要新增负担。

本书主要讨论使上世纪飞速增长成为可能的体系结构思想和相关的编译器改进、这些急剧
变化的原因，以及21世纪体系结构思想、编译器和解释器面对的挑战和一些富有前景的方法。
本书的核心内容是一种量化的计算机设计与分析方法，所采用的工具是对程序的经验观察、试
验和模拟。本书中就反映了这种计算机设计风格与方法。本章的目的是为后续各章及附录奠定
量化基础。

编写本书的目的不只是为了解释这种设计风格，还希望激励读者为这一进程作出贡献。这
种量化方法对过去的隐式并行计算机是有效的，我们相信这种方法对未来的显式并行计算机也
同样有效。

\section{计算机的分类}
由于上述变化，我们在新世纪里看待计算、计算应用程序和计算机市场的观点也发生了巨
大变化。自个人计算机诞生以来，我们还没有见到过计算机在外观和操作方式上发生如此之大
的变化。计算机使用方式的变化推动形成了种不同的计算市场，每一种都有自己不同的应用、
需求和计算技术。表1-1总结了主流计算环境及其重要特征。
\begin{table}[]
    % \tiny
    \scriptsize
    \centering
    \begin{tabular}{C{0.09\textwidth}|C{0.15\textwidth}|C{0.15\textwidth}|C{0.15\textwidth}|C{0.15\textwidth}|C{0.15\textwidth}}
        \hline
        特征    & 个人移动设备（PMD）    & 台式机   & 服务器     & 集群/仓库级计算机   & 嵌入式     \\ \hline
        系統价格  & 100$\sim$1000美元     & 300$\sim$2500 美元     & 5000$\sim$10000000美元 & 100000$\sim$200000000美元 & 10$\sim$100000美元   \\ \hline
        微处理器价格    & 10 $\sim$100美元    & 50 $\sim$500美元    & 200 $\sim$2000美元     & 50 $\sim$250美元     & 0.01$\sim$100美元   \\ \hline
        关键的系统设计问题 & 成本，能耗，媒体性能，响应率 & 性价比，能耗，图形性能 & 吞吐量，可用性可扩展性，能耗      & 性价比，吞吐量，能耗均衡性  & 价格，能耗，应用的特有性能 \\ \hline
    \end{tabular}
    \caption{*2010年的销售量包括大约18化个PMD（90\%为手机）、3.5亿个台式PC和2000万个服务器。嵌入或处理器的总销
        售量接近190亿。2010年共交付了61亿个基于 ARM拉术的芯片。注意服务器和嵌入器系純的系統价格跨度极大，
        包含了从USB 密钥到网络路由器在内的各种设备。对于服务器，这一变化范国主要是因汋需要超大規模多处理器系
        统来完成高端事务处理。}
\end{table}

\subsection{个人移动设备}
个人移动设备（PMD）是指一类带有多媒体用户界面的无线设备，比如手机、平板电脑
等。由于整个产品的零售价格为数百美元，所以成本成为一个关键因素。尽管经常会因为使用
电池而需要强调能效，但由于需要使用相对便宜的外壳（由塑料或陶瓷制成），而且缺少冷却风
扇，所以也限制了总功耗。我们将在1.5节更详细地研究能耗和功率。PMD上的应用程序经常
是基于 Web 应用、面向媒体的，比如上面提到的Google Goggles。能耗与尺寸要求决定了要采
用闪存而不是磁盘来作为存储方式（第2章）。

响应性能和可预测性能是多媒体应用程序的关键特性。实时性能需求是指应用程序的一个
程序段有一个确定的最大执行时间。例如，在 PMID上播放一段视频时，由于处理器必须在短
时间内接收和处理下一个视频帧，所以对每个视频帧的处理时间是有限的。某些应用程序中还
有一个更具体的需求：当超出某一最大时间时，会限制一项特定任务的平均时间和实例数目。
如果仅仅是偶尔违反一个事件的时间约束条件（而非过多地发生这种情况），就可以采用有时被
称为软实时的方法。实时性能往往严重依赖于具体的应用程序。

许多 PMD 应用程序中还有其他一些关键特性：需要将存储器占用减至最少，需要高效利
用能量。电池容量和散热问题都需要提高能耗效率。存储器可能在系统成本中占有很大的比例，
在这种情况下，存储器优化是非常重要的。由于应用程序已经决定了数据规模，所以重视存储
器用量其实就是要重视代码规模。

\subsection{桌面计算}
以资金而论，一级市场（可能仍然是最大的市场）是桌面计算市场。桌面计算覆盖了从低
端到高端的整个产品范围，既有售价不到300美元的低端上网本，也有售价可能达2500美元的
高端高配工作站。从2008年开始，每年生产的桌面计算机中有一半以上是由电池供电的笔记本
计算机。

在整个价格与性能范围内，桌面计算机市场都有优化性价比的趋势。系统的性能（主要以
计算性能和图形性能来衡量）和价格对这个市场中的客户来说是最重要的，因此对计算机架构
师也是最重要的。结果，最新、最高性能的微处理器和低成本微处理器经常首先出现
桌面系统中。（1.6节讨论了影响计算机成本的问题。）

尽管以Web 为中心的互动应用日益增多，为性能评估带来了新的挑战，但根据应
测试还是能够较好地刻画桌面计算的特征。

\subsection{服务器}
自20世纪80年代开始转向桌面计算机以来，服务器的角色逐渐变为提供更大规模、更可
靠的文件和计算服务。这些服务器已经代替传统的大型机，成为大规模企业计算的中枢。

对服务器而言，所强调的特征不同于桌面计算机。首先，可用性是至关重要的。（我们将在
1.7节讨论可用性。）考虑一下运行银行 ATM机或者航班订票系统的服务器。由于这些服务器必
须每周7天、每天24小时不间断工作，所以此类服务器系统发生故障时产生的灾难性后果要远
比单个桌面计算机故障严重。表1-2估算了服务器应用程序因宕机所造成的收益成本。

服务器系统的第二个关键特征是可扩展性。服务器系统经常需要扩展，以满足其所支持服
务的增长需求，或者对功能的增长需求。因此，服务器扩展计算容量、内存、存储器和 I/O带
宽的能力极为重要。

最后一个特征，服务器的设计应使其具有很高的吞吐能力。也就是说，服务器的整体性能
（每分钟处理的事务数或者每秒提供的网页数）才是最重要的。尽管对单个请求的响应速度依然
重要，但总体效率和成本效益（由单位时间内能够处理的请求数决定）才是大多数服务器的关
键度量。我们将在1.8节再来讨论如何评估不同计算环境类型的性能问题。

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[]
    \centering
    \caption{假定有3种不同可用性级别且宕机时间均匀分布，通过分析宕机成本（直接收入损失），给出由于
            系统不可用而带来的成本（四含五入至10万美元）}
    \begin{tabular}{|c|c|ccc|}
    \hline
    \multirow{2}{*}{应用程序} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}每 ⼩ 时 的 宕 机 成 本\\ （ 千 美 元 ）\end{tabular}} & \multicolumn{3}{c|}{不同宕机率造成的年度亏换（百万美元）}                                                                                                                                                                                    \\ \cline{3-5} 
                        &                                                                                      & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}1\%\\ （87.6小时/年）\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}0.5\%\\ （43.6小时/年）\end{tabular}} & \begin{tabular}[c]{@{}c@{}}0.\%\\ （8.8小时/年）\end{tabular} \\ \hline
    经纪业务                  & 6450                                                                                 & \multicolumn{1}{c|}{565}                                                      & \multicolumn{1}{c|}{283}                                                        & 56.5                                                     \\ \hline
    信用卡授权                 & 2600                                                                                 & \multicolumn{1}{c|}{228}                                                      & \multicolumn{1}{c|}{114}                                                        & 22.8                                                     \\ \hline
    包裹运输服务                & 150                                                                                  & \multicolumn{1}{c|}{13}                                                       & \multicolumn{1}{c|}{6.6}                                                        & 1.3                                                      \\ \hline
    家庭购物频道                & 113                                                                                  & \multicolumn{1}{c|}{9.9}                                                      & \multicolumn{1}{c|}{4.9}                                                        & 1.0                                                      \\ \hline
    目录销售中心                & 90                                                                                   & \multicolumn{1}{c|}{7.9}                                                      & \multicolumn{1}{c|}{3.9}                                                        & 0.8                                                      \\ \hline
    航空订票中心                & 89                                                                                   & \multicolumn{1}{c|}{7.9}                                                      & \multicolumn{1}{c|}{3.9}                                                        & 0.8                                                      \\ \hline
    手机服务激活                & 41                                                                                   & \multicolumn{1}{c|}{3.6}                                                      & \multicolumn{1}{c|}{1.8}                                                        & 0.4                                                      \\ \hline
    网络在线费用                & 25                                                                                   & \multicolumn{1}{c|}{2.2}                                                      & \multicolumn{1}{c|}{1.1}                                                        & 0.2                                                      \\ \hline
    ATM服务费                & 14                                                                                   & \multicolumn{1}{c|}{1.2}                                                      & \multicolumn{1}{c|}{0.6}                                                        & 0.1                                                      \\ \hline
    \end{tabular}
\end{table}

* 数据来源：Kemiel［2000］，由 Contingency Plaming Research 收集、分析。


\subsection{集群/仓库级计算机}
软件即服务（Saas）应用（比如搜索、社交网络、视频分享、多人游戏、在线销售等）的
发展已经推动了一类被称为集群的计算机的发展。集群是指一组桌面计算机或服舒器通过局域
网连接在一起，运转方式类似于一个更大型的计算机。每个节点都运行自己的操作系统，节点
之间使用网络协议进行通信。最大规模的集群称为仓库级计算机（WSC），它们的设计方式使
数万个服务器像一个服务器一样运行。第6章详细介绍了这类超大型计算机。

WSC是如此之大，因而性价比和功耗非常关键。第6 章将解释一一个价值9000万美元的仓
库级计算机，其成本中有80\%与计算机内部的功耗和冷却技术有关。这些计算机本身和网络设
备另外需要7000万美元，每隔几年就必须更换一次。在购买这样大规模的计算设备时，一定
要非常精明，因为性价比提高10\%就意味着可以节省700万美元（7000万美元的10\%）。

WSC与服务器的相通之处在于它们都非常看重可用性。例如，Amazon.com 在2010年第四
季度的销售额为130亿美元。一个季度大约有2200个小时，每小时的平均收入差不多是600万
美元。在圣诞节购物的高峰时间，潜在损失可能要多出许多倍。第6章将会解释，WSC与服务
器的区别在于，WSC以很多廉价组件为构建模块，依靠软件层来捕获和隔离在这一级别进行计
算时发生的许多故障。注意，WSC的可扩展性是由连接这些计算机的局域网实现的，而不是像
服务器那样，通过集成计算机硬件来实现。

超级计算机与 WSC的相通之处在于它们都非常昂贵，需要花费数千万美元，但超级计算
机的不同之处在于它强调浮点性能，会运行大型的、通信密集的批程序，这些程序可能会一次
运行几个星期。这种紧耦合性决定了超级计算级要使用非常快速的内部网络。而WSC则不同，
它重视互动应用程序、大规模存储、可靠性和很高的因特网带宽。

\subsection{嵌入式计算机}
嵌人式计算机在日用电器中随处可见。微波炉、洗衣机、大多数打印机、大多数网络交换
机和所有汽车中都有简单的嵌入式微处理器。

PMID 中的处理器经常被看作是嵌入式计算机，但我们仍然把它们看作一个不同类别，这是
因为 PMD 是一些可以运行外部开发软件的平台，它们与桌面计算机有许多共同特征。其他嵌
入式设备在硬件和软件复杂性方面都有很大的限制。我们以能否运行第三方软件作为区分嵌人
式和非嵌入式计算机的分界线。

嵌入式计算机的处理能力和成本差别最大。它们既包括只需要0.1美元的8位和16位处理
器，也有可以每秒执行1亿条指令、价格低于5美元的32位微处理器，还有用于网络交换机的
高端处理器，它们的售价高达100美元，每秒可以执行数十亿条指令。尽管嵌人式计算市场中
的计算能力相差很大，但价格仍然是此类计算机设计的关键因素。性能要求当然是的确存在的，
但主要目标通常是以最低价格满足性能需要，而不是以更高的价格来获得更高的性能。

本书的大多数内容适用于嵌入式处理器的设计、使用和性能，无论是现成的微处理器，还
是与其他专用硬件组装在一起的微处理器核心，都是适用的。实际上，本书第3版还包含了一
些嵌人式计算示例，用来演示每章的思想。

遗憾的是，大多数读者对第3版中的示例感到不满意，这是因为计算机的量化设计与评估
需要数据来推动，而嵌人计算领域的相关数据还不够充足（参见1.8 节中EEMBC的挑战）。因
此，我们现在只给出定性描述，这种方式与本书其余部分不是特别一致。有鉴于此，在上一版
和这一版中，我们将嵌入计算机的相关材料合并到附录E中。我们认为把它们放在一个单独的
附录中，既便于在正文中流畅地表达思想，又可以让读者了解这些不同需求是如何影响嵌人式
计算的。

\subsection{并行度与并行体系结构的分类}
在所有4个计算机类别中，多种级别的并行度现在已经成为计算机设计的推动力量，而能
耗和成本则是主要约束条件。应用程序中主要有以下两种并行。

\begin{enumerate}
    \item \textbf{数据级并行（DLP）}，它的出现是因为可以同时操作许多数据项。
    \item \textbf{任务级并行（TLP）}，它的出现是因为创建了一些能够单独处理但大量采用并行方式执
    行的工作任务。
\end{enumerate}

计算机硬件又以如下4种主要方式来开发这两种类型的应用并行。

\begin{enumerate}
    \item 指令级并行在编译器的帮助下，利用流水线之类的思想适度开发数据级并行，利用推理
    执行之类的思想以中等水平开发数据级并行。
    \item 向量体系结构和图形处理（GPU）将单条指令并行应用于一个数据集，以开发数据级
    并行。
    \item 线程级并行在一种紧耦合硬件模型中开发数据级并行或任务级并行，这种模型允许在并
    行线程之间进行交互。
    \item 请求级并行在程序员或操作系统指定的大量去耦合任务之间开发并行。
\end{enumerate}

硬件支持数据级并行和任务级并行的这4种方式可以追溯到50年前。Michael Flynn ［1966］
在20世纪60年代研究并行计算工作量时，提出了一种简单的分类方式，我们今天仍在使用这
种分类的缩。他研究了多处理器最受约束组件中的指令流及数据流的并行，并据此将所有计
算机分为以下4类。

\begin{enumerate}
    \item \textbf{单指令流、单数据流（SISD）}：这个类别是单处理器。程序员把它看作标准的顺序计算
    机，但可以利用指令级并行。第3章介绍了采用 ILP技术（比如超标量和推理执行）的SISD体
    系结构。
    \item \textbf{单指令流、多数据流（SIMD）}：同一指令由多个使用不同数据流的处理器执行。SIMD
    计算机开发数据级并行，对多个数据项并行执行相同操作。每个处理器都有自己的数据存储器
    （也就是 SIMD 中的 MID），但只有一个指令存储器和控制处理器，用来提取和分派指令。第4
    章介绍 DLP和3种开发 DLP的不同体系结构：向量体系结构、标准指令集的多媒体扩展、GPU。
    \item \textbf{多指令流、单数据流（MIISD}）：到目前为止，还没有这种类型的商用多处理器，但包含
    这种类型之后，这种简单的分类方式变得更完整。
    \item \textbf{多指令流、多数据流（MIMID}）：每个处理器都提取自己的指令，对自己的数据进行操
    作，它针对的是任务级并行。一般来说，MIIMD 要比 SIMD更灵活，所以适用性也更强，但它
    要比 SIMD更贵一些。例如，MIMD 计算还能开发数据级并行，当然，其开销可能要比SIMD
    处理器高一些。这种开销是指粒度大小要足够大，以便高效地开发并行度。第5 章介绍紧耦合
    MIMD 体系结构，由于多个互相协作的线程是并行操作的，所以它开发了线程级井行。第6章
    介绍开发请求级并行的松耦合 MIMD 体系结构（具体来说，就是集群和仓库级计算器），在这
    种情况下，可以很自然地并行执行许多独立任务，几乎不需要通信和同步。
\end{enumerate}

这种分类模型很粗略，许多并行处理器是 SISD、SIMD 和 MIMD 的混合类型。不过，我们
可以用它为本书将要介绍的计算机设计空间设定一个框架。

\section{计算机体系结构的定义}

计算机设计人员面对的是一个非常复杂的任务：判断哪些属性对于种新计算机来说是至
关重要的，然后在设计这种计算机时使其性能和能耗效益达到最佳，同时还要满足成本、功耗
和可用性约束条件。这项任务包括许多方面：指令集设计、功能组织、逻辑设计、实现方式。
实现方式可能包括集成电路设计、包装、电池和冷却。为使设计方案达到最优效果，设计人员
需要熟悉从编译器、操作系统到逻辑设计与包装等广泛技术。

几年前，计算机体系结构一词通常仅包括指令集设计。计算机设计的其他方面称为实现，
言下之意通常就是实现方式不太重要，或者说没有什么挑战性。

我们认为这种观点是错误的。架构师的工作远不止指令集设计一项，在项目其他方面遇到
的技术障碍很可能比指令集设计中遇到的障碍更具挑战性。在介绍计算机架构师的更多挑战之
前，先来快速回顾一下指令集体系结构。

\subsection{指令集体系结构：计算机体系结构的近距离审视}
我们在本书中用指令集体系结构（ISA）一词来指代程序员可以看到的实际指令集。ISA的
作用相当于区分软件和硬件的界限。在下面对ISA 的快速回顾中，将使用80x86、ARM 和 MIPS
的例子从7个方面来介绍ISA。附录A和附录K更详细地介绍了这3种ISA。

\begin{enumerate}
    \item ISA分类。现今几乎所有的ISA 都划分到通用寄存器体系结构中，在这种体系结构中，
    操作数或者是寄存器，或者是存储器地址。80x86有16个通用寄存器和16个通常存入浮点数据
    的寄存器，而 MIPS 则有32个通用寄存器和32个浮点寄存器（见表1-3）。这一类别有两种
    主流版本，一种是寄存器-存储器ISA，比如80x86，可以在许多措令中访问存储器；另一种
    是载入-存储ISA，比如ARM 和MIPS，它们只能用载人或存储指令来访问存储器。所有最新
    ISA 都采用载入-存储版本。
    \item 存储器寻址。几乎所有桌面计算机和服务器计算机（包括80x86、ARM 和 MIPS）都使
    用字节寻址来访问存储器操作数。有些体系结构（像 ARM和 MIPS）要求操作对象必须是对齐
    的。一个大小为s的对象，其字节地址为A，如果Amods=0，则对这个对象的访问是对齐的。
    80x86（见附录图 A-2）不需要对齐，但如果操作数是对齐的，访问速度通常会更快一些。
    \item 寻址模式。除了指定寄存器和常量操作数之外，寻址模式还指定了一个存储器对象的地
    址。MIPS 寻址模式为：寄存器（寻址）、立即数（寻址）和位移量（寻址）。立即数寻址用于常
    数寻址，在位移量寻址模式中，将一个固定偏移量加到寄存器，得出存储器地址。80x86 支持
    上述3种模式，再加上位移量的3种变化形式，即：无寄存器（绝对数）、两个寄存器（用位移
    量进行基址寻址）、两个寄存器，其中一个寄存器的内容乘以操作数的字节大小——用比例索引
    和位移量进行变址寻址。它与上述3种寻址方式类似，只是要减去位移量字段，加上寄存器间
    接寻址、基址寻址和变址寻址。ARM 拥有3种 MIIPS 寻址模式再加上相对 PC（程序计数器）
    的寻址方式、两个寄存器之和，还有一种方式也是两个寄存器之和，但其中一个寄存器的内容
    要乘以操作数的字节大小。它还有自动递增寻址和自动递减寻址：计算得到的地址会被放在用
    于构造该地址的一个寄存器中，替代其中的内容。
    \item 操作数的类型和大小。和大多数ISA类似，80x86、ARM和 MIPS 支持的操作数大小为
    8位（ASCII字符）、16位（Unicode 字符或半个字）、32位（整数或字）、64位（双学或长整型）
    以及 IEEE 754浮点数，包括32位（单精度）和64位（双精度）。80x86还支持80位浮点（扩
    展双精度）。
    \item 操作指令。常见的操作类别为：数据传输指令、算术逻辑指令、控制指令（下面进行讨
    论）和浮点指令。MIPS 是一种简单的、易于实现流水化的指令集体系结构，它是2011年采用
    RISC体系结构的代表。表1-4总结了 MIPS ISA。80x86 的操作指令集要丰富得多，大得多（参
    见附录K）。
    \item 控制流指令。几乎所有ISA，包括上述三种在内，都支持条件转移、无条件跳转、过程
    调用和返回。所有这三种都使用相对于PC的寻址方式，其中的分支地址由一个地址字段指定，
    该地址将被加到 PC。这三种 ISA 之间有一些微小的区别。MIPS 条件分支（BE、BNE等）检验
    寄存器中的内容，而80x86 和 ARM分支测试条件代码位，这些位是在执行算术/逻辑运算时顺
    带置位的。ARM和 MIPS 过程调用将返回地址放在一个寄存器中，而80x86调用（CALLF）将返
    回地址放在存储器中的一个栈内。
    \item ISA 的编码。有两种基本的编码选择：固定长度和可变长度。所有ARM和 MIPS 指令
    的长度都是32位，从而简化了指令译码。图1-2给出了 MIPS指令格式。80x86编码为可变长
    度，变化范围为1~18个字节。与固定长度的指令相比，可变长度的指令可以占用较少的空间，
    所以为80x86编译的程序通常要小于为 MIIPS 编译的相同程序。注意，上面提到的编码选择会
    影响将指令转换为二进制编码的方式。例如，由于寄存器字段和寻址模式字段可以在一条指令
    中出现许多次，所以寄存器的数目和寻址模式的数目都对指令的大小具有显著影响。（注意，
    ARM 和 MIIPS 后来都进行了扩展，支持长16位的指令，以便缩小程序规模，这两种扩展分别
    叫做 Thurb 或 Thumb-2、MIPS16）
\end{enumerate}

\begin{table}[]
    \centering
    \caption{MIPS寄存暑和使用规范}
    \begin{tabular}{|c|c|c|c|}
    \hline
    名称             & 编号  & 用途         & 在调用之间是否保留 \\ \hline
    \verb|$zero|    & 0     & 常量值O                   & 不可用 \\ \hline
    \verb|$at|      & 1     & 为汇编程序保存的临时寄存器    & 否 \\ \hline
    \verb|$v0-$v1|  & 2~3   & 函数返回值和表达式计算结果的值 & 否 \\ \hline
    \verb|$a0-$a3|  & 4~7   & 实参                      & 否 \\ \hline
    \verb|$t0-$t7|  & 8~15  & 临时变量                   & 否 \\ \hline
    \verb|$s0-$s7|  & 16~23 & 已保存的临时变量            & 是 \\ \hline
    \verb|$t8-$t9|  & 24~25 & 临时变量                   & 否 \\ \hline
    \verb|$K0-$k1|  & 26~27 & 沟操作系統内核保留          & 否 \\ \hline
    \verb|$gp|      & 28    & 全局指针                  & 是 \\ \hline
    \verb|$sp|      & 29    & 栈指针                    & 是 \\ \hline
    \verb|$fp|      & 30    & 帧指针                    & 是 \\ \hline
    \verb|$ra|      & 31    & 返回地址                  & 是 \\ \hline
    \end{tabular}
\end{table}
\begin{verbatim}
    *除了32个通用寄存器（RO-R31）之外，MIPS 还有32 个浮，点寄存器（FO-F31），可以保存一个32 位单精度教或一
    个64位双精度数。
\end{verbatim}

\begin{verbatim}
    表1-4 MIPS64 中的部分指令
    指令类型/操作码
    数据传输
    LB、LBU、SB
    LH、LHU、SH
    LALHUSW
    LD、SD
    L.S.L.D、S.S、S.D
    MFCO、MTCO
    HOV.S、MDV.D
    MFC1、MTCL
    算术/逻辑
    DADD、DADDI、DADOU、DADDTU
    DSUB、DSUBU
    CMUL、DMULU、DOIV、 DDIVU、MADD
    AND、ANDI
    OR、ORI、XOR、XORI
    LUI
    DSLL、 DSRL、DSRA、DSLLY、DSRLV、
    DSRAV
    SLT、SLTI、SLTU.SLTIU
    控制
    BEQZ、BNEZ
    BEQ、BNE
    BCIT、BCIF
    MOVN、MOVZ
    J、JR
    指令含义
    在奇存册和存储器之间，或者在整数和FP或特珠寄存器之间移动数据：唯一的存
    储器寻址樸式是16位位移量加上GPR的内容
    载入字节、载人无符号字节、存储字节（至/自整数寄存器）
    载人半字、载入无符号半字、存储半字（至/自鳖数寄存器）
    载人字、载人无符号字、存储字（至/自整数寄存器）
    载人双字、存储双字（至/自整数寄存器）
    载人SP浮点、载入DP浮点、存储SP浮点、存储DP浮点
    在GPR与特殊寄存器之间复制数据
    将一个SP或DPFP寄存器复制到另一个FP寄存器
    在FP寄存器与整数寄存器之间复制132位
    对GPR中的整数或逻辑数据进行操作：带符号算术运算溢出时进行陷阱捕获
    加，加立即数（所有立即数为16位），有符号和无符号
    减，有符号和无符号
    乘和除，有符号和无符号，乘-加；所有运算的操作数和结果都是64位数值
    与，和立即数相与
    或，和立即数求或，异或，和立即数求异或
    载入高位立即数：将立即数载人到寄存器的32~47位，然后进行符号扩展
    移位：立即数形式（DS_）和变量形式（DS_V），移位为左逻辑移位、右涩辑移
    位、右算术移位
    若小于操作数则置位、若小于立即数则置位、有符号和无符号
    控制分支和迷转，相对于PC寄存晋或通过寄存器控制
    GPR等于/不等于0时转移、相对于PC+4偏移16位偏移量
    GPR相等/不相等时转移、相对于PC+4转移16位偏移
    测试FP状态寄存器中的对比位，并转移：相对于PC+4转移16位偏移量
    如果第三个GPR为负数/零，则将第一个GPR复制到第二个GPR
    眺转至与PC+4偏移26位偏移量的位置（J）、眺转至寄存器中的目标位置（JR）
    （续）
    指令类型/操作码
    指令含义
    JAL、JALR
    眺转和链接：将PC+4保存在R31中，目标为相对于PC（JAL）或寄存器（JALR）
    TRAP
    转移到操作系统的一个向量地址
    ERET
    从异常中返回用户代码，恢复用户模式
    浮点
    对DP和SP格式执行FP操作
    AD0.D、ADD.S、ADD.PS
    DP、SP数相加，一对SP数相加
    SUB.D、SUB.S.SUB.PS
    DP、SP数相减，一对SP数相减
    MUL.D、MUL.S、MUL.PS
    DP、SP浮点数相乘，一对SP数相乘
    MADD.D、MADD.S、MADD.PS
    DP、SP浮点数相乘加，一对SP數相乘加
    DIV.D、DIV.S、DIV.PS
    DP、SP浮点数相除，一对SP数相除
    CVT！-
    转換指令：CVT.X.y从类型x转換为类型Y，其中x和 为L（64位整数），W（32位整
    数），D（DP）或S（SP）。两个操作数都是FRP
    C.
    _.D、C._.S
    DP和SP对比：“_”=LT，GT，LE，GE，EQ,NE，在FP状态寄存器中置位
    *SP-单精度、DP-双精度附录A给出了有关 MIPS64的更多详细信您。对数据而言，最高有效位编号为0，最低有效
    位为 63。
\end{verbatim}

除了ISA设计方面的挑战之外，如果指令集之间的区别很小，如果存在不同的应用领域，
那计算机架构师面对的其他挑战将更加严重。因此，从本书上一版开始，除了这里给出的快速
回顾之外，还在附录中提供了大量有关指令集的材料（参见附录A和网站上的附录K）。

本书以 MIPS64 的于集作为ISA 的例子，是因为它既是网络领域的主导ISA，又是前面提
到的 RISC 体系结构的出色示例，ARM （Advanced RISC Machine，高级 RISC 机器）是 RISC
体系结构的最流行示例。2010年出产的芯片中有61 亿个采用了 ARM处理器，与采用80x86处
理器的芯片相比，大约是其20倍。

MIPS64 指令集体系结构格式。所有指令的长度都是32位。R格式用于整数寄存器至寄存器操作，
比如 DADDU、DSUBU等。格式1用于数据传送、分支和立即数指令，比如L.D、SD、BEQZ 和
DADDIo格式J用于跳转指令，FR格式用于浮点操作，FI格式用于浮点分支

\subsection{真正的计算机体系结构：设计满足目标和功能需求的组成和硬件}
计算机的实现包括两个方面：组成和硬件。组成一词包含了计算机设计的高阶内容，比如
存储器系统，存储器互连，设计内部处理器或CPU（中央处理器——算术、逻辑、分支和数据
输送功能都在这里实现）。有时也使用微体系结构一词来代替“组成”。例如，AMD Opteron 和
Intel Core i7 是两个指令集体系结构相同但组成不同的处理器。这两种处理器都实现x86 指令集，
但它们的流水线和缓存组成有很大不同。

由于单个微处理器上开始采用多个处理器，所以人们开始使用核心一词来称呼处理器。人
们一般不说“多处理器微处理器”，而是使用“多核”。由于现今几乎所有芯片都有多个处理器，
所以人们不怎么使用中央处理器（或CPU）一词了。

硬件是指一个计算机的具体实现，包括计算机的详尽逻辑设计和封装技术。同一系列的计
算机通常具有相同的指令集体系结构和几乎相同的组成，但在具体硬件实现方面有所不同。例
如，Intel Core i7（见第3章）和 Intel Xeon 7560（见第5章）基本相同，但提供不同的时钟速
率和不同的存储器系统，Xeon 7560更适用于服务器计算机。

在本书中，体系结构涵盖了计算机设计的所有三个方面：指令集体系结构、组成或微体系
结构、硬件。

计算机架构师设计的计算机必须满足功能需求，并达到价格、功耗、性能和可用性指标。
表1-5总结了在设计新计算机时要考虑的要求。通常，架构师还必须判断有什么样的功能要求，
其中哪一项可能是主要任务。需求可能是由市场驱动的特定功能。应用软件决定了计算机的使
用方式，从而经常会推动特定功能需求的选择。如果存在大量为一特定指令集体系结构设计的
软件，那架构师可能会决定：新计算机应当实现这种已有指令集。如果某类应用程序拥有庞大
的市场，那可能会鼓励设计人员整合一些需求，使计算机在这一市场上具有更强的竞争力。后
面章节将深入研究大量此类需求和功能。
\begin{table}[]
    % \tiny
    % \small
    \scriptsize
    \centering
    \caption{架构师面对的一些最重要功能需求汇总}
    \begin{tabular}{C{0.15\textwidth}C{0.7\textwidth}}
    \hline
    \textbf{功能需求}         & \textbf{应当具备或支持的典型特性} \\ \hline
    \textbf{应用领域}         & \textbf{计算机的目标} \\
    个人移动设备         & 一系列任务的实时性能，包括图形、视频和音频的交互性能，能效（第2、3、4、5章，附录A） \\
    通用桌面计算机         & 一系列任务的均衡性能，包括图形、视频和音频的交互性能：能效（第2、3、4、5章，附录A） \\
    服务器         & 支持数据库和事务处理，可靠性和可用性的增强，支持可伸缩性（第2、5章，附录A.D、F） \\
    集群/仓库级计算机         & 许多独立任务的吞吐量性能，存储器的纠错功能，能耗均衡（第2、6章，附录F） \\
    嵌入式计算         & 通常需要对图形或视频提供特支持（或者其他专用扩展），可能需要功耗限制和电源控制，实时約束（第2、3、5章，附录A、E） \\ \hline

    \textbf{软件兼容级别}         & \textbf{决定计算机的现有软件数目} \\
    在编程语言级别         & 对设计人员来说最为灵活，需要新编译器（第3、5章，附录A） \\
    目标代码或二进制代码兼容性         & 指令集体系结构完全确定（几乎没有灵活性），但不需要在软件或端口程序中进行投人（附录A） \\ \hline

    \textbf{操作系统需求}         & \textbf{支持选定OS所需要的特性（第2章、附录B）} \\
    地址空间的大小         & 非常重要的特性（第2章），可能会限制应用 \\
    存储器管理         & 为现在操作系统所必需，可能进行分页或分段（第2章） \\
    保护         & 不同的操作系統和应用需要：分页或分段，虚拟机（第2章） \\ \hline

    \textbf{标准}         & \textbf{市场可能要求特定的标准} \\
    浮点         & 格式和算法：IEEE 754标准（附录J），用于图形处理或信号处理的特殊算法 \\
    I/O接口         & 对于I/O设备：申行ATA，串行连接SCSI、PCI Express（附录D、F） \\
    操作系统         & UNIX, Windows、Linux,CISCO IOS \\
    网络         & 支持不同网络：以太网、Infiniband（附录F） \\
    编程语言         & 语言（ANSIC、C++、Java、Fortran）影响指令集（附录A） \\ \hline
    \end{tabular}
\end{table}
\begin{verbatim}
    *左列描述需求的类别，右列给出特定示例，还包含讨论相应主题的章节和附录。
\end{verbatim}
架构师还必须了解技术和计算机应用这两方面的重要趋势，因为这些趋势不仅会影响未来
的成本，还会影响到体系结构的寿命。
\section{技术趋势}
一种指令集体系结构要取得成功，它的设计必须能够适应计算机技术的快速变化。毕竟，
一种成功的新指令集体系结构可能要持续几十年——例如，TBM 大型机的核心已经使用了将近
50年。一种成功的计算机可能会因为技术变革而延长寿命，架构师必须提前为此类技术变革做
出应对计划。

要为计算机的发展作长远计划，设计人员必须了解实现技术的快速变化。以下5种实现技
术是现代计算机实现不可或缺的，它们都在发生急剧的变化。

\begin{itemize}
    \item 集成电路逻辑技术。晶体管密度每年大约增加35\%，差不多每四年时间翻两番。晶片大
    小的增长速度要慢一些，也比较难以预测，每年在10\%到20\%之间。两者综合起来，一
    个芯片上的晶体管数目每年大约增长40\%~55\%，或者说每18~24个月翻番。这就是人
    们熟悉的摩尔定律。器件的增长速度要慢一些，下面将进行讨论。
    \item 半导体 DRAM（动态随机访问存储器）。由于大多数 DRAM芯片主要是以 DIMM 模块形
    式交付的，所以很难跟踪芯片容量，因为DRAM 制造商通常会同时提供几种容量产品，
    以与 DIMM 容量相匹配。最近几年来，单个 DRAM芯片的容量每年增加大约25\%~40\%，
    大约每2~3年翻一番。这一技术是主存储器的基础，我们将在第2章详细讨论。注意，
    从表1-6可以看出，这一增长速度一直在随着本书的反复再版而下降。由于高效制造更
    小型 DRAM 单元的难度持续增大，人们甚至在担心，在5~7年内会不会停止增长［Kim
    2005］。第2章提到了其他几种技术，可以在 DRAM 碰到容量壁垒时取代它。
    \item 半导体闪存（电可擦编程只读存储器）。这种永久性半导体存储器是 PMD中的标准存储
    器件，普及率的迅速提高刺激了其容量的快速增加。最近几年，单个闪存芯片的容量以
    每年大约50\%~60\%的速度增长，大约每两年翻一番。2011年，每比特的闪存价格大约
    是DRAM价格的1/15~1/20。第2章将详细探讨闪存。
    \item 磁盘技术。在1990年之前，磁盘密度每年提高大约30\%，3年翻一番。之后每年增长60%，
    1996年的增速为100\%。从2004年开始，已经回落到大约40\%，每3年翻一番。每比特
    的磁盘价格大约是闪存价格的1/15~1/25。由于DRAM 的增长速度缓慢，所以每比特的
    磁盘价格现在大约是 DRAM的1/300~1/500。这一技术是服务器和仓库级存储的核心技
    术，附录D中详细讨论了这些变化趋势。
    \item 网络技术。网络性能取决于交换机性能和传输系统的性能。附录F中详述了网络技术的
    趋势。
\end{itemize}

\begin{table}[]
    % \tiny
    % \small
    % \scriptsize
    \centering
    \caption{DRAM 容量增长速度随时间的变化}
    \begin{tabular}{cccc}
    \hline
    \textbf{CA:AQA版本}         & \textbf{年份} & \textbf{DRAM增长速率（年）} & \textbf{DRAM容量的增长特征} \\ \hline
    1 & 1990 & \verb|60%|       & 每\verb|3|年翻两番 \\
    2 & 1996 & \verb|60%|       & 每\verb|3|年翻两番 \\
    3 & 2003 & \verb|40%~60%|   & 每\verb|3~4|年翻两番 \\
    4 & 2007 & \verb|40%|       & 每\verb|2|年翻一番 \\
    5 & 2011 & \verb|20%~0%|    & 毎\verb|2~4|年翻一番 \\ \hline
    \end{tabular}
\end{table}
\begin{verbatim}
*前两个版本甚至将这一速率称为 DRAM 增长经验定律，因 从1977年的 16Kbi DRAM到1996年的 64MIbit DRAM，
始终都是以这一速率增长的。由于大容量三维 DRAM 单元的制造难度，有人开始担心 DRAM容量在5-7年之内是
否会究全停止增长［Kitm 2005］。
\end{verbatim}

这些快速发展的技术左右着计算机设计的命运，由于计算速度的激增和技术的迅猛发展，
一种计算机设计的生存周期可能只有3~5年。DRAM、闪存和磁盘等关键技术的发展如此之快，
设计人员必须为应对这些变化作好打算。事实上，设计人员在设计时经常要考虑到下一代技术，
因为他们知道，当一件产品开始大量交付时，下一代技术可能是最具成本效益的，或者可能拥
有性能优势。一般来说，成本的下降速度与密度的增长速度大体相当。

尽管技术进步是连续性的，但只有当技术积累到一定程度，为新功能的出现作好准备时，
才会产生跳跃性的、不连续的影响。比如，当MOS 技术在20世纪80年代早期发展到可以在单
片芯片上集成25000 到50000个晶体管时，才使单片32位微处理器的制造成为可能。到20世
纪80年代后期，一级缓存可以出现在一个芯片上。通过消除处理器内部以及处理器与缓存之间
的芯片交叉，使成本效率和能耗效率的大幅提高成为可能。在技术发展到一定程度之前，这种
设计就无法付诸实现。随着多核微处理器的出现以及每一代核心数目的增加，甚至服务器计算
机也开始追求将所有处理器放在一片芯片上。这类技术门槛绝非罕见，对众多设计决策都有着
重要影响。

\subsection{性能趋势：带宽胜过延迟}
在1.8节将会看到，带宽和吞吐量是指在给定时间内完成的总工作量，比如在进行磁盘
传送时每秒完成的MIB 数。与之相对，延迟或响应时间是指一个事件从开始到完成所经历的
时间，比如一次磁盘访问需要的毫秒数。图1-3绘制了微处理器、存储器、网络和磁盘等各项
技术在产生里程碑式进步时，带宽与延迟的相对改进曲线。表1-7更详细地描述了这些示例和
里程碑。

表1-7中各个带宽与延迟里程碑相对于第一个里程碑的双对数曲线。注意，延迟的改进为6~8倍，
而带宽的改进为300~25000倍。更新自 Patterson［2004］

\begin{verbatim}
    表1-7 微处理、存储器、网络和磁盘在过去20~40年里的性能里程碑
    16位地址 32 位 地
    5级流水线、
    微处理器
    /总线、微
    址/总线、
    片上1&D缓
    2路超标基、
    乱序3路超
    乱序超流 多核000 4
    编码
    微编码
    64位总线
    标盘
    水线、片上
    路片上L3缓
    存、FPU
    L2缓存
    存、Turbo
    产品
    Intel
    Intel
    Intel 80486
    Intel Pentium
    Intel
    Intel
    Intel Core i7
    80286
    80386
    Peatium Pro
    Pentium 4
    年份
    1982
    1985
    1989
    1993
    1997
    2001
    2010
    晶片大小（平方
    47
    43
    90
    308
    217
    240
    毫米）
    晶体管数
    处理器数/芯片
    管脚
    延迟（时钟周期）
    总线宽度（位）
    134 000
    1
    68
    6
    16
    275 000
    1
    132
    5
    1200 000
    1
    168
    5
    32
    3 100000
    1
    273
    5
    64
    5500000
    42 000000
    1 170000 000
    1
    387
    10
    1
    423
    22
    64
    4
    1366
    14
    196
    16
    第1章 量化设计 *！
    时钟频率（MHiz）
    带宽 （MIPS）
    延迟（ns）
    存储器模块
    12.5
    2
    320
    DRAM
    模块宽度（位）
    年份
    MbivDRAM芯片
    晶片大小（平方
    16
    1980
    0.06
    35
    毫米）
    管脚/DRAM芯 16
    片
    带宽（MB/s）
    延迟（ns）
    局域网
    16
    6
    313
    分页模式
    DRAM
    16
    1983
    0.25
    45
    16
    —
    25
    25
    200
    快速分页模
    式DRAM
    32
    1986
    1
    70
    18
    66
    132
    76
    快速分页模
    式DRAM
    64
    1993
    16
    130
    20
    200
    600
    50
    同步DRAM
    64
    1997
    64
    170
    54
    1500
    4500
    15
    双数据率
    SDRAM
    64
    2000
    256
    204
    66
    （续）
    3333
    $0 000
    4
    DDR3
    SDRAM
    64
    2010
    2048
    $0
    134
    13
    225
    以太网
    40
    170
    快速
    160
    125
    cbit太网
    267
    640
    75
    62
    1600
    52
    16000
    37
    10Gbit
    100Gbit
    以太网
    以太网
    以太网
    IEBE标准
    年份
    带宽（Mbit/s）
    延迟（us）
    硬盘
    产品
    802.3
    803.34
    802.3ab
    802.3ac
    802.3ba
    1978
    1995
    1999
    2003
    2010
    10
    100
    1000
    10000
    100000
    3000
    500
    340
    190
    100
    3600RPM
    5400 RPM
    7200RPM
    10000RPM
    15 000 RPM
    15 000 RPM
    CDC
    希捷
    希捷
    希捷
    希捷
    希捷
    Wrenl
    94145-36
    ST41600
    ST15150
    ST39102
    ST3734$3
    $T3600057
    年份
    1983
    1990
    1994
    1998
    2003
    2010
    容量（GB）
    0.03
    1.4
    4.3
    9.1
    73.4
    600
    磁盘物理尺寸
    5.25英寸
    5.25英寸
    3.5英寸
    3.5英寸
    3.5英寸
    3.5英寸
    介质直径
    5.25英寸
    5.25英寸
    3.5英寸
    3.0英寸
    2.5英寸
    2.5英寸
    接口
    ST-142
    SCSI
    SCSI
    sCSi
    SCSI
    SAS
    帶宽 （MB/s）
    0.6
    4
    9
    24
    86
    204
    延迟（ms）
    48.3
    17.1
    12.7
    8.8
    5.7
    3.6
\end{verbatim}
*微处理器里程碑是几代IA-32处理醫，从16位慈线、微編码80285到64位总线、多核、乱序执行、超流水线 Core i7。
存储露樸块里程碑包括从 16位宽、纯 DRAM 到64 住宽双教据率第3版同步 DRAM。以太网从 10Mbit/S 发展到
100Gbit/s。磁盘里程碑是 以旋转速魔为标志的，从3600 RPM至15 000 RPM。每种情况都是指最佳带宽，延退就是
假定没有争用时执行简单操作的时间。更新自 Patterson［2004］o

性能是区分微处理器和网络的主要指标，所以它们的进步最大：带宽为10000~25000倍，
延迟为30~80倍。对容量和磁盘来说，容量通常要比性能更重要，所以容量的提高最多，但带
宽发展了300~1200倍，仍然要远远高于延迟的6~8倍。

显然，在这些技术的发展过程中，带宽完胜延迟，而且这一趋势很可能会继续下去。一个
简单的经验法则是：带宽的增长速度至少是延迟改进速度的平方。计算机的设计人员应当制定
相应规划。

\subsection{晶体管性能与连线的发展}
集成电路的制造工艺是用特征尺寸来衡量的，所谓特征尺寸就是一个晶体管或一条连线在
x方向或y方向的最小尺寸。特征尺寸已经从 1971年的10微米下降到2011年的0.032微米；事
实上，我们已经改变了单位，所以2011年的产品工艺被称为“32纳米”，22纳米的芯片也在研
发之中。由于每平方毫米硅片上的晶体管数目是由单个晶体管的表面积大小决定的，所以当特
征尺寸线性下降时，晶体管密度将以平方曲线上升。

不过，晶体管性能的增长就要更复杂了。当特征尺寸缩小时，器件在水平方向以平方关系
缩小，在垂直方向上也会缩小。垂直方向上的缩小需要降低工作电压，以保持晶体管的正常工
作和可靠性。缩放因子的这种组合效果使晶体管性能和工艺特征尺寸之间产生了复杂的相互关
系。大致来说，晶体管性能的提高与特征尺寸的下降成线性关系。

当特征尺寸下降时，晶体管性能以线性提升，而晶体管数目却是以平方曲线增长，这一事
实既是挑战，也是机遇，计算机架构师就是为此而生的！在微处理器发展的早期，借助晶体管
密度的这种快速增长，微处理器迅速从4位发展到8位、16位、32位乃至64位。最近几年，
密度的增长已经足以支持在一个芯片上引入多个处理器，支持更宽的SIMD单元、推理执行和
缓存中的许多创新，在第2、3、4、5章将会讨论这些内容。

尽管晶体管的性能通常会随着特征尺寸的缩小而得到提升，但集成电路中的连线却不会如
此。具体来说，一段连线的信号延迟与其电阻、电容的乘积成正比。当然，当特征尺寸缩小时，
连线会变短，但单位长度的电阻和电容都会变差。这种关系很复杂，这是因为电阻和电容都依
赖于工艺的具体细节、连线的几何形状、连线的负载，甚至取决于与其他结构的邻近程度。偶
尔也会存在一些工艺方面的改进，比如铜的引入，这些改进会一次性地改善连线延迟性能。

一般来说，与晶体管性能相比，连线延迟方面的改进小得可怜，增加了设计人员面临的挑
战。在过去几年里，除了功率耗散方面的限制之外，连线延迟已经成为大型集成电路的主要设
计限制，往往比晶体管开关延迟还要关键。越来越多的时钟周期被消耗在信号在连线上的传播
延迟上，而功率现在扮演的角色甚至比连线延迟还要重要。

\section{集成电路中的功率和能耗趋势}
今天，对于几乎所有类型的计算机来说，功率都是计算机设计人员面对的最大挑战。第一，
必须将功率引入芯片，并进行分配，而现代微处理器仅仅为电源和接地就使用了数以百计的管
脚和多个互连层。第二，功率以热的形式耗散，必须消除。

\subsection{功率和能耗：系统观点}
系统架构师或用户应当如何考虑性能、功率和能耗呢？从系统架构师的角度来看，共有三
个主要关注事项。

第一，一个处理器需要的最大功率是多少？满足这一要求对于确保正确操作非常重要。例
如，如果处理器试图汲取的功率大于电源系统能够提供的功率（也就是试图汲取的电流大于电
源系统能够提供的电流），其结果通常会导致电压下降，而电压下降可能会导致器件无法正常工
作。现代处理器在峰值电流时的功耗变化范围很大，因此提供了电压指数方法，允许处理器减
缓速度，在更大幅度内调𤨣电压。显然，这样会降低性能。

第二，持续功耗是多少？这个度量普遍称为热设计功耗（TDP），这是因为它决定了冷却需
求。TDP 既不是峰值功率（峰值功率通常要高1.5倍），也不是在一个给定计算期间消耗的实际
平均功率（它可能还要更低一些）。在为一个系统设定典型电源型时，其功率通常要大于TDP，
而一个冷却系统通常设计为与 TDP相匹配或大于 TDP。如果不能提供足够的冷却功率，可能会
使处理器中的结点温度超出最大值，导致器件故障，甚至永久损坏。由于最大功率可能超出 TDP
指定的长期平均值（从而使热量和温度上升），所以现代处理器提供了两项功能来帮助管理热量。
第一，当温度接近结点温度上限时，电路降低时钟频率，从而减小功率。如果这一技术不成功，
则启用第二热过载启动装置，以降低芯片的功率。

设计者和用户需要考虑的第三个因素是能耗和能耗效率。回想一下，功率就是单位时间的
能耗：1瓦=1焦/秘。哪个度量更适合对比处理器呢：能耗，还是功率？一般来说，能耗总是要
更好一些，因为它与特定任务以及该项任务所需要的时间结合在一起。具体来说，执行一项工
作负载的能耗等于平均功率乘以此项工作负载的执行时间。

因此，如果我们想知道两种处理器中的哪一个对于某一给定任务更为高效，应当对比执行
该项任务的能耗（而不是对比功率）。例如，处理器A可能比处理器B的平均功耗高20\%，但如
果A执行该任务的时间仅为B所需时间的70\%，它的能耗就是1.2×0.7=0.84，显然要更好一些。

有人可能会说，在一个大型服务器或者云中，由于工作负载经常被认为是无限的，所以考
虑平均功率就足够了，但这是一种误导。如果云中填充的是处理器B，而不是处理器A，那这
个云在消耗相同能量的情况下，所做的工作会更少一些。使用能耗进行对比可以避免这一谬误。
只要我们的工作负载是固定的，那无论是仓库规模的计算机，还是智能手机，在对比处理器时
使用能耗指标总是正确的方法，因为无论是云的电费单还是智能手机的电池寿命，都是由所消
耗的能量决定的。

那功率消耗什么时候才是一种有用的衡量指标呢？它的主要合理用途是作为一一种约束条
件：比如，一个芯片的功率可能被限定为不得超过100瓦。如果工作负载是固定的，那就可以
用它来进行度量，但在这种情况下，它只不过是平均任务能耗这一真正度量的变体。

\subsection{微处理器内部的能耗和功率}

对CMOS芯片来说，传统的主要能耗源是开关晶体管，也称为动态能耗。每个晶体管所需
要的能耗与该晶体管驱动的容性负载与电压平方的乘积成正比：

能耗s盎容性负载×电压2

这个公式的计算结果就是逻辑转变脉冲01-0或1-20 1的能耗。那么一次转換（0 1或1-+0）
的能耗就是：

能耗非 1/2×容性负载 x 电压2

每个晶体管所需要的功率就是一次转换的能耗与转换频率的乘积：

功率猫1/2×容性负载×电压2x开关频率

对于一项固定任务，降低时钟频率可以降低功率，而不会降低能耗。

显然，通过降低电压可以大幅降低动态功率和能耗，所以在20年里，电压已经从5V降低
到 1V 以下。容性负载的大小取决于输出端连接的品体管数目及所用技术，这种技术决定了连
线和晶体管的电容。

例题
现在的一些微处理器设计采用可调电压，电压降低15%可能导致频率下降 15%。
这对动态能耗和动态功率有什么影响？
解答
由于电容值不变，所以能耗变化就是电压平方之比：
-=0.852=0.72
能耗廒
因此，能耗大约降为原能耗的72%。对于功率，需要考虑频率的比值：
功率 =0.72×（开关救率×0.85）=0.61
功率繳
开关频率
缩小到原功率的大约61%。

当我们从一种制造工艺转向另一种工艺时，晶体管的开关次数以及其开关频率的增高强于
负载电容和电压的下降，从而导致功耗和能耗的总体上升。第一代微处理器消耗的功率低于1
瓦，第一代32位微处理器（比如 Intel 80286）消耗大约2瓦，而3.3GHz Intel Core i7 消耗 130
瓦。如果这些热量必须从旁边的一个大约为1.5cm的芯片上消散出去，那实际已经达到了风冷
所能达到的极限。

根据上述公式，如果不能降低电压或提高每个芯片的功率，那可能就要减缓时钟频率的增
长速度。图14表明，实际上从 2003年开始就已经是这种局势了，图1-1中的微处理器都是每
一年度的最佳处理器，它们也无一例外。注意，图 1-4中具有平坦时钟频率曲线的那段时期与
图1-1 中性能改进缓慢的时期相对应。

图1-1中各微处理备时钟频率的增长。从1978年到1986年，时钟频率的年增长速度低于1.5\%，
而性能的年增长速度为25\%。在1986年到2003年性能年增长速度达到52\%的“复兴时期”，时钟
频率飞速增长，几乎达到每年40\%。之后，时钟速率几乎停滞不前，每年的增长速度低于 1\%，
而单处理器性能的年增长速度低于22\%

分配功率、消散热量和防止热区已经变成难度日增的挑战。功率是现在使用品体管的主要
限制，在过去，主要约束体现在原料硅区域。因此，现代微处理器提供了许多技术，试图在时
钟频率和电源电压保持不变的情况下，提高能耗效率。

（1）以逸待劳。今天的大多数微处理器都会关闭非活动模块的时钟，以节省能耗和动态功率。
例如，如果没有正在执行浮点指令，浮点单元的时钟将被禁用。如果一些核心处于空闲状态，
它们的时钟也会被停止。

（2） 动态电压-频率调整（DVFS）。第二种技术直接来自上述公式。个人移动设备、膝上型
电脑、甚至服务都会有一些活跃程度较低的时期，在此期间不需要以最高时钟频率和电压运转。
现代微处理器通常提供几种能够降低功率和能耗的工作时钟频率和工作电压。图1-5绘制了当
工作负载降低时，服务器通过 DVFS 可能节省的功率，三种不同时钟频率为：2.4GHZ、1.8 GHIz
和1GHz。在这两个步骤的每一步中，服务器节省的总功率大约为10\%~15\%。

图1-5
采用 AMD Opteron 微处理器、8 GB DRAM、一个 ATA磁盘的服务节省的能耗。工作频率力
1.8 GHz时，服务器在不降低服务水平的情况下最多只能处理三分之二的工作负载，当工作频率
为1.0GHz时，只能安全地处理三分之一的工作负载（Barroso、Holzle［2009］书中的图5-11）

（3） 针对典型情景的设计。由于 PMD 和膝上型电脑经常空闲，所以内外存储器都提供了
低功率模式，以节省能耗。例如，DRAM具有一系列功率逐渐降低的低功率模式，用于延长 PMD
和膝上型电脑的电池寿命，针对磁盘也提出了一些建议，在空闲时使其采用低转速模式，以节省
功率。遗憾的是，我们不能在这些模式下访问 DRAM 和磁盘，无论访问速度有多低，都必须返
回全速工作模式才能进行读写。前面曾经提到，PC微处理器的设计已经考虑了一种更典型的情
景：在高工作温度下密集使用，这种设计依靠片上温度传感器检测应当在什么时候自动减少活动，
以避免过热。这种“紧急减速”使制造商能够针对一种更典型的情景进行设计，如果运行程序消
耗的功率真的远远超出典型功率，则可以依靠这种安全机制来保证安全。

（4） 超频。Intel 在2008年开始提供 Turbo模式，在这种模式中，芯片可以判定在少数几
个核心上以较高时钟频率短时运行是安全的，直到温度开始上升为止。例如，3.3 GHz Core i7
可以在很短的时间内以3.6GHz的频率运行。实际上，从2008年开始，图1-1 中每一年度最高
性能的微处理器都提供了短时超频功能，超频频率大约比标称时钟频率高10%。在执行单线程
代码时，这些微处理器可以仅留下一个核心，并使其以更高时钟频率运行，而其他所有核心均
被关闭。注意，操作系统可以关闭 Turbo模式，而且在启用时也没有通知，所以程序员可能会
惊奇地发现，他们的程序可能会因为室温而发生性能变化。

尽管通常认为动态功率是 CMOS 中的主要功率耗散源，但由于即使晶体管处于截止状态时
也存在泄漏电流，所以静态功率也正在成为一个重要问题：

功率糖态 电流料态 ×电压

也就是说，静态功率与器件数目成正比。

因此，如果增大品体管的数目，即使它们处于空闲状态也会增加功率，当晶体管的尺寸较
小时，处理器中的泄漏电流会增大。所以，极低功率的系统甚至会关闭非活动模块的电源（电
源门控），以控制由于泄漏电流导致的损失。2011年，泄漏目标是总功耗的 25\%，而高性能设
计中的泄漏有时会远远超过这一目标。对于此类芯片，泄漏可能高达 50\%，都分原因是大型
SRAM缓存需要功率来维持其存储值。（SRAM 中的S表示“静态”，即 static）。停止泄漏的唯
一手段就是关闭部分芯片的电源。

最后，由于处理器只是系统整体能耗中的一部分，所以如果使用一个速度较快但能耗效率
较低的处理器，使系统的其他部分能够进人睡眠模式，那也可能有助于降低整体能耗。这种策
略被称为竞相暂停 （race-to-halt）。

由于功率和能耗的重要性，人们在评价一项创新时，更加重视对其效率的审核。因此，现
在的主要评价指标是每焦耳完成的任务数或者每瓦特实现的性能，而不再是每平方毫米的硅所
实现的性能。这一新的度量影响了并行化方法，在第4章和第5章将会读到这一内容。

\section{成本趋势}
尽管成本趋势在一些计算机设计中不是特别重要（特别是在超级计算机中），但对成本敏感
的设计正在变得越来越重要。事实上，在过去30年里，通过技术改进来降低成本（以及提高性
能）已经成为计算机行业的一个重要主题。

教科书中经常会忽略“成本-性能”中的成本部分，这是因为成本的不断变化会使书中内容
变得过时，还有一个原因是，这些问题非常微妙，因行业部门的不同而不同。但对计算机架构
师来说，了解成本及其因素是必不可少的，在存在成本问题时，可以帮助他们明智地决定是否
要包含某一项新功能。（想象一下，如果摩天大楼的设计师完全不了解钢梁和混凝士的成本，那
会是一种什么结果！）

本节讨论影响计算机成本的主要因素，以及这些因素如何随时间变化。

\subsection{时间、产量和大众化的影响}

即使基础实现技术没有发生任何重大进步，计算机组件的制造成本也会随着时间的推移而
降低。推动成本走低的基础原理是学习曲线——制造成本随时间的推移而降低。学习曲线本身
是根据成品率的变化测得的，所谓成品率是指成功通过测试程序的器件占所生产器件总数的百
分比。无论是芯片、主板，还是系统，使成品率加倍的设计就能使成本减半。

了解学习曲线如何提高成品率，对于在一件产品生存周期的不同阶段控制成本非常重要。
比如，长期以来，每兆字节的 DRAM 价格一直在下降。由于 DRAM 的定价往往与成本密
切关联（出现供给不足或过度供给的时期除外），所以DRAM的价格与成本变化趋势基本一致。
微处理器的价格也随时间的推移而降低，但由于它们的标准化程度弱于DRAM，所以价格
与成本之间的关系要更复杂一些。当竞争非常激烈时，价格的变化趋势与成本非常一致，当然，
微处理器销售商赔钱销售的可能性很少。

产量是决定成本的第二个重要因素。产量的提高会以几种不同方式对成本产生影响。第一，
产量的提高缩短了降低学习曲线所需要的时间，这一时间在一定程度上与系统（或芯片）的制
造数量成正比例关系。第二，由于产量的增加会提高购买与制造效率，所以产量会降低成本。
一些设计人员根据经验估计：产量每增加一倍，会使成本下降大约10\%。此外，产量的增加还
降低了必须分摊到每台计算机上的开发成本，使成本与销售价格更为接近。

大众化商品是指有多家销售商大量出售且基本相同的产品。在杂货商店货架上出售的几乎
所有产品都是大众化商品，标准的DRAM、闪存、磁盘、监视器和键盘也都是大众化商品。在
过去25年里，个人计算机行业的大部分领域已经变为一项大众化商品业务，主要生产运行
Mictosoft Windows 的桌面式计算机和膝上型计算机。

因为许多供应商都提供几乎完全相同的产品，所以市场竞争非常激烈。这种竞争当然会缩
小成本与销售价格之间的距离，而且还会降低成本。由于大众化商品市场既拥有很大的产量，
又有明确的产品定义，这样可以让那些为大众化产品制造组件的供应商展开竞争，从而降低成
本。因此，由于组件供应商之间的竞争，以及销售商所能达到的产量效率，会降低产品的总成
本。与其他部门相比，这种竞争使计算机行业的低端能够获得更好的性价比，得以更快速地增
长，当然，它们的利润率非常有限（在所有大众化产品行业内，通常都是如此）。

\subsection{集成电路的成本}
一本讲解计算机体系结构的书中为什么会有一节内容来讨论集成电路的成本呢？在竞
争日益激烈的计算机市场上，标准零件（磁盘、闪存、DRAM等）在系统成本中的份额越来
越高，集成电路成本成为计算机成本差异的重要因素，在大产量、价格敏感的市场中龙为如
此。事实上，由于个人移动设备越来越依赖于整体片上系统（SOC），所以集成电路的成本
成为 PMD成本的主体部分。因此，计算机设计人员必须了解芯片的成本，才能理解当前计
算机的成本。

尽管集成电路的成本以指数形式下降，但基本的硅制造工艺没有变化：仍然要对晶圆
（wafer）进行测试，切割成晶片（die）进行封装（见图1-6、图1-7和图1-8）。因此，一个已封
装集成电路的成本为：

集成电路的成本=晶片成本+晶片测试成本+封装与最终测试成本
最终测试成品率

这一节主要讨论晶片成本，最后总结测试和封装中的关键问题。

要学习如何预测一个晶圆上的正品芯片数目，需要首先了解一个晶圆上可以放多少个晶片，
然后了解如何预测正常工作晶片的百分比。知道了这些数据，预测成本就很简单了：

晶圆成本
晶片成本三每个品圆上的品片数×品片成品率

晶片成本公式第一项中的最重要特征是它对晶片尺寸非常敏感，如下所示。

图1-6 Intel Core i7 微处理器晶片的相片，在第2章到第5章将对其进行评价。在45 nm 工艺中，
尺寸为 18.9 mm × 13.6 mm （257mm’）（感谢 Intel提供）

1-7 左图为團1-6中 Core i7 晶片的布置图，右图为第二核心布置图的特写

图1-8 这个 300mm 的晶園上包含 280个全沙桥晶片，采用32nm 工艺时，每个晶片的大小为
20.7mm ×10.5 mm。（沙桥是 Intel 在 Core i17 中所用 Nehalem 的后续产品）。当晶片大小为216mm2
时，每个晶圆上的晶片数大约为282个（感谢 Intel 提供）

每个晶圆上的晶片数目大约等于晶圆面积除以晶片面积。更准确的估算公式为：
每个晶圆上的晶片数= x（晶圆直径）2’
×品圆直径
晶片面积
2x晶片面利
30］

第一项是晶圆面积（wr）与晶片面积之比。第二项对“方枘圆凿”问题（也就是接近晶圆外围
的矩形晶片）作出补偿。将圆周（ncd）除以方形晶圆的对角线，大约就是沿边缘排列的晶片数目。

\begin{verbatim}
    例题
    解答
    若晶片边长为 1.Scm，求一个 300mm （30cm）晶圆上的晶片数目，若晶片的
    边长为 1.0cm，
    又可以有多少个晶片。
    当晶片面积为2.25 cm2时：
    每个品圆上的品片数=Z×（30/2）
    T×30
    706.9
    294.2=270
    V2×2.25
    2.25
    2.12
    由于较大晶片的面积大了 2.25倍，所以每个晶圆上的小晶片数大约多2.25倍：
    每个品圆上的品片数=7x（30/2）
    #×30
    706.9
    2-942-640
    1.00
    V2×1.00
    1.00
    1.41
\end{verbatim}

但这个公式只给出了每个晶圆上的最大晶片数目。关键问题是：一个晶圆上的合格晶片占
多大比例呢？或者说晶片成品率是多少呢？集成电路成品率的一种简单模型假定晶圆上的缺陷
是随机分布的，成品率与制造工艺的复杂度成反比，由这一模型可以得出如下结果：

晶片正品率=晶圆正品率x1/（1+单位面积上的缺陷x晶片面积）”

这个波斯-爱因斯坦公式是通过研究许多生产线的成品率而得出的经验模型［Sydow 2006］。晶圓
成品率考虑了完全损坏而不需要测试的晶圆。为简单起见，我们直接恨定晶圆成品率为100\%。
单位面积上的缺陷数是发生随机制造缺陷的度量。2010年，对于40nm 工艺，这个数值通常为
每平方英寸0.1~0.3个缺陷，或者为每平米厘米0.016至0.057个缺陷，具体取决于工艺的成熟
度（回想一下前面提到的学习曲线）。最后，N是一个称为工艺复杂度因数的参数，用于衡量制
造难度。对于2010年的40nm 工艺，N的范围大约为11.5~15.5。

例题
解答
设缺陷密度为 0.031/cmn？，N为13.5，若晶片边长为1.5cm和1.0cm，求品片成品率。
总晶片面积为2.25 cm2和 1.00cm’。较大品片的成品率为：
晶片成品率=1/（1+0.031 ×2.25） 36=0.40
较小晶片的成品率为：
晶片成品率=1/（1+0.031 × 1.00）'3.6=0.66
即，所有较大晶片中，成品数少于一半，而较小晶片中有三分之二以上是成品。

这个计算结果是每个晶圆上的合格晶片数，它等于每个晶圆上的晶片数乘以晶片成品率，
将缺陷效应考虑在内。上述示例预测在300mm 晶圆上大约可以制造109个 2.25 cm’的合格晶
片或者424个 1.00cm2的合格晶片。许多微处理器都介于这两个尺寸之间。低端嵌人式32位
处理器有时小至 0.10 cm”，而（在打印机、微波炉等设备内部）用于嵌人式控制的处理器通常
小于0.04cm”。

由于 DRAM和 SRAM之类的大众化商品承受着巨大的价格压力，所以设计人员会加上一
些冗余，作为提高成品率的方法。很多年来，DRAM中都有规律地包含一些冗余存储器单元，
从而可以容许存在一定数目的缺陷。设计人员在标准 SRAM 中和用作微处理器内部缓存的大型
SRAM 阵列中使用类似技术。显然，冗余单元的存在可以显著提高成品率。

采用2010年业内领先技术，直径为300mm（12英寸）的晶圆制造成本介于 5000~6000
美元。假定晶圆的生产成本为5500美元，1.00cm2晶片的成本大约为13美元，但每个2.25 cm2
晶片的成本将达到大约51美元，尺寸略大于2倍，而成本几乎达到了4倍。

关于芯片成本，计算机设计人员应当记住什么呢？制造工艺决定了晶圆成本、晶圆成品率
和单位面积上的缺陷数，设计人员唯一能够控制的就是晶片面积。在实践中，由于单位面积上
的缺陷数目很小，所以每个晶圆上合格晶片数的增长速度大致与晶片面积的平方成正比，每个
晶片的成本也符合这一规律。计算机设计人员可以影响晶片大小，从而影响成本，方法有两个：
决定晶片上包含哪些功能或者排除哪些功能，确定1/O管脚的数目。

必须首先对晶片进行测试（将合格晶片从不合格晶片中分离出来）、封装、封装后的再测试，
才能得到一个能够在计算机中使用的零件。这些步骤都增加了成本。

上述分析的重点是生产一个功能晶片的可变成本，适用于大批量生产的集成电路。但是对
于小批量生产的集成电路（小于100万），固定成本中有一个非常重要的部分会显著影响到集成
电路的成本，这个重要部分就是掩膜组的成本。集成电路工艺中的每个步骤都需要一个单独的
掩膜。因此，对于现在具有4~6个金属层的高密度制造工艺来说，掩膜成本超过100万美元。
显然，这一庞大的固定成本影响着原型设计和调试过程的成本，对于小批量生产来说，可能会
成为生产成本的一个重要部分。由于掩膜成本可能继续增大，所以设计人员可以采用可重新配
置的逻辑，以提高一件零件的灵活性，或者选择使用门阵列（门阵列的自定义掩膜级别较少），
从而降低掩膜带来的成本。

\subsection{成本与价格}
随着计算机的大众化，一件产品的制造成本与销售价格之间的差额已经缩小了。这些差额
主要用来支付公司的研发、营销、销售、制造设备维护、厂房租金、财务、税前利润、税收等
各项费用。大多数公司的研发费用只占其收入的4\%（大众化PC业务）至12\%（高端服务器业
务），其中包括了所有工程费用，许多工程师在知道这一数据时都非常惊讶。

\subsection{制造成本与运行成本}
在本书的前四个版本中，成本是指计算机的制造成本，价格是指购买计算机的价格。在仓
库级计算机（其中包含数万个服务器）出现之后，除了购买成本之外，这种计算机的运行成本
也非常高。

第6章指出，服务器和网络的可分摊购买价格仅略高于仓库级计算机月运行成本的60\%假
定这一IT设备的短暂寿命为3~4年）。月运行成本的大约30\%是电费以及用于配电和 IT设备
冷却的可分摊基础设施（尽管这一基础设施的费用可以分摊到10年以上）。因此，要降低仓库
级计算机的运行成本，计算机架构师需要高效利用能源。

\section{可信任度}
在历史上，集成电路曾经是计算机中最可靠的组件之一。尽管它们的管脚很容易损坏，在
信道中也可能发生错误，但芯片内部的错误率是非常低的。当我们向32 nm 乃至更低特征尺寸
前进时，上述常识发生了变化，由于暂时错误和永久错误的出现频率都大大增加，所以架构师
设计的系统必须能够应对这些挑战。这一节快速回顾了一些可信任度问题，而术语与方法的官
方定义请参阅附录D的D.3节。

计算机是在不同抽象层上设计和构建的。我们可以逐级深人计算机的不同层面，将每个组
件放大为一个完整的子系统进行查看，直到深入到独立的品体管为止。尽管有些错误分布得比
较普遍，比如掉电，但许多错误都局限于一个模块的单个组件中。因此，在某一层级看来是整
个模块完全失效的情况，从更高层级来看，可能只是一个模块中的组件故障。这种层级区分对
于找出构建可靠计算机的方法很有帮助。

如何判断一个系统的运行是否正常，这是一个难题。随着互联网服务的普及，这一同题变
得更为明确。基础设施供应商开始提供服务等级协议（SLA）或服务等级目标（SLO），保证他
们的网络或电源服务是可靠的。例如，他们在一个月内无法满足协议的时间超过若干小时，就
会向客户提供赔偿。因此，可以使用SLA来判断系统是在正常运行，还是已经宕机。

系统在 SLA规定的两种服务状态之间场换。

（1）服务实现，即提供了指定服务
（2） 服务中断，即所提供服务与 SLA不一致
两种状态之间的转换由故障（由状态1至状态2）或恢复（状态2至状态1）导致。对这两
种转换进行量化，可以得到可信任度的两种主要度量。

口 模块可靠性是从一个参考初始时刻开始持续实现服务的度量（一种等价说法是：对发生
故障之前的时间度量）。因此，平均无故障时间（MTTF）是一种可靠性度量。MTTF的
倒数就是故障率，通常以运行10亿小时发生的故障数来表示，或称为 FIT （Failures In
Time）。因此，MTTF等于1000000 小时，相当于109/108-1000FIT。服务中断以平均修
复时间（MTTR）来度量。平均故障间隔时间（MT'BF）就是 MTTF+MTTR。尽管
MTBF的使用更为广泛，但MTTF通常更为适用。如果一组模块的寿命服务以措数分布，
也就是说模块的老化对于故障概率的影响并不是很大，那么这一组模块的整体故障率就
是这些模块的故障率之和。

口 模块可用性是指在服务完成与服务中断两种状态之间切换时，对服务完成的度量。对于
可修复的非冗余系统，模块可用性为
MTTF
模块可用性=（MTTF+MTTR）

注意，可靠性和可用性现在是可量化度量，而不再是可信任度的同义词。从这些定义出发，如
果我们对组件的可靠性作出一些假设，并假设故障之间是互相独立的，则可以量化估计一个系
统的可靠性。

例题
设磁盘子系统的组件及 MTTF 如下：
口10个磁盘，各自的等级为 1000 000小时 MTTF
口1个 ATA 控制器，500000小时 MTTF
口1个电源，200000小时 MTTF
口1个风扇，200 000小时 MTTF
口1根 ATA 电缆，1000000小时 MTTF
采用简化假设：寿命符合指数分布，各故障相互独立，试计算整个系统的 MTTF。
解答
故障率之和为：
故障率系=10× 000000＋
500000*200000*200000*1000000
10+2+5+5+1
23000
1 000000小时
-=1 000000 1 000000000小时
或23 000 FIT。系统的 MITF 就是故障率的倒数：
1
MTIT茶熱三政障率环統
-=
1 000 000 000小时
23000
-=43 500小时
或略低于5年。

应对故障的主要方法是冗余，或者是时间冗余（重复操作，以查看是否仍然错误），或者是
资源冗余（当一个组件发生故障时，由其他组件接管）。在替换组件、完全修复系统后，认为系
统的可信任度与新系统相同。现在用一个例子来量化冗余的好处。

例题
解答
磁盘子系统经常备有冗余电源，以提高可信任度。利用上述组件和 MTTF，计算冗余
电源的可靠性。假设一个电源足以运行磁盘子系统，而且我们正在添加一个冗余电源。
我们需要一个公式来表明当可以容忍一个故障并仍能提供服务时的情景。为了简化
计算，假定组件的寿命为指数分布，而且组件故障之间没有相关性。冗余电源对的
MTTF就是两个量的比值，分子是从初始时刻到一个电源发生故障的平均时间，分
母是在更换第一个电源之前另一电源也发生故障的几率。因此，如果在修复第一个
故障之前发生第二个故障的机会很小，那么电源对的MTTF就很大。

由于我们有两个电源，而且故障独立，则在一个磁盘发生故障之前的平均时间为
MTTF 电w/2。发生第二个故障的概率有一个很好的近似：用 MT'TR除以另一电源发
生故障之前的平均时间。因此，冗余电源对的合理近似为：
MTTF电源 =
MTTF电w/2 =-
MTTFY电派/2
MTTR电源
MTTR心源
MITTF2山源
--2xMTTR也w
MTTF 淋
使用以上 MTTF 数字，如果假设操作人员平均需要24小时才能注意到电源发生故
障并进行更换，则这个容错电源对的可靠性为：
MTTF此源
MTTF电激对
--200 000°
=830 000 000
2×MTTR也源
2×24
使电源对的可靠程度比单电源提高大约4150倍。

在计算机的成本、功率和可信用度进行量化之后，我们可以开始量化性能了。

\section{性能的测量、报告和汇总}
如果我们说一台计算机比另一台计算机快，这是什么意思呢？一个台式计算机的用户说一
台计算机更快，可能是一个程序的执行时间较短，而Amazon.com 管理员说一台计算机更快，
可能是它每小时完成的事务较多。计算机用户关心的是缩短响应时间，也就是一个事件从启动
到完成的时间，也称为执行时间。仓库级计算机的操作人员可能关心的是吞吐量，也就是在给
定时间内完成的总工作量。

在对比不同设计时，我们经常希望找出两台不同计算机（比如说×和Y）性能之间的关系。
这里所说的“x比Y快”是指给定任务在 X上的响应时间或执行时间短于在Y上的响应时间。
具体来说，“x的速度是Y的n倍”是指：

热行时间 =n
执行时间x

由于执行时间是性能的倒数，所以以下关系成立：

执行时间 =想
性能Y
执行时间x
性能x

“x的吞吐量是Y的1.3倍”指计算机 ×在单位时间内完成的任务数是Y上完成任务数的1.3倍。

遗憾的是，在对比计算机性能时并非总是使用时间这一度量标准。我们的观点是：唯一稳
定、可靠的性能度量就是实际程序的执行时间，以任意其他度量代替时间或者以任意其他被测
项目代替实际程序，最终都会在计算机设计中产生误导，甚至是错误。

即使是执行时间，也可以根据我们的测量内容采用不同的定义方式。最直接的时间定义被
称为挂钟时间，响应时间或已用时间，也就是完成一项任务的延迟，包括磁盘访问、存储器访
问、输人/输出活动、操作系统开销等所有相关时间。在同时运行多个程序的情况下，处理器在
等待1/O 时处理另一个程序，不一定使某一程序的已用时间缩至最短。因此，我们需要有一个
术语来表达这一行为。CPU 时间可以区分这种不同，它是指处理器执行计算的时间，不包括等
待1/O或运行其他程序的时间。（显然，用户观测到的响应时间是程序的已用时间，而不是CPU
时间。）

那些定期运行相同程序的计算机用户当然是评估新计算机性能的最佳候选人。如果他们要
评估一个新系统的性能，只需要比较其工作负载的执行时间就行了（其工作负载就是在计算机
上运行的程序和操作系统命令）。但很少有用户具备这种得天独厚的条件。大多数用户必须依赖
其他方法来评价计算机的性能，还经常需要使用评估软件，希望这些方法能够预测自己在使用
新计算机时的性能。

\subsection{基准测试}
测量性能的最佳基准测试方法就是采用实际应用程序，比如 1.1节的 Google Goggles。人们
曾经尝试运行一些远比实际应用程序简单的程序，但这种做法已经导致了性能隐患。这些简单
程序的示例包括：

\begin{itemize}
    \item 程序内核，即实际应用程序中的短小、关键部分；
    \item 玩具程序，为了完成编程入门作业而编写的小程序，通常不超过100行，比如快速排序；
    \item 合成基准测试程序，为了匹配实际应用程序的特征和行为而编写的虚拟程序，比如
    Dhrystone。
\end{itemize}

今天，所有这三种方法都没有什么好名声，主要是因为编译器的编写人员和架构师可以申
通起来，使计算机在执行这些替代程序时能够比运行实际应用程序时显得更快一些。令本书作
者感到沮丧的是，合成程序 Dhrystone仍然是应用最为广泛的嵌人式处理器基准测试程序！（由
于我们认为计算机架构师也认同合成程序的名声不佳，所以在本书前四版中就不再使用合成程
序来测量计算机性能。）

另外一个问题就是运行基准测试的条件。一种提高基准测试性能的方法是使用基准测试的
专用标志；这些标志经常会导致对许多程序的非法转换，还可能降低另外一些程序的性能。为
了限制这种情况，并使结果更有意义，基本测试开发人员经常要求销售商对所有使用同一语言
（C++或C）编写的程序使用同一编译器和同一组标志。除了编译器标志的问题之外，还有另外
一个问题：是否允许修改源代码。有三种不同方法可以解决这一问题。

\begin{itemize}
    \item 不允许修改源代码。
    \item 允许修改源代码，但基本没有修改可能。例如，数据库基准测试取决于拥有数千万行代
    码的标准数据库程序。数据库公司几乎不可能为了提高一个特定计算机的性能而进行修改。
    \item 允许修改源代码，只要修改后的版本能够给出相同输出结果即可。
\end{itemize}

在决定是否允许修改源代码时，基准测试设计人员面对的主要问题是这些修改是否会反映
实际做法，能否向用户提供有用的洞察能力，还是只会降低基准测试的准确度，只能作为实际
性能的预测值。

为了避免将太多鸡蛋放在一个篮子中所带来的危险，一种流行的做法是采用基准测试应用
程序集（称为基准测试套件）来衡量处理器处理各种应用程序的性能。当然，这些套件的准确
程序不会超过组成该套件的各个基准测试。不过，这种套件的主要优势在于任何一个基准测试
的弱点都会因为其他基准测试的存在而变小。基准测试套件的目的是描述两个计算机的相对性
能，特别是那些客户可能会运行又未包含在该套件之内的程序。

电子设计新闻杂志嵌入式微处理器基准测试联盟（缩写为 EEMBC，发音与 embassy 相同）
基准测试就是前车之鉴。它由41个内核程序组成，用于预测不同嵌人式应用程序的性能，这些
领域包括汽车/工业、消费应用、网络、办公自动化和电信。EEMBC报告中给出的性能数据未
经任何修改，显得有些“杂乱”，几乎所有信息都包含在内。因为这些基准测试采用内核程序，
还因为这些复杂的报告选项，所以 EEMBC 并不能很好地预测业内不同嵌人式计算机的相对性
能。正是由于 EEMBC的不够成功，才使它试图取代的 Dhrystone一直沿用至今。

在创建标准化基准应用程序套件方面，最成功的尝试之一是 SPEC（标准性能评估机构），
它源于20世纪80年代后期为了更好地对工作站进行基准测试所付出的努力。计算机行业一直.
在发展之中，所以对不同基准测试套件的需求也在不断发展，现在有许多 SPEC 基准测试，可
以涵盖众多应用领域。所有SPEC基准测试套件及其测试报告都可以在www.spec.org找到。
尽管在下面的许多章节中，我们将主要讨论 SPEC基准测试，但针对运行 Windows 操作系
统的PC机，人们已经开发了许多其他基准测试。

1.桌面基准测试
桌面基准测试分为两大类：处理器密集型基准测试和图形密集型基准测试，不过许多图形
基准测试中包含大量处理器行为。SPEC最初开发了一个针对处理器性能的基准测试集（最初被
称为 SPEC89），它现在已经发展到第五代：SPEC CPU 2006，前面还有SPEC2000、SPEC95、
SPEC92 和 SPEC89。SPEC CPU2006由12个整数基准测试（CINT2006）和17个浮点基准测试
（CFP2006）组成。图1-9介绍了目前的SPEC 基准测试及其以前的各个版本。

SPEC 基准测试是一些实际应用程序，这些应用程序经过修改就能够移植，并能在最大群
度上降低T/O 对性能的影响。整数基准测试涉及的范围很广，既有C编译器的一部分，又有一
个国际象棋程序，还有一个量子计算机的模拟。浮点基准测试包括用于有限元建模的结构化网
格代码、用于分子动力学的粒子方法代码，以及用于流体动力学的稀疏线性代数代码。SPECCPU
套件可用于对桌面系统和单处理器服务器进行处理器基准测试。在本书中，将会看到许多此类
程序的相关数据。但是，这些程序与1.1 节介绍的编程语言、环境以及 Google Goggles 应用程
序没有什么共同点。其中7个使用C++、8个使用C、9个使用Fortran！它们甚至都是静态链接
的，这些应用程序本身反应比较迟钝。我们不太清楚 SPECINT2006 和 SPECFP2006能否把握
21世纪的计算特点。

1.11 节将介绍在开发SEEC 基准测试套件时已经出现的失误，以及为了维护一个有用的、
具有预测性的基准测试套件所面对的挑战。

SPEC CPU2006针对的是处理器性能，不过SPEC还提供了许多其他基准测试。

SPEC2006 程序及 SPEC 基准测试随时间的演变，粗线上方为整数程序，下方为浮点程序。在
SPEC2006的12个整数应用程序中，9个用C编写、其余3个用C++编写。在浮点程序中，6个
用Fortran编写、4个用C++编写、3个用C编写、4个用C和 Fortran 混合编写。图中给出了在1989
年、1992年、1995 年和2006年版本中的所有70个程序。左侧的基准测试描述仅针对 SPEC2006，
不适用于之前的版本。同一行中不同 SPEC代的程序之间一般不相关；例如，fpppp 不像 bwaves
那样是 CFD代码。gce 是这个组中的高级成员。只有3个整数程序和3个浮点程序在三个或三个
以上的版本中幸存下来。注意，SPEC2006中的所有浮点程序都是新加入的。尽管有些程序一代
一代地沿续下来，但程序的版本在变化，或者是基准测试的输人发生变化，或者是其大小发生变
化，这些变化是为了延长其运行时间或者避免CPU时间之外的某种因素来干扰执行时间的测量或
动摇其主导地位

2. 服务器基准测试
服务器有许多功能，所以也存在多种类型的基准测试。最简单的基准测试可能是面向处理
器吞吐量的基准测试。SPECCPU2000利用 SPEC CPU 基准测试构建了一个简单的吞吐量基准
测试，这种测试可以测试多处理器的处理速率：运行每个 SPEC CPU 基准测试的多个副本（副
本数目通常与处理器数目相同），并将 CPU时间转变为处理速率。这样会得到一个名为SPECrate
的度量，它也是1.2节介绍的请求级并行的度量。为了测量线程级并行，SPEC提供了一些圈绕
OpenMP和MPI 的基准测试，称之为高性能计算基准测试。

除了 SPECrate 之外，大多数服务器应用程序和基准测试都有大量因为磁盘和网络通信流量
所产生的1/O行为，包括用于文件服务器系统、Web 服务器和数据库与事务处理系统的基准测
试，都是如此。SPEC提供了一个文件服务器基准测试（SPECSFS）和 Web 服务器基准测试
（SPECWeb）。SPECSFS 基准测试利用文件服务器请求脚本来测试 NFS（网络文件系统）性能，
它会测试1/0系统（包括磁盘I/O和网络1/O）与处理器的性能。SPECSFS是面向吞吐量的基准
测试，但具有一些非常重要的响应时间需求。（附录 D详细讨论了一些文件和 1/O 系统基准测
试。）SPECWeb 是一种Web 服务器基准测试，它模拟多个客户端从服务器请求静态页和动态页，
还模拟客户端向服务器张贴数据。SPECjbb 测量针对Java 的Web 应用程序的服务器性能。最新
的 SPEC基准测试是SPECvit\_Sc2010， 它评估虚拟化数据中心服务器的端到端性能，包括硬件、
虚拟机层、虚拟化来宾操作系统。另一个比较新的SPEC 基准测试用于测量功率，我们将在1.10
节研究它。

事务处理（TP）基准测试测量一个系统处理事务（包括数据库访问与更新）的能力。航空
订票系统和银行 ATM 系统是比较典型的简单 TP 示例，更高级的TP 系统涉及复杂数据库和决
策制定。在20世纪80年代中期，一群工程师特地为此组建了独立于供应商的事务处理委员会
（TPC），尝试为 TP创建客观公平的基准测试。www.tpc.org 有关于TPC基准测试的介绍。

第一个 TPC 基准测试 TPC-A 于1985年发布，它随后被几个不同基准测试取代和增强。
TPC-C最初在1992年创建，模拟一种复杂的查询环境。TPC-H 对专用决策支持建模——查询之
间没有相互关联，不能利用过去查询的相关知识来优化将来的查询。TPC-E 是一种新的联机事
务处理（OLTP）工作负载，它模拟一个代理公司的客户账户。最近发布的基准测试是 TPC Energy，
它向所有现有TPC 基准测试添加了能耗度量。

所有 TPC基准测试都以每秒完成的事务数来测试性能。此外，它们还包含响应时间要求，
仅在满足响应时间限制时才会测试吞吐量性能。在实际系统建模时，更高的事舒率也与更大型
的系统关联在一起，这种所说的“更大型”一方面表现在用户数上，另一方面表现在作为事舒
应用对象的数据库上。最后，基准测试系统的系统成本也必须包含在内，以便准确地对比性价
比。TPC修改了它的定价策略，对于所有 TPC 基准测试只有一个规格，从而可以验证 TPC发布
的价格。

\subsection{报告性能测试结果}
在报告性能测试结果时，应当坚持一条指导原则—可重现性，即列出其他试验者在重现
该结果时所需要的全部信息。SPEC基准测试报告需要全面描述计算机和编译器标志，以及所公
布的基准性能和优化结果。除了对硬件、软件和基准调优参数的描述之外，SPEC报告还包含了
实际执行倍数（performance times），以表格和曲线图两种形式给出。TPC 基准测试报告甚至更
为复杂，因为它必须包含基准测试审核的结果和成本信息。自从制造商在高性能和高性价比方
面展开竞争以来，这些报告就成为确定计算系统实际成本的极佳信息源。

\subsection{性能结果汇总}
在实际计算机设计中，必须通过一组相关基准测试来评估大量设计选项的相对量化优势。
同样，消费者在选择计算机时，也会依靠—-些基准测试的性能测试结果，希望这些基准测试与
用户的应用程序相类似。在这两种情况下，拥有一组基准测试的测量结果都是有用的，一些重
要应用程序的性能会与套件中一或多个基准测试的性能类似，另一方面也可以了解性能的变化
程度。在理想情况下，这个套件类似于应用空间上的统计有效样本，但这样一个样本所需要的
基准测试要多于大多数套件的基准测试数，因此需要进行随机采样，基本上没有基准测试套件
使用这一方法。

一旦我们决定用某一种基准测试套件来测量性能，就希望能够用一个数值来汇总套件的性
能结果。计算汇总结果的一种简单方法是对比套件中各个程序执行时间的算术平均值。遗憾的
是，一些 SPEC程序花费的时间要比其他程序长4倍，所以如果使用算术均值作为总结性能的
唯一数值，那这些程序就太过重要了。一种替代方法是为每个基准测试增加一个加权因子，以
加权算术平均作为总结性能的唯一数值。现在的问题是如何选择权重；SPEC是由一些相互存在
竞争的公司组成的联盟，每家公司可能都有自己中意的权重集，这就很难达成一致意见。另一
种方法是在选择权重时，使所有程序在某一基准计算机上的执行时间相同，但这样会使测试结
果出现偏差，向基准计算机的性能特性靠近。

当然，也可以不选择权重，而是以基准计算机为依据，对执行时间进行归一化：将基准计
算机上的执行时间除以待评价计算机上的执行时间，得到一个与性能成正比的比值。SPEC 就是
使用这种方法，将这个比值称为 SPECRatio。这是一个特别有用的特性，与本书对比计算机性
能的方法相匹配（即比较性能比）。例如，假定在进行基准测试时，计算机A的SPECRation是
计算机B的1.25倍，于是可以计算：

\begin{verbatim}
    执行时间基洮
    1.25=SPECRatioA
    执行时间A
    SPECRation
    执行时间越雅
    -=
    执行时间 _性能A
    执行时间A
    性能B
    执行时间a
\end{verbatim}

注意，基准计算机上的执行时间会略去不计，所以在以比值形式进行比较时，基准计算机
可以任意选择，我们将一直使用这种方法。表1-8给出了一个示例。

\begin{verbatim}
    表1-8 Sun Ultra 5 （SPEC2000的基准计算机）的SPECIp2000执行时间（秒）和 AMD Opteron、
    Intel Itanium 2 的执行时间与 SPECRation
    Ultra 5 时间
    Opteron时间
    基准测试
    wupwise
    swim
    mgrid
    SPECRatio
    art
    Jucas
    …啲呵呵哎wm嗯mm呵mk咧的
    （秒）
    51.5
    125.0
    98.0
    94.0
    64.6
    86.4
    92.4
    72.6
    73.6
    136.0
    88.8
    22.52
    Itanium 2时间 sPECRation um时间（秒）SPECRation
    Opteron/ltani ltanium/Opteron
    （秒）
    56.1
    28.53
    0.92
    0.92
    70.7
    43.85
    1.77
    1.77
    65.8
    27.36
    1.49
    1.49
    50.9
    41.25
    1.85
    1.85
    108.0
    12.99
    0.60
    0.60
    40.0
    72.47
    2.16
    2.16
    21.0
    123.67
    4.40
    4.40
    36.3
    35.78
    2.00
    2.00
    86.9
    21.86
    0.8$
    0.85
    1320
    16.63
    1.03
    1.03
    107.0
    18.76
    0.83
    0.83
    ［41
    ［42］
    ［43］
    34
    第1章
    （续）
    基准剥试
    firna3d.
    sixtrack
    apsi
    Ultra 5 时间
    （秒）
    2100
    1100
    2600
    Opteron时间
    Opteron/ltani Ntaniur/Opteron
    （秒）
    SPECRatio
    Ianiug2时间 sPECRation CRNT《粉）PSPECRGROM
    120.0
    17.48
    123.0
    8.95
    150.0
    17.36
    131.0
    68.8
    231.0
    16.09
    0.92
    0.92
    15.99
    179
    1.79
    11.27
    0.65
    0.65
    几何平均值
    20.86
    27.12
    1.30
    1.30
\end{verbatim}
（SPEC2000 将执行时间的比值乘以100，以清除结果中的小教点，所以 20.86 在报告中显示为2086。）最后两列给
出执行时间和SPECRatio的比值。这一数字说明基准计算机与相对性能无关。执行时间之比与 SPECRatio 之比相同，
几何均值之比（27.12/20.86-1.30）与比值的几何均值（1.30）相等。

因为SPECRatio 是一个比值，而不是绝对执行时间，所以必须用几何平均来计算它的均
值。（由于 SPECRatio没有单位，所以以算术方式比较 SPECRatio是没有意义的。）几何平均
的公式是：

例题
几何平均= 口样本，
对于 SPEC，样本：表示第：个程序的SPECRatio。使用几何均值可以确保以下两个重要特性。
（1）这些比值的几何均值与几何均值之比相等。
（2）几何均值之比等于性能比值的几何均值，这就意味着与基准计算机的选择无关。
因此，使用几何均值的动机更为充分，特别是在使用性能比值进行对比时，尤为如此。
证明几何均值之比等于性能比值的几何平均，且与SPECRatio 基准计算机的选择
无关。
解答
假定有两个计算机A和B，每个计算机有一组 sPECRatio。
几何均值A
ITsPECRatioA，
几何均值B
" SPECRatioAL
｛SPECRatioa，
C1 SPECRat oB，
执行时间选滩
1I
执行时间AL=
注1
执行时间基推
“性能入
V占性能，
执行时间日，

即，A与B的SPECRatio的几何均值等于对A与B执行套件中所有基准测试所得
性能比的几何均值。表1-8用SPEC中的示例表明了其有效性。


\section{计算机设计的量化原理}
既然我们已经知道如何对性能、成本、可靠性、能耗和功率进行定义、测量和汇总，现在
可以开始研究在计算机设计与分析中非常有用的指导原则了。这一节将介绍有关设计的重要观
测结果，以及两个用于评估备选设计的公式。

\subsection{充分利用并行}
充分利用并行是提高性能的最重要方法之一。本书的每一章都有一个如何通过开发并行来
提高性能的示例。这里给出三个简单的例子，在后续各章会给出详细解释。

第一个例子是在系统级别开发并行。为了提高在一个典型服务器基准测试（比如SPECWeb
或TPC-C）上的吞吐量性能，可以使用多个处理器和多个磁盘。随后可以在处理器和磁盘之间
分散处理请求的工作负载，从而提高吞吐量。扩展内存以及处理器和磁盘数目的能力称为可扩
展性，这对服务器来说是非常有价值的优点。在许多磁盘之间分布数据，以实现并行读写，就
可以支持数据级并行。SPECWeb 还依靠请求级并行来使用大量处理器，而TPC-C使用线程级
并行实现对数据库请求的更快速处理。

在单独的处理器级别，充分利用指令间的并行对于实现高性能非常关键。实现这种并行的
最简单方法之一就是通过流水线。（在附录C中会更详细地解释流水线，它也是第3章的一个重
点。）流水线背后的基本思想是将指令执行重叠起来，以缩短完成指令序列的总时间。流水线能
够实现的关键是认识到并非所有执行都取决于与其直接相邻的前一条指令，所以有可能完全并
行或部分并行地执行这些指令。流水线是人们最熟悉的指令级并行示例。

在具体的数字设计级别也可以开发并行。例如，组相联（Set Associative）缓存使用多组存
储器，通常可以对它们进行并行查询，以查找所需项目。现代ALU（算术逻辑单元）使用先行
进位，这种方法使用并行来加快求和过程，使计算时间与操作数位数之间的关系由线性关系变
为对数关系。数据级并行的例子还有许多。

\subsection{局域性原理} \label{subsec:PrincipleOfLocality}

人们通过观察程序特性，已经得到了一些重要的基本事实。我们经常用到的一个最重要程
序特性是局域性原理：程序常常重复使用它们最近用过的数据和指令。一条广泛适用的经验规
律是：一个程序90\%的执行时间花费在仅10\%的代码中。局域性意味着我们可以根据一个程序
最近访问的指令和数据，比较准确地预测它近期会使用哪些内容。局域性的原理也适应于数据
访问，不过不像代码访问那样明显。

人们已经观察到两种局域性类型。时间局域性是指最近访问过的内容很可能会在短期内被
再次访问。空间局域性是指地址相互临近的项目很可能会在短时间内都被用到。我们将会在第
2 章看到这些原理的应用。

\subsection{重点关注常见情形}

最重要、最普遍的计算机设计原则可能就是重点关注常见情形：在进行设计权衡时，常见
情形优先于非常见情形。这一原则适用于资源的分配方式，如果某一情形会频繁出现，那对其
进行改进会产生更显著的效果。

对于功率、资源分配和性能，重点关注常见情形这一原则都是有效的。处理器中指令提取
与译码器的使用可能比乘法器频繁得多，所以应当优先对其进行优化。这一原则也适用于可靠
性。如果一个数据库服务器为每个处理器准备50个磁盘，那系统可靠性将主要取于存储可
靠性。

此外，常见情形经常要比非常见情景更简单一些，完成速度更快一些。比如，在处理器中
对两个数值求和时，可以预料溢出是很少出现的情形，因此可以通过优化没有溢出的更常见情
形来提高性能。强调非溢出情形可能会降低溢出情形的处理速度，但如果很少发生溢出，那整
体性能可以通过优化正常情形得以提高。

在本书中将会看到这一原则的许多示例。在应用这一简单原则时，我们必须判断常见情形
是什么，加快这一常见情形可以使性能提高多少。有一种基本定律可以用来量化这一原则，即
Amdahl 定律。

\subsection{Amdahl定律}

利用 Amdahl 定律，可以计算出通过改进计算机某一部分而能获得的性能增益。Amdabl定
律表明，使用某种快速执行模式获得的性能改进受限于可使用此种快速执行方式的时间比例。
Amdabl 定律定义了使用某一特定功能所获得的加速比（speedup）。加速比是什么？假定我
们可以对某一计算机进行某种升级，在采用这一升级时可以提高计算机的性能。加速比的定义 ：

整个任务在采用该升级时的性能
加速比=整个任务在未采用该升级时的性能

或者：

整个任务在未采用该升级时的执行时间
加速比=
整个任务在采用该升级时的执行时间

加速比告诉我们，与原计算机相比，在经过升级的计算机上运行一个任务可以加快多少。
Amdahl 定律为我们提供了一种快速方法，用来计算某一升级所得到的加速比，加速比取决
于下面两个因素。

（1） 原计算机计算时间中可升级部分所占的比例。例如，一个程序的总执行时间为60秒，
如果有20秒的执行时间可进行升级，那这个比例就是20/60。我们将这个值称为升级比例，它
总是小于或等于1。
（2） 通过升级执行模式得到的改进，也就是说在为整个程序使用这一执行模式时，任务的运
行速度会提高多少倍。这个值等于原模式的执行时间除以升级模式的执行时间。如果为程序的
某一部分采用升级模式后需要2秒，而在原始模式中需要5秒，则提升值为5/2。我们将这个值
称为升级加速比，它总是大于1。

原计算机采用升级模式后的执行时间等于该计算机未升级部分耗用的时间加上使用升级部
分耗用的时间：

例题
新执行时间=原执行时间x（I-升级比例）+
总加速比是这两个执行时间之比：
总加速比=原执行时间=-
1
新执行时间
升级比例
（1-升级比例）+一
升级加速比

假设我们希望升级一个用于提供 Web 服务的处理器。新处理器执行Web 服务应用
程序的计算速度是原处理器的10倍。假定原处理器有40\%的时间忙于计算，60\%
的时间等待1/O，进行这一升级后，所得到的总加速比为多少？
解答
升级比例=0.4、升级加速比=10、总加速比=—
0.40
1
-21.56
0.64
0.6+
10

Amdahl 定律阐述了一个回报递减规律：如果仅改进一部分计算的性能，在增加改进时，所
获得的加速比增量会逐渐减小。Amdahl定律有一个重要推论：若某一升级仅对一项任务的一部
分适用，则该任务的总加速比不会超过一个数值，该数值即1减去未升级部分所占比例，再取
其倒数。

在应用 Amdahl 定律时的一个常见错误是混淆“可升级部分在升级之前所占时间比例” 和
“升级部分在升级之后所占时间比例”。如果我们测量的不是计算中可以应用该升级的时间，而
是测试应用升级之后的时间，结果就是错误的！

Amdahil 定律可用来判断某项升级能使性能提高多少，以及如何分配资源来提高性价比。分
配目标显然是：某一部分的升级资源应当与这一部分原来花费的时间成比例。Amdahl定律对于比
较两种系统的整体系统性能尤其有用，不过也可用于比较两种处理器设计，如下面的例子所示。
例题

图形处理器中经常需要的一种转换是求平方根。浮点（FP）平方根的实现在性能
方面有很大差异，特别是在为图形设计的处理器中，尤为明显。假设FP 平方根
（FPSQR）占用一项关键图形基准测试中20\%的执行时间。有一项提议：升级
FPSQR 硬件，使这一运算速度提高到原来的10倍。另一项提议是让图形处理器
中所有 FP指令的运行速度提高到原来的1.6倍，FP指令占用该应用程序一半的执
行时间。设计团队相信，他们使所有FP指令执行速度提高到1.6倍所需要的工作
量与加快平方根运算的工作量相同。试比较这两种设计方案。

解答
可以通过计算加速比来对比两种方案：
1
加速比FPSQR
-=1.22
0.2
0.82
（1-0.2）＋
10
1
加速比pp=
=1.23
0.5
0.8125
（-0.5+1.6
提高整体 FP运算的性能要稍好一些，原因是它的使用频率较高。

Amdahl定律的适用范围不仅限于性能。我们重做1.7节的可靠性例题，通过冗余来提高电
源可靠性，将 MTTF 从 200 000小时提高到830000000小时，达到4150多倍。

例题
磁盘子系统故障率的计算为：
故障率系统=10×一
i000000+
500000 200000
1
200000
1
1 000000
10+2+5+5+1
23
1 000000小时
一1000000小时
因此，可改进的故障率比例就是5次/百万小时占整个系统23次/百万小时的比例，
即 0.22。
47
48
38
解答
弟1平 重化攻计一10m加
可靠性的改进为：
改进山源 =—
1
0.22
=1
=1.28
（1-0.22）+4150
0.78
尽管一个模块的可靠性提高了4150倍之巨，但从系统的角度来看，这一改变所带
来的好处虽然可测，但数值很小。

在上面的几个例子中，我们需要知道改进后的新版本所占比例；这些时间一般是很难直接
测量的。在下一节，我们将看到另外一种比较方法：利用一个公式将 CPU执行时间分解为三个
独立分量。如果我们知道一种候选方案是如何影响这三个分量的，就可以判断它的整体性能。
另外，通常可以构建一个模拟器，在实际设计硬件之前先测量这些分量。

\subsection{处理器性能公式}
几乎所有计算机都有一个以固定频率运行的时钟。这些离散时间事件称为：嘀嗒、时钟嘀
嗒、时钟周期、时钟、脉冲周期等。计算机设计人员用时钟周期的持续时间（例如，1ns）或
其频率（例如，1GHz）来描述时钟周期的时间。程序的CPU时间可以有两种表示方法：

CPU 时间=程序的CPU时钟問期数 ×时钟間期时间
或者
CPU时间三程序的CPU时间周期数
时间频率

除了执行一个程序所需要的时钟周期数之外，我们还会计算所执行的指令数：指令路径长
度或指令数（IC）。如果我们知道时钟周期数和指令数，就可以计算每条指令时钟周期数（CPI）
的平均值。由于这个指标便于使用，也因为这一章讨论的处理器比较简单，所以我们使用CPI。
设计人员有时也将它称为每时钟周期指令数（IPC），它是CPI的倒数。

CPI 的计算公式为：

CPI=程序的CPU时钟周期数
指令数

通过这个处理器指标值可以深人了解不同类型的指令集和实现方式，在后续四章中将广泛使用
这一指标。

变换以下公式中的指令数，时钟周期可以定义为 IC×CPl。这样就可以在执行时间公式中
使用 CPI：

CPU 时间=指令数×CPI x时钟周期时间
将第一个公式按测试单位展开，可以看到各部分是如何组合在一起的：

从这个公式可以看出，处理器性能取决于三个特性：时钟周期（或时钟频率）、每条指令的时钟
周期和指令数。此外，CPU时间同等取决于这三个特性；例如，三个特性中任一项改进10%，
将使 CPU时间改进10%。

遗憾的是，用于改变这三项特性的基本技术都是相互关联的，所以很难在不改变其他两个
参数的情况下改变其中一个参数。

\begin{itemize}
    \item 时钟周期时间：硬件技术与组成。
    \item CPI：组成与指令集体系结构。
    \item 指令数：指令集体系结构和编译器技术。
\end{itemize}

幸运的是，许多可能采用的性能改进技术都是主要改进处理器性能的一个分量，而对其他两个［49］
分量的影响较小或在可预测范围内。

有时，在设计处理器时，采用以下公式计算处理器总时钟周期数目会有所帮助：
CPU时钟厲期-名1G×CPL，
式中，IC：表示一个程序中第；个指令的执行次数，CPI，表示第：个指令的每条指令平均时钟周
期数。这一形式可用来将 CPU 时间表示为：
CPU时间=
c.xcP, k时钟两期时间
总CPI为：
ZIC，×CPI，
CPI=上）
背令数
一-名和公街XCPI
CPI 的后一种计算形式使用了各个CPI，和该指令在一个程序中所占的比例（即，IC；除以指令数）。
CPI 应当通过测量得出，而不是根据一个参考手册后面的表格来进行计算，这是因为它必须包
括流水线效应、缓存缺失和存储系统的任何其他低效特性。

考虑1.9.4节的性能示例，这里改为使用指令执行频率的测试值和指令CPI 测量值，在实际
中，后者是通过模拟或硬件仪器获得的。

例题
假设已经进行以下测量：
FP 操作频率=25%
FP操作的平坞CPI=4.0
其他指令的平均CPI=1.33
FPSQR 的频率=2%
FPSQR 的CP1-20
假定有两种设计方案，一种方案将 FPSQR的CPI降至2，一种是把所有FP換作的
平均CPI降至2.5。请使用处理器性能公式对比这两种设计方案。
解答
首先，观察到仅有CPI发生变化；时钟频率和指令数保持不变。我们首先求出没
有任何改进时的原 CPI：
CPiw-客cP（看冬取）
= （4×25%）+（1.33×75%）=2.0
从原 CPI 中减去节省的周期数就可以求出改进FPSQR后的CPI：
CPI 果用新 FPSQR=CPI 原 -2% × （CPI HFPSQR - CPI 仪新EPSOR）
=2.0-2%×（20-2）=1.64
我们可以采用相同方式来计算对所有 FP 指令进行改进后的 CPI，也可以将 FP 和
非FP CPI相加。采用后一种方法，将得到：
［S0］
51
CPI折TP=（75% × 1.33）+ （25%×2.5）=1.625
由于总 FP改进的CPI稍低一些，所以它的性能也稍好一点。具体来说，总 FP 改
进的加速比为：
加速比 印P CPU时间
CPU时间際=-
ICx时钟周期xCPI脱
ICx时钟周期×CPL新FP
C =！
2.00
一=1.23
CPl都rp
1.625
令人开心的是，我们使用1.9.4 节的 Amdabl 定律得到了同一加速比。

要测量处理器性能公式的各个组成部分，通常是可能做到的。与前面例子中的Amdahl定
律相比，这是使用处理器性能公式的重要优势之一。具体来说，有些东西可能很难测量，比如
一组指令的执行时间在总执行时间中所占的比例。在实际计算中，一般是对指令数与集中每一
指令的CPI乘积进行求和得到。由于计算过程通常是从测量各个指令数目和CPI开始的，所以
处理器性能公式就更为有用。

要把处理器性能公式用作一种设计工具，需要能够测量各种因素。对于已有处理器来说，
很容易通过测量来获得执行时间，而且我们知道默认的时钟速度。问题在于如何求得指令数或
CPI。大多数新处理器中都包含对所执行指令和时钟周期进行计数的计数器。通过定期观察这些
计数器，还可以将执行时间和指令数与代码段关联在一起，如果程序员希望了解应用程序的性
能并对其进行调优，那可能会有所帮助。通常，设计人员或程序员都希望更深入地了解性能，
而不仅限于硬件计数器提供的信息。比如，他们可能希望知道CPI 为什么是现在这种状况。在
这种情况下，就要采用一些模拟技术，这些技术类似于正在设计的处理器所采用的技术。

有些能够提高能耗效率的技术，比如动态电压频率调整和超频（见1.5节），会增加这个公
式的使用难度，在对程序进行测量时，时钟速度可能会发生变化。一种简单的方法是关闭这些
功能，从而使结果能够重现。幸运的是，由于性能和能耗效率之间通常具有非常密切的联系（在
短时间内完成一个程序，通常就可以节省能量），所以在评估性能时不考虑 DVFS或超频对结果
的影响，也是可行的。

\section{融会贯通：性能、价格和功耗}
在每章末尾的“融会贯通”小节中，我们提供了一些利用该章基本原理的真实示例。本节，
我们将研究如何使用SPECpower 基准测试对一些小型服务器测量性能和功率性能。

表1-9给出我们正在评估的三个多核服务器及其价格。为了保持价格对比的公平，所有服务
器都是 Dell PowerEdge 服务器。第一台是 PowerEdge R710，它的微处理器为 Intel Xeon X5670，时
钟频率为 2.93 GHz。这个 Intel 芯片有6个核心和1个12 MB L3缓存，不同于第2章到第5章的
Intel Core i7，后者有4个核心和一个8MB L3缓存，不过这些核心本身是一样的。我们选择了一
个两插槽系统，装有12G受ECC保护的1333 MHzDDR3 DRAM。第二台服务器是PowerEdge R815，
它的微处理器是 AMID Opteron 6174微处理器。这一芯片拥有6个核心和一个 6MBL3缓存，其运
行频率为 2.20GHz，不过AMID在一个插槽中放了2个芯片。因此，一个插槽拥有12个核心和2
个6MB L3缓存。我们的第二服务器有两个插槽，共有12个核心和16GB受ECC保护的1333 MHz
DDR3 DRAM，第三台服务器（也是 PowerEdge R815）有四个插槽，共48个核心和 32 GB DRAM。
所有这些服务器都运行 IBM J9JM和 Microsoft Windows 2008 Server x64企业版。

\begin{verbatim}
    表1-9 三个Dell PowerEdge被测服多及2010年8月的各自价格
    系统1
    系统2
    系统3
    组件
    基本服务器
    一
    电源
    处理器
    成本（%成本）
    PowerEdge
    $6$3 （7%）
    R710
    s70w
    Xeon
    $3738（40%）
    ×$670
    2.93 GHZ
    12
    PowerBdge
    R815
    1100W
    成本（%成本）
    $1437（15%）
    成本（%成本）
    PowerEdge
    $1437 （11%）
    R815
    1100W
    $2679 （29%）
    $5358 （42%）
    肘钟频率
    核心总数
    插槽数
    核心/插槽
    DRAM
    以太网
    磁盘
    6
    12 GB
    双 1Gbit
    50 GB SSD
    $484 （5%）
    $199 （2%）
    $1279 （14%）
    $2999 （32%）
    $9352 （100%）
    2.20 GHz
    24
    2
    12
    16GB
    双1Gbit
    50 GB SSD
    $693（7%）
    $199 （2%）
    $1279 （14%）
    $2999 （33%）
    $9286 （100%）
    2.20 GHz
    48
    4
    12
    32 GB
    双 1Gbit
    50 GB SSD
    Windows 操作系统
    总值
    $1386 （11%）
    $199 （2%）
    $1279 （10%）
    $2999 （24%）
    $12658（100%）
    最大\verb|ssj_ops|
    910978
    926 676
    最大\verb|ssj_ops|/$
    97
    100
    1840450
    145
\end{verbatim}
*我们在计算处理器的成本时减去了第二个处理器的成本。与此类似，通过查看额外存储器的成本来计算存储器的总
成本。因此，通过减去默认处理器和存储器的估计成本，调整服务器的基础成本。第5 章介绍这些多插槽系統是咖
何连接在一起的。

注意，由于基准测试的压力（见1.11 节），这些服务器的配置不同寻常。与计算量相比，
表1-9中的系统在存储器方面比较可怜，只有一个很小的50GB 固态磁盘。如果不需要相应增
加内存和存储，添加核心的费用是比较便宜的。

SPEC CPU不是运行静态链接的C程序，而是一种使用Java编写的更加现代化的软件栈。
它的基础是 SPECjbb，代表着业务应用程序的服务器端，性能的测量以每秒完成的事务数为单
位，称为 \verb|ssi_ops| （ server side Java operations per second，每秒完成的服务器端 Java操作）。它不
仅和SPECCPU一样，测试服务器的处理器，还会测试缓存、存储器系统，甚至还包括多处理
器互连系统。除此之外，它还会测试 Java 虚拟机（JVM），包括 JIT运行库编译器和垃圾回收器，
还有底层操作系统的相关部分。

如表1-9的最后两行所示，在性能和性价比方面的优胜者是拥有四个插槽和48个核心的
PowerEdge R815。它达到了 1.8M \verb|ssj_ops|，每美元的 \verb|ssj_ops| 达到了最高的145。令人惊讶的是，
核心数目最多的计算机其成本效率竟然最高。处在第二位的是具有24个核心的两插槽 R815，
拥有12个核心的R710处在最后一位。

尽管大多数基准测试（以及大多数计算机架构）都只关心峰值负载时的系统性能，但计算
机实际上很少运行在峰值负载状态。事实上，第6章的表6-2显示了 Google 数万个服务器六个
多月使用情况的测量结果，平均利用率为100\%的服务器只有不到1\%。大多数服务器的平均利
用率介于 10\%到50\%之间。因此，SPECpower 基准测试在收集功率信息时，将目标工作负载从
其峰值开始，以10\%为间隔，一直降至 0\%，工作负载为0\%时的状态称为“活联空闲”。

图1-10绘制了每瓦的 \verb|ssj_ops| （SSJ操作/秒）以及目标负载从100\%变到0\%时的平均功率。
在每个目标工作负载级别，Intel R710的功率总是最低，\verb|ssj_ops|/瓦总是最佳。一个原因是 R815
的电源功率要大得多，为1100瓦，而R715 的功率为570瓦。如第6章所示，电源效率在一个
计算机的总功率效率中非常重要。由于1瓦=焦/耳，这个度量与每焦耳的SSJ操作成正比。

图1-10
表1-9中3个服务器的功率效率。\verb|ssj_ops|/瓦值放在左坐标轴上，有3个柱形与它相关联，瓦数
表示在右坐标轴上，有三条线与它相关联。水平轴显示目标工作负载，从100\%变化到“活跃空闲”。
在每个工作负载级别，Intel 的 R715 都具有最佳\verb|ssj_ops|/瓦，而且它在每个级别消耗的功率也最低
\begin{verbatim}
    \verb|ssj_ops|/秒
    秒_s9j ops /秒
    砂=\verb|ssj_ops|
    瓦
    焦/秒
    焦
    为了计算出一个数字，用来对比系统的功率效率，SPECpower 使用：
    总\verb|ssj_ops|/瓦=Zsi_ops
    Z功率
\end{verbatim}

这3个服务器的总 \verb|ssj_ops|/瓦分别是：Intel R710为 3034、AMI双插槽 R815 为2357、AMDD四
插槽 R815 为 2696。因此，Intel R710具有最佳功率效率。除以服务器的价格之后，Intel R710
的\verb|ssj_ops|/瓦/1000美元324、双插槽 AMD R815为254、四插槽 MIDR815为213。因此，增
加功率会反转性价比竞赛的结果，Intel R710荣获价格-功率-性能的奖杯，而48核的R815垫底。

\section{谬论与易犯错误}
在每一章都会有这样一节，其目的是解释读者应当避免的常见错误观念或误解。我们将此
类错误观念称为谬论。我们在讨论谬论时，会尝试给出一个反例。我们还会讨论易犯错误。一
般来说，谬论是随意推广一些在特定环境中才成立的原理而造成的。这些小节的目的是帮助读
者避免在自己设计的计算机中犯这些错误。

\textbf{谬论 多处理器是万能钥匙。}

2005年左右之所以转向一芯多核，并不是因为取得了什么重大突破，显著简化了并行编程
方式，或者使多核计算机的生产变得简单。之所以发生这种变化，就是因为 ILP壁垒和功率壁
垒的存在而别无选择。在一个芯片中设计多个处理器并不能保证功率较低，而的确有可能设计
一种消耗更高功率的多核芯片。其潜力仅仅在于能够用几个低时钟频率的高效核心代替高时钟
频率的低效核心，从而有可能继续提高效率。随着技术的发展，晶体管变得更小，使电容和电
压都可以稍有下降，从而可以使每一代核心数目都会有适度提高。例如，在最近几年里，Intel
每更新一代增加两个核心。

在第4 章和第5 章将会看到，性能现在已经成为程序员的负担。单靠硬件设计人员，不费
吹灰之力就能加快程序运行速度的L.a-2-Boy®程序员时代，已经正式结束了。如果程序员希望自
己的程序在每一代处理器上都能更快速地运行，他们必须提高自己程序的并行度。

摩尔定律的通俗版本（即用每一代新技术来提高性能）现在摆在了程序员的面前。

\textbf{易犯错误 Amdahl心碎定律的牺牲品。}

几乎每一位有实践经验的计算机架构师都知道 Amdahl 定律。尽管如此，我们几乎都曾经在
测量某一功能的使用之前，花费大量力气来对其进行优化。只有在总加速比让人感到失望时，
才会想起在花费如此之多的精力进行改进之前，应当先对其进行测量。

\textbf{易犯错误 单点故障。}

利用1.9.4节的 Amdahl 定律来计算可靠性改进，可以发现可靠性不再是链子中最薄弱的一
环了。无论我们让电源变得多么可靠（就像例子中那样），磁盘子系统的可靠性也会因为仅有一
个风扇而受到限制。通过观察 Amdahil 定律得出一个有关容错系统的经验法则，那就是确保所
有组件都有冗余，使单一组件故障不会导致整个系统宕机。第6 章说明软件层如何避免仓库级
计算机内部出现单点故障。

\textbf{谬论 能够提高性能的硬件改进也可以提高能耗效率，至少不会加大能耗。}

Esmaeilzadeh 等人［2011］在一个使用Turbo 模式（1.5节）的 2.67 GHz Intel Core i7上进行
SPEC2006测试。当时钟频率增加到 2.94GHz（1.10倍）时，性能提高到原来的1.07倍，但消
耗的功率超过原来的1.37倍，能耗超过原来的1.47倍。

\textbf{谬论 基准测试永远有效。}

有几个因素会影响到一个基准测试在预测实际性能方面的有效性，其中一些因素是随时间
变化的。一个影响基准测试有效性的重要因素是它要能够对抗“基准测试工程”或“基准测试
技巧”。一旦某项基准测试变为标准普及测试，人们感受到提高性能的巨大压力，于是就可能进
行有针对性的优化，或者对基准测试的运行规则作出对自己有利的主动解读。一些在少量代码
上花费大量时间的小型内核或程序尤其缺乏这种免疫力。

 La-Z-Boy 是美国知名的家具公司，其生产的“懒汉椅”在美国家喻户晓。编者注

例如，最初的 SPEC89基准测试套件中包括一个名为 matrix300的小型内核，它由8个不同
的300x300短阵乘法组成（当然最初包含这个小型内核的出发点是好的）。在这个内核中，99%
的执行时间用于运行一行代码（见SPEC［1989］）。当一个 IBM编译器针对这一内部循环进行优
化后（采用一种名为分块的思想，在第2章和第4章中详细讨论），其性能提高到该编译器上一
版本的9倍！这个基准测试程序测试的是编译器的调优情况，当然不能很好地表征警体性能，
也不是这一具体优化的典型值。

经过很长一段时间之后，这些修改甚至会让一个精心选择的基准测试被迫弃用；gcc是
SPEC89中的长期幸运者。图1-9列出了各种SPEC版本中所有70个基准测试的状态。令人惊
讶的是，在SPEC2000（或更早版本）的所有程序中，大约70\%都会在新一版中被弃用。
谬论 磁盘的额定平均无故障时间为1200 000小时，差不多是140年，所以磁盘实际上永远
不会发生故障。

磁盘制造商现在采用的一些营销手段可能会误导用户。这样一个 MTTF 是如何计算得到
的呢？在早期过程中，制造商将数千个磁盘放在一个房间里，运行几个月的时间，记下故障
磁盘的数目。他们计算 MTTF的方法是将所有这些磁盘的累积工作小时数除以发生故障的磁
盘数目。

这里的问题是，这个数字远远超过了磁盘的寿命（人们通常认为一个磁盘的寿命为5年或
43800小时）。为了使这个巨大的 MTTF数字还有点意义，磁盘制造商宣称这个模型适用于那些
购买磁盘后每5年更换一次的用户（这里的5年就是磁盘的预期寿命）。这种声明是说，如果许
多客户（和他们的曾孙）到下一个世纪都还坚持这种做法，那在发生故障之前，他们要更換27
次磁盘，也就是大约140年的时间。

一个更有用的测量数字应当是故障磁盘的百分比。假定有1000个 MTTF为1000 000 小时
的磁盘，这些磁盘每天使用24小时。如果用一个具有相同可靠特性的新磁盘更換故障磁盘，那
在一年中（8760个小时）发生故障的磁盘数目为：

故障磁盘数=磁盘数x时间-1000个磁盘x8760小时/原动器=9
1 000 000小时/故障

或者说，每年将有0.9\%的磁盘发生故障，或者说在5年的寿命期中有4.4\%的磁盘发生故障。
另外，这些很大的数字是在假定温度与振动范围有限的情况下得到的，如果超过这些范围，
那就不一定会是什么样的结果了。对实际环境中磁盘驱动器的一次调查［Gray 和 van Ingen 2005］
发现：每年有3\%~7\%的磁盘驱动器发生故障，MTTF 大约为125000到300000小时。一个更
大型的调查发现每年的磁盘故障率为2\%~ 10\%［Pinheiro、Weber 和 Barroso 2007］。因此，实际
MTTF大约要比制造商宣称的MTTF差2~10倍。

\textbf{谬论 峰值性能能够反映实际观测性能。}

峰值性能唯一适用的定义是：“计算机肯定不会超越的性能水平”。图1-11 给出了4个程序
在4个多处理器上的运行性能占峰值性能的百分比。其变化范围为5\%~58\%。由于这个间距如此
之大，而且可能受到基准测试的显著影响，所以峰值性能对于预测实际观测性能一般没有什么用。

图1-11 4个程序在4个多处理器上的运行性能占峰值性能的百分比（峰值性能系在64 个处理器获得）。
Earth Simultor和X1为向量处理器（见第4章和附录G）。它们不仅提供了较高的峰值性能比例，
而且也具有最高的峰值性能和最低的时钟频率。除了 Paratec 程序之外，Power 4 和Itanium 2系
统提供的性能占其峰值功能的5\%到10\%之间。数据来自 Oliker等人［2004］

\textbf{易犯错误 故障检测会降低可用性。}

之所以会出现这一明显与事实相反的错误，是因为计算机硬件的状态中，有相当一部分并
非总会对计算机的正常运行产生关键性影响。例如，如果分支预测器中发生错误，可能不会产
生致命性的后果，而只是使性能受损。

在那些积极开发指令级并行的处理器中，并不是所有操作都需要程序的正确执行。
Mukherjee 等人［2003］发现，对于在 Itanium 2上运行的SPEC2000 基准测试，只有不到30\%的操
作可能处在关键路径上。

这一观察结果对程序也是成立的。如果程序中的一个寄存器“死亡”（也就是说，这个程序
在再次读取该寄存器之前会先向其写人内容），那寄存器中发生错误就没有什么关系。如果在一
个死亡寄存器中检查到晶体管错误就要终止程序，那才会不必要地降低可用性。

Sun 公司在2000年就犯了这样一个错误，它在 Sun E3000 至 Sun E10000系统中使用了一
个包含奇偶校验却无法纠错的L2缓存。他们用于构造这些缓存的SRAM 有一些可用奇偶校验
检测到的间歇性故障。如果缓存中的数据未被修改，则处理器直接从缓存中重新读取数据。由
于设计人员没有用 ECC（纠错码）来保护缓存，所以操作系统别无选择，只能报告脏数据错
误，并终止程序。现场工程师在实地查看时发现，90\%以上的此种情况都不存在问题。

为了减少出现此类错误的频率，Sun 修改了 Solaris 操作系统，为它添加了一个主动将
脏数据写到存储器的进程，从而“洗净”缓存。由于处理器芯片没有足够的管脚用于添加
ECC，所以对于脏数据的唯一硬件选项就是复制外部缓存，使用没有奇偶错误的副本来纠正
这些错误。

这种易犯错误在于检测了错误却没有提供纠正错误的机制。这些工程师不大可能再设计另
一个没有对外部缓存提供ECC保护的计算机了。

\section{结语}
这一章已经介绍了大量概念，并提供了一种量化框架，我们将在本书中对其进行扩展。从
这一版开始，在讨论性能时将会增加能耗效率这一指标。

在第2章，我们将开始讨论存储器设计的所有重要内容。我们将研究各种技术，这些技术
同心协力，让存储器看起来有无限大，同时还能尽可能保持快速。（附录B 为没有太多经验和
背景知识的读者提供了有关缓存的介绍性材料。）在后面各章中，我们将看到硬件与软件的结合
已经成为高性能存储器系统的关键，就如同它们是高性能流水线的关键一样。这一章还将介绍
虚拟机，这种保护技术的重要性正在与日俱增。

在第 3章，我们将研究指令级并行（ILP），流水线是它的最简单、最常见形式。ILP 的开
发是构建高速单处理器的最重要技术之一。第3章首先对基础概念展开广泛讨论，为本章及第
4章研究的大量思想奠定基础。第3章使用的例子跨度差不多有40年，来源范围从第一代超级
计算机（IBM360/91）到2011年市场上的最快速处理器。它强调了一种开发 ILP的方法，称为
动态方法或运行时方法。它还讨论了IP思想的局限性，并介绍了多线程，在第4 章和第5章
将深入展开这一内容。附录C为那些没有太多流水线经验和背景知识的读者提供了有关流水线
的介绍性材料。（我们认为这一内容可以帮助许多读者来复习流水线知识，包括我们编写的人门
教材—《计算机组成与设计：硬件/软件接口》）。

第4章是这一版的新增内容，它解释了三种开发数据级并行的方法。其中最经典、最早的
方法是向量体系结构，我们首先从这里人手，给出 SIMID 设计的基本原理。（附录G将更深人
地讨论向量体系结构。）接下来解释当今大多数桌面微处理器都存在的 SIMD 指令集扩展。4.4
节详细解释了现代图形处理器（GPU）的工作方式。大多数GPU 说明文字都是从程序员的角度
撰写的，通常隐藏了计算机的实际工作方式。这一部分从内部知情人的角度解释GPU，包括
GPU术语与更传统的体系结构术语之间的对应关系。

第5章主要讨论使用多个处理器（或称多处理器）实现更高性能的问题。多重处理采用并
行机制不是为了重叠各个指令的执行过程，而是允许同时在不同处理器上执行多个指令流。我
们的重点是多处理器的主要形式—共享存储器多处理器，当然，我们也会介绍其他一些类型，
并讨论在所有多处理器都会出现的主要问题。我们还是会研究各种技术，重点放在20世纪80
年代到20世纪90年代首次提出的重要思想上。

第6 章也是这一版新增加的内容。我们介绍了集群，然后深人讨论仓库级计算（WSC），
它是由计算机架构师帮助设计的。WSC的设计人员是超级计算机先驱（比如 Seymour Cray）的
专业接班人，因为他们也正在设计超大型计算机。这些仓库级计算机中包含成千上万的服务器，
容纳它们的设备和机房需要近2亿美元。前面各章对性价比和能耗效率的关注也适用于WSC，
量化的決策方法也同样适用。

本书提供了丰富的线上材料（详细介绍请见“前言”部分），以便在降低成本的同时还能向
读者介绍大量高深主题。表1-10列出了所有这些内容。以印刷方式出现在本书中的附录A、B、
C可供许多读者回顾相关知识。

\begin{verbatim}
    表1-10 附录清单
    附
    景
    题
    目
    A
    B
    指令集基本原理
    存储器层级结构回顾
    CDEE
    流水线：基础概念与中级概念
    存储系統
    嵌人式系统
    互连网络
    深人讨论向量处理器
    VLIW和EPIC的硬件与软件
    大规模多处理器和科学应用
    计算机算法
    K
    L
    指令集体系结构调查
    历史回顾与参考文献
\end{verbatim}
在附录D中，我们离开以处理器为中心的视点，转而讨论存储系统中的问题。我们采用了
一种类似的量化方法，但这种方法主要依靠对系统行为的观察，并使用端到端方法进行性能分
析。它解决了如何主要使用低成本磁存储技术来实现高效数据存储与提取的重要问题。重点是
研究磁盘存储系统对典型 I/O 密集型工作负载的性能，比如本章介绍的 OLTP 基准测试。我们
将广泛研究 RAID 系统中的高级主题，这种系统使用冗余磁盘来同时获得高性能和高可用性。
最后，这一章介绍了排队理论，为权衡利用率与延迟奠定基础。

附录E从嵌入式计算的角度来研究前面每一章、每个附录中介绍的思想。

附录F广泛讨论系统互连内容，包括实现计算机通信的广域网和系统域网络。

附录H回顾了VLIW硬件和软件，与本书上一版出版之前EPIC出现时相比，VLIW 的流
行度已经有所降低了。

附录1描述了在高性能计算中使用的大规模多处理器。

附录J是唯一从第一版一直保留下来的附录，介绍了计算机算法。

附录K提供了一份关于指令体系结构的调查报告，包括80x86、IBM360和 VAX，还有许
多RISC体系结构，包括 ARM、MIPS、Power 和 SPARC。

下面介绍附录L。

\section{历史回顾与参考文献}
附录L从历史角度回顾了本书每一章中介绍的重要思想。这些历史回顾可以让我们通过一
系列计算机或重大项目的介绍来了解一种思想的发展历程。如果你想研究一种思想或机器的最
初发展，或者希望扩展阅读，可以参见每段历史介绍的未尾提供的参考文献。关于本章，可参
见附录L.2节（The Early Development of Computers，计算机的早期发展），其中讨论了数字计
算机及性能测量方法的早期发展。

在阅读这些历史资料时，你很快就会意识到，与许多其他工程领域相比，计算科学是如此
“年轻”，它的重要优势之一就是许多先驱仍然健在—我们可以直接向他们了解历史！

案例研究与练习（Diana Franklin 设计）
案例研究1：芯片制造成本
本案例研究说明的概念
口 制造成本
口制造成品率
口 以冗余容忍缺陷
计算机芯片的价格中涉及许多因素。新的小型化技术大幅提升了芯片性能，降低了所需要的芯片面
积。采用小型化技术，人们可以缩小芯片的面积或者在芯片上放置更多硬件，从而实现更多功能。在这个
研究案例中，我们将研究包括制造技术、芯片面积和冗余在内的各种不同设计决策是如何影响芯片成本的，
见表1-11。
表1-11 几种现代处理器的制造成本困素
芯
片
IBM PowerS
Sun Niagara
AMD Opteron
晶片尺寸（mm2）
389
380
199
估测缺陷率（每cm2）
0.30
0.75
0.75
制程（nm）
130
90
90
晶体管数（百万个）
276
279
233
1.1
［10/10］<1.6>表1-11给出了影响几种当前芯片成本的相关芯片统计数字。在下面几个练习中，
我们将研究IBM Power5 的不同设计决策所产生的影响。
8.［10］<1.6>IBM Power5 的成品率是多少？
b.［10］ <1.6>为什么IBM Power5 的缺陷率要低于 Niagara 和 Opteron？
1.2
［20/20/20/20］<1.6>建造一套新的制造设备需要10亿美元。我们将销售由这家工厂生成的一系
列芯片，需要决定每种芯片的生产量。Woods芯片的大小为150 mm‘，每个无峡陷芯片的利润
为20美元。Markon 芯片的大小为250mm’，每个无峡陷芯片的利润为25美元。这套制造设备
与 Power5 的制造设备相同。每个晶圆的直径为300 mm。
a. ［20］<1.6>如果制造 Woods 芯片，每个晶圆的利润为多少？
b.［20］<1.6>如果制造Markon 芯片，每个晶圆的利润为多少？
c.［20］<1.6>我们应当用这套设备生产哪种芯片？
d. ［20］ <1.6~每种新Power5芯片的利润是多少？如果Woods芯片的月需求量为50000个，Markon
芯片为25000个，而这套设备一个月可以生产150个晶圆，如何分配这些晶圆？
1.3
［20/20］<1.6>AMD公司的一位同事建议：由于成品率如此之低，所以如果在晶片上再放一个核
心，只有那些两个处理器都失效的芯片才被扔掉，那就有可能降低芯片的制造成本。为了完成
这个练习，我们将成品率看作是在给定缺陷率下，特定区域未发生敏陷的概率。分别基于每种
Opteron 核心计算概率（这种计算方法可能不完全准确，成品率公式是根据实验证据得出的，而
不是根据芯片不同部分出现错误的概率，再经过数学计算得出的）。
2.［20］<1.6>在两个处理器核心中，敏陷核心数不超过一个的概率是多少？
b.［201<1.6~如果每个旧芯片的成本为20美元，考虑到新的芯片面积和成品率，新芯片的成本
应当是多少？
案例研究 2：计算机系统中的功耗
本案例研究说明的概念
口 Amdabi定律
D1ana trankiun 攻™T ）
4y
口冗余
O MTTF
口 功耗
现代系统中的功率取决于多种因素，包括芯片时钟频率、效率、磁盘驱动器速度、磁盘驱动器使用
率和 DRAM。下面的练习研究不同设计决策和使用情景对功率的影晌。
1.4
［20/10/20］<1.5>表1-12给出了几种计算机系统组件的功耗。在这个练习中，我们将研究硬盘驱
动器是如何影响系统功耗的。
a. ［20］ <1.5>假定每个组件的负载最大，且电源效率为 80%，有一系统，采用 Intel Pentium 4芯
片，2GB 240管脚金士顿 DRAM 和一个7200rpm的硬盘驱动器，问服务器电源必须向这个
系统提供的功率为多少瓦？
b.［10］<1.5>如果这个7200rpm 磁盘驱动器的空闲时间大约占60%，则它会消耗多少功率？
c.［20］<1.5>假定从一个7200rpm磁盘驱动器读取数据的时间大约是5400 rpm磁盘读取时间的
75%，7200rpm磁盘的空闲时间占多大比例时，两个磁盘的平均功耗相等吗？
1.5
［10/10/20］<1.5>在为服务器场供电时，一个至关重要的因素就是冷却。如果不能有效地使计算
机散热，风扇就会把热空气而不是冷空气吹回计算机。我们将研究各种不同设计决策如何影响
一个系统的必要冷却方式，从而影响它的价格。请使用表1-12 进行功率计算。
a.［10］<1.5>机架上安装一个冷却门的成本是4000美元，可以消散14KW（向室内散热；向室
外散热需要增加成本）。如果服务器采用 Intel Pentium 4处理器，1GB 240管脚DRAM和一
个7200rpm硬盘驱动器，那么一个冷却门可以冷却多少个服务器？
b.［10］ <1.5>我们正在考虑为硬盘驱动器提供容错功能。RAID1将磁盘数目加倍（见第6章）。
现在，一个只有一个冷却器的机架中可以放人多少个系统？
c.［20］<1.5>典型的服务器场每平方英尺可以消耗最多200W的热量。如果一个服务器机架需要
11平方英尺（包括前后间隙），在一个机架内可以放人多少个第（a）步中提到的服务器？需要
多少个冷却门？
表1-12 几种计算机组件的功耗
组件类型
处理器
产品
性能
Sun Niagara B-core
1.2 GHz
Intel Pentium 4
2 GHz
DRAM
金士顿X64C3AD21GB
184个管脚
金士顿D2N31GB
240个管脚
硬盘驱动器
DiamondMax 16
5400 rpm
DiamondMiax9
7200 tpm
功率
72~79W（峰值）
48.9~66 W
3.7W
2.3W
读取/寻道时7.0W，空闲时2.9W
读取/寻道时7.9W，空闲时4.0W
1.6［讨论］<1.8>表1-13给出了几种基准测试对两个服务器的功率和性能进行对比的结果。两个服务
器分别为 Sun Fire T2000（采用 Niagara）和TBM ×346（使用 Intel Xeon处理器）。这一信息曾
在 Sun Web 网站上发布。共发布了两条信息：两个基准测试的功率和速度。对于所示结果，Sun
Fire T2000显然要更好一些。还有其他哪些因素也很重要，会使一些人因为IBM x346在这些领
域有出众表现而选择它？
功率（瓦）
SPECjbb（操作数/秒）
功率（瓦）
SPECWeb（复合）
表1-13 Sun功率/性能对比，由Sun选择性报告
Sun Fire T2000
298
63 378
330
14 001
IBM×346
438
39 985
438
1348
63
［64
65
20
1.7
［20/20/20/20］<1.6、1.9>公司的内部研究表明：一个单核系统就足以满足对处理能力的要求，而
我们正在研究使用两个核心能否节省功率。
2.［20】<1.9>假定应用程序有80%是可并行化的。可以将频率降低多少而仍能获得相同性能？
b.［20］<1.6>假定电压可能随频率线性下降。利用1.5节的公式，与单核系统相比，双核系统可
能需要多少动态功率？
c.［20］<1.6、1.9>现在假定电压不会降至原电压的25%以下。这一电压被称为电压下限，低于
这一电压就会丢失状态。当并行化百分比为多少时，将使电压处于这一电压下限？
d. ［20］<1.6、1.9>使用1.5节的公式，考虑到电压下降，双核系统与单核系统相比，需要多少动
态功率？
练习
1.8
［I0/1S/15/10/10］<1.4、1.5>架构师面对的一个挑战是，今天拟定的设计方案可能需要几年的时
间进行实施、验证和測试，然后才能上市。这就意味着架构师必须提前为几年之后的技术进步
制定计划。有时，这是很难做到的。
a.［10］<1.4>根据摩尔定律观测到的器件发展趋势，到2015年，一个芯片上的晶体管数目应当
是2005年的多少倍？
b.［15］<1.5>时钟频率的增加也一度反映了这一趋势。如果时钟频率仍以20世纪90年代的相同
速度攀升，2015年的时钟速率大约是多少？
c.［15］<1.5>以目前的增长速率，2015年的时钟频率是多少？
d.［10］ <1.4~-是什么限制了时钟频率的增长速度？为了提升性能，架构师现在能用多出来的晶体
管做些什么？
e. ［10］<1.4>DRAM容量的增长速度也已变缓。20年来，DRAM 容量每年提高60%。这一速率
下降到每年40%，现在的改进速率为每年25%~40%。如果这一趋势继续下去，2020年的
DRAM 容量增速大约是多少？
［10/10］<1.5>我们正在为一种实时应用设计系统，这种应用要求必须在指定期限之前完成计算。
提前完成计算没有任何收益。我们发现，在最糟糕的情况下，这一系统执行必需代码的速度是
最低要求速度的两倍。
a.［10］ <1.5>如果以当前速度执行计算，并在完成任务后关闭系统，可以节省多少能量？
b.［10］<1.5>如果将电压和频率设置为现在的一半，可以节省多少能量？
1.10
T10/10/20/20］<1.5>诸如 Google 和 Yahoo！之类的服务器场都为当时的最高请求速率提供了足够
的计算容量。假设这些服务器在大多数时间内仅以60%的容量运行。进一步假设功率不会随负载
线性改变，也就是说，当服务器以 60%的容量运行时，它们消耗的功率为最大功率的90%。这些
服务器可以关闭，但在负载更多时，需要的重新启动时间过长。有人提议采用一种新型系统，它
能够快速重新启动，但处在这种“勉强生存” 状态时需要消耗一定的功率，为最大值的20%。
a.［10］<1.5>关闭60%的服务器可以节省多少功率？
b.［10］ <1.5>将60%的服务器置于“勉强生存”状态，可以节省多少功率？
c. ［20］ <1.S>将电压降低 20%，频率降低40%，可以节省多少功率？
d.［20］<1.5>将30%的服务器置于“勉强生存”状态，30%的服务器关闭，可以节省多少功率？
1.11
［10/10/20］<1.7>可用性是服务器设计中的最重要考虑事项，紧随其后的是可扩展性和吞吐量。
a.［10］<1.7>有一个处理器，其FTT为100。这个系统的平均无故障时间（MTTF）为多少？
b.［10］<1.7>如果需要1天的时间才能让这个系统再次正常运行，这个系统的可用性是多少？
c.［20］<1.7>假设政府为了降低成本，准备用廉价计算机构建一个超级计算机，而不是使用可靠
但都昂贵的计算机。一个具有1000个处理器的系统，其MTTF 为多少？（假设这些处理器
一损俱损。）
Jana FTanKIn 仪TT/
J1
1.12
［20/20/20］<1.1、1.2、1.7>在 Amazon或eBay 使用的服务器场中，一个故障不会导致整个系统
崩遗，而是减少在任意时刻能够满足的请求数目。
2.［20］<1.7>如果一个公司有10000台计算机，每台计算机的 MTTF 为35天，而且只有当1/3
以上的计算机发生故障时才会经历灾难性故障，系统的MTTF为多少？
b.［20］<1.1、1.7>如果一台计算机的 MTTF加倍，需要另加1000美元，这是不是一个很好的业
务决策？证明你的结论。
c.［20］<1.2>表1-2给出了宕机的平均成本，假定在一年的所有时间内，该成本不变。但对于零
售商来说，圣诞季节是盈利水平最高的（因此，如果因为宕机造成无法销售，损失也最大）。
如果目录销售中心在第四季度的通信流量是其他任一季度的两倍，那第四季度每小时的平均
岩机成本是多少？其他时间的宕机成本又是多少？
1.13
［10/20/20］<1.9~你的公司正要选择是购买 Opteron，还是Itanium 2。你已经分析了公司的应用情
况，在60%的时间里运行类似于 wupwise之类的应用程序，20%的时间里运行类似于 ammp之
类的应用程序，20%的时间里运行类似于 apsi 之类的应用程序。
a.［10］如果仅依据 SPEC总体性能进行选择，你选择哪一种？为什么？
b.［20］ 对 Opteron 和Itanium 2来说，这种混合应用程序的加权平均执行时间比是多少？
c.［20］ Opteron 相对于 Itanium 2的加速比是多少？
［20/10/10/10/15］<1.9>在这个练习中，假定我们正在考虑通过添加向量硬件来提高一个机器的性
能。当一个计算运行于向量硬件的向量模式时，其速度是正常执行模式的10倍。我们将使用向
量模式时花费的时间百分比称为向量化百分比。向量将在第4章讨论，但回答下面的问题不需
要知道有关其工作方式的任何信息！
a.［20］<1.9>绘制一条曲线，以加速比为因变量，以向量模式下所执行计算的比例为自变量。将
2轴标记为“净加速比”，x轴标记为“向量化百分比”。
b.［10］<1.9>向量化百分比达到多少时，才能使加速比为2？
c.［10］<1.9>如果已经使加速比为2，在向量模式下的计算运行时间占多大百分比？
d. ［10］<1.9>向量化百分比达到多少时，才能使加速比为向量模式所能实现的最大加速比的
一半？
e. ［15］<1.9>假定已经测得程序的向量化百分比为70%。硬件设计组估计，通过大量追加投
人，可以加快向量硬件的速度。你想知道编译器组是否也能提高向量化百分比。编译器团
队需要实现多大的向量化百分比，才能在向量单元中获得另外 2倍的加速（超过最初的
10倍以上）？
1.15 ［15/10］<1.9>假定我们对一台计算机进行了升级，使某种执行模式提升为原来的10倍。升级模
式的使用时间占总时间的50%，这一数值是在使用该升级模式时测得的执行时间百分比。回想
一下，Amdabl定律需要的是能改进但还没有改进的原执行时间比例。因此，在使用 Amdahl定
律计算加速比时，不能使用这个 50%的测量值。
a.［15］<1.9>从快速模式获得的加速比是多少？
b.［10］<1.9>转换为快速模式的原执行时间比例是多少？
［20/20/15］<1.9>在为了优化处理器的某一部分而进行改变时，经常会出现这样一种情况：加
速某种类型的指令时，会降低其他某些指令的速度。例如，如果放入一个复杂的浮点单元，
它要占用空间，为了容纳仑，就得将某些东西移得远一些，这样就会要增加一些延退周期才
能到达被挪远的单元。基本的Amdabl定律公式没有考虑这种折中。
a.［20］<1.9>如果这个新的快速浮点单元使浮点运算平均提高到2倍，浮点运算占用的时
间为原程序执行时间的20%，那么总加速比为多少（忽略对所有其他指令的影响）？
b.［20］<1.9>现在假定浮点单元的加速会降低数据缓存访问的速度，减缓倍数为1.5（或者说加
速比为2/3）。数据缓存访问时间为总执行时间的10%。现在的总加速比为多少？
c.［15］<1.9>在实现新的浮点运算之后，在浮点运算上花费的执行时间占多大比例？数据缓存访
问又占多大比例？
1.17［10/10/20/20］<1.10~公司刚刚购买了一个新的 Intel Core i5 双核处理器，你接到针对这一处理器
来优化软件的任务。你将在这个双核处理器上运行两个应用程序，但它们的资源需求并不一样。
第一个程序需要 80%的资源，另一个仅需要20%的资源。假定对该程序的一部分进行并行化时，
该部分的加速比为2。
2.［10］ <1.10>假定第一个应用程序的40%可以并行化，那么在隔离运行时，通过这个应用程序
可以实现多大的加速比？
b.［10］<1.10>假定第二个应用程序的99%可以并行化，那么在隔离运行时，这个应用程序可以
达到多大的加速比？
c.［20］<1.10>假定第一个应用程序的40%可以并行化，如果对其实现并行化，系統总加速比为
多少？
d. ［20］<1.10~假定第二个应用程序的99%可以并行化，如果对其实现并行化，系统总加速比为
多少？
1.18［10/20/20/20/25］<1.10>在实现一个应用程序的并行化时，理想加速比应当等于处理器的个数。
但它要受到两个因素的限制：可并行化应用程序的百分比和通信成本。Amdabl 定律考虑了前者，
但没有考虑后者。
a.［10］<1.10>如果应用程序的80%可以并行化，N个处理器的加速比为多少？（忽略通信成本。）
b.［20］<1.10>如果每增加一个处理器，通信开销为原执行时间的0.5%，则8个处理器的加速比
 为多少？
c.［20］<1.10>如果处理器数目每增加一倍，通信开销增加原执行时间的0.5%，则8个处理器的
加速比为多少？
d. ［20］<1.10> 如果处理器数目每增加一倍，通信开销增加原执行时间的0.5%，则N个处理器的
加速比为多少？
e. ［25］<1.10>写出求解这一问题的一般公式：如果一个应用程序中占原执行时间的P%可以并行
化，处理器数目每增加一倍，通信成本增加原执行时间的5%，则达到最高加速比的处理器
数目为多少？
