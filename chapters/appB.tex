\chapter{存储器层次结构回顾}
缓存：隐藏或存储东西的安全位置。
《韦氏新世界美语词典》
学院版第2版（1976）

\section{引言}
本附录对存储器层次结构进行了快速回顾，包括缓存与虚拟存储器的基础知识、性能公式、
简单优化。第一节介绍下面36个术语。
\begin{verbatim}
    缓存（cache）
    虛拟存储器（virtual memory）
    存储群停顿周期（memory stall cycies）
    直接映射（direct mapped）
    有效位（valid bit）
    块地址（block address）
    直写（write through）
    指令缓存（instruction cache）
    存储器平均访问时间（average memory
    全相联（fully associative）
    重写（脏）位 （dirty bit）
    块偏移（block offset）
    写回（write back）
    数据缓存（data cache）
    命中时间（hit time）
    缓存缺失（cache miss）
    页面错误（pagefault）
    缺失率 （miss rate）
    写入分派（write allocate）
    统一綵存 （unified cache）
    每条指今缺失数 （misses per instruction）
    块（block）
    局城性（locality）
    地址跟踪（address trace）
    組（set）
    随机替換 （random replacement）
    索引字段（index field）
    access time）
    缓存命中（cache hit）
    页（page）
    缺失代价（miss penalty）
    n路组相联（n-way set associative）
    最近最少使用（least-recently used）
    标志字段（tagfield）
    无写入分派 （no-write allocate）
    写入缓冲区（write buffer）
    写停顿（Write stall）
\end{verbatim}
如果这一部分回顾内容过于简略，读者可以查看《计算机组成与设计》一书的第7章，那是我
们专为初学者编写的。

缓存是指地址离开处理器后遇到的最高级或第一级存储器层次结构。由于局域性原理适用
于许多级别，而且充分利用局域性来提高性能的做法非常普遍，所以现在只要利用缓冲方法来
重复使用常见项目，就可以使用缓存一词，文件缓存、名称缓存等都是一些实例。

如果处理器在缓存中找到了所需要的数据项，就说发生了缓存命中。如果处理器没有在缓
存中找到所需要的数据项，就是发生了缓存缺失。从主存储器中提取固定大小且包含所需字的
数据集，并将其放在缓存中，这个数据集称块。时域局域性告诉我们：我们很可能会在不远
的将来再用到这个字，所以把它放在缓存中是有用的，在这里可以快速访问它。由于空域局域
性，马上用到这个块中其他数据的可能性也很高。

缓存缺失需要的时间取决于存储器的延迟和带宽。延迟决定了提取块中第一个字的时间，
带宽决定了提取这个块中其他内容的时间。缓存嵌失由硬件处理，会导致采用循序执行方式的
处理器暂停或停顿，直到数据可用为止。在采用乱序执行方式时，需要使用该结果的指令仍然
必须等待，但其他指令可以在缺失期间继续进行。

与此类似，程序引用的所有对象不一定都要驻存在主存储器中。虚拟存储意味着一些对
象可以驻存在磁盘上。地址空间通常被分为固定大小的块，称为页。在任何时候，每个页要么
在主存储器中，要么在磁盘上。当处理器引用一个页中既不在缓存中也不在主存储器中的数据
项时，就会发生页错误，并把整个页从磁盘移到主存储器中。由于页错误消耗的时间太长，所
以它们由软件处理，处理器不会停顿。在进行磁盘访问时，处理器通常会切换到其他某一任务。
从更高级别来看，缓存和主存储器在对引用局域性的依赖性方面、在大小和单个位成本等方面
的关系，类似于主存储器与磁盘的相应关系。

表B-1给出了各种计算机（从高端台式机到低端服务器）每一级存储器层次结构的大小与
访问时间范围。

表B-1 大型工作站或小型服务器存储器层次结构的典型级别，在远离处理器时，相应级别的速度减缓、
\begin{verbatim}
    容量变大
    级
    别
    1
    2
    3
    4
    名称
    寄存器
    缓存
    主存储器
    磁盘存储
    典型大小
    ＜1 KB
    32 KB~8 MB
    <S12 GB
    >1 TB
    实现技术
    具有多个端口的定制存储器、CMOS
    片上CMOS SRAM
    CMOS DRAM
    磁盘
    访问时间（ns）
    0.15~0.30
    0.5~15
    30~200
    $ 000 000
    带宽（MB/s）
    100 000-1 000 000
    10 000-40 000
    $000-20 000
    50-500
    管理者
    编译器
    硬件
    操作系统
    搡作系统/操作员
    支持者
    缓存
    主存储器
    磁盘
    其他磁盘和DVD
\end{verbatim}
*嵌入式计算机可能没有磁盘存储，存储器和缓存也要小得多。在移向层次结构的更低级别时，訪问时间延长，从而
有可能以較低的反应速度来管理数据传输。实现技水显示了这些功能所用的典型技术。表中给出的访问时间数据是
2006年的典型值，单位为纳秒；这些时间数据将随时间的推移而缩小。存储器层次结构各级之间的带宽以MB/8 单位
给出。磁盘存储的带寬包括介质和城冲接口的带宽。

\subsection{缓存性能回顾}
由于局域性的原因，再加上存储器越小其速度越快，所以存储器层次结构可以显著提高性
能。评价缓存性能的一种方法是扩展第1章给出的处理器执行时间公式。我们现在考虑处理器
在等待存储器访问而停顿时的周期数目，称为存储器停顿周期。性能结果为处理器周期与存储
器停顿周期之和与时钟周期时间的乘积：

CPU 执行时间=（CPU时钟周期＋存储器停顿周期）x时钟周期时间

此公式假定 CPU时钟周期包括处理缓存命中的时间，并假定处理器在发生缓存缺失时停顿。B.2
节重新检视了这一简化假定。

存储器停顿周期数取决于缺失数目和每次缺失的成本，后者称为缺失代价：

存储器停顿周期=缺失数×缺失代价
=IC×、
鉄失 x 失代价
指令
=IC× 存储辉访间 x 缺失率×铁失代价
指令

最后一种形式的优点在于其各个分量容易测量。我们已经知道如何测量指令数（IC）。（对于推
测处理器，只计算提交的指令数。）可以采用同一方式来测量每条指令的存储器引用数；每条指
令需要一次指令访问，很容易判断它是否还需要数据访问。

注意，我们计算出缺失代价，作为平均值，但下面将其作为常数使用。在发生续失时，缓
存后面的存储器可能因为先前的存储器请求或存储器刷新而处于繁忙状态。在处理器、总线和
存储器的不同时钟之间进行交互时，时钟周期数也可能发生变化。所以请记住，为缺失代价使
用单一数值是一种简化。

缺失率分量就是缓存访问中导致缺失的访问比例（即，导致缺失的访问数除以总访问数）。
缺失率可以用缓存模拟器测量，它会取得指令与数据引用的地址跟踪，模拟该缓存行为，以判
断哪些引用命中，哪些缺失，然后汇报命中与缺失总数。今天的许多微处理器提供了用于计算
峡失与存储器引用数的硬件，这一缺失率测量方式要容易得多、快得多。

由于读取和写人操作的缺失率和缺失代码通常是不同的，所以上面的公式得出的是一个近
似值。存储器停顿时钟周期可以用每条指令的存储器访问次数、读写操作的缺失代价（以时钟
周期为单位）、读写操作的缺失率来定义：

存储器停顿时钟周期=IC×每条指令的读取操作 ×读取缺失率× 读取缺失代价
+ICx每条指令的写入操作x写人缺失率x写入缺失代价

我们通常会合并读写操作，求出读取与写人操作的平均缺失度与缺失代价，以简化上面的完整
公式：

存储器降顿时钟周期二1Cx 在修雞皿 x峡失率x锁失代价

缺失率是缓存设计中最重要的度量之一，但在后面各节将会看到，它不是唯一的度量标准。
例题

假定有一个计算机，当所有存储器访问都在缓存中命中时，其每条指令的周期数
（CPI）为1.0。仅有的数据访问就是载入和存储，占总指令数的50%。如果缺失代
价为25 个时钟周期，缺失率为 2%，当所有指令都在缓存中命中时，计算机可以
加快多少？

解答
首先计算计算机总是命中时的性能：

CPU 执行时间=（CPU 时钟周期＋存储器停顿周期）×时钟周期
= （IC ×CPI+0） ×时间周期
=IC × 1.0x时间周期

现在，对于采用实际缓存的计算机，首先计算存储器停顿周期：

存储器停顿周期=IC×在储器访回数 ×觖失率x毓失代价
指令
= IC× （1+0.5）×0.02×25
=IC×0.75

式中，中间项（1+0.5）表示每条指令有1 次指令访问和0.5次数据访问。总性能
为：

CPU执行时间取=（IC × 1.0+IC× 0.75）×时间周期
= 1.75 ×IC×时钟周期

性能比是执行时间的倒数：
CPU执行时间缀存
1.75 ×IC ×时钟周期
CPU执行时间
-=1.OxICx时钟周期
=1.75

没有缓存峡失时，计算机的速度为有缺失时的1.75倍。

一些设计师在测量缺失率时更愿意表示为每条指令的缺失数，而不是每次存储器引用的缺
失数。这两者的关系为：

\begin{verbatim}
    鋏失数_缺失数×存储腸访问数-峡失数x
    存储器访问数
    指令数
    指令数
    指令数
\end{verbatim}

如果知道每条指令的平均存储器访问数，后面一个公式是有用的，因为这样可以将觖失率
转换为每条指令的缺失数，反之亦然。例如，我们可以将上面示例中每次存储器引用的缺失率
转换为每条指令的缺失：

\begin{verbatim}
    缺失数
    =缺失数x存储髒访可数
    -=0.02 ×1.5=0.030
    指令数
    指令数
\end{verbatim}

顺便说一下，每条指令的缺失数经常以每千条指令的缺失数给出，以显示整数而非小数。
因此，上面的答案也可以表示为每1000条指令发生30次缺失。

表示为“每条指令的缺失数”的好处在于它与硬件实现无关。例如，推测处理器提取的指
令数大约是实际提交指令数的两倍，如果测量每次存储器引用而非每条指令的缺失数，那么就
可以人为地降低缺失率。其缺点在于每条指令的缺失数与体系结构相关；例如，对于80x86与
MIPS，每条指令的存储器访问平均数可能会有很大不同。因此，对于仅使用单一计算机系列的
架构师，最常使用的是每条指令的缺失数，不过与 RISC体系结构的相似性也可以让人们深入
理解其他体系结构。

例题
为了展示这两个缺失率公式的等价性，让我们重做上面的例题，这一次假定每干
条指令的缺失率为30。根据指令个数，存储器停顿时间为多少？
解答

重新计算存储器停顿周期：

存储器停顿周期=缺失数x缺失代价
缺失数
=IC×
指令数 ×缺失代价
缺失数
= IC/1000x
x缺失代价
指令数 × 1000
= IC/1000 ×30×25
= IC/1000 ×750
=IC×0.75

得到的答案与前面的例题相同，表明这两个公式的等价性。

\subsection{4个存储器层次结构问题}
我们通过回答有关存储器层次结构第一级的4个常见问题来继续对缓存的介绍。

问题1：一个块可以放在上一级的什么位置？（块的放置）
问题2：如果一个块在上一级中，如何找到它？（块的识别）
问题3：在缺失时应当替换哪个块？（块的替换）
问题4：在写人时会发生什么？（写入策略）

这些问题的答案可以帮助我们理解存储器在层次结构不同级别所做的不同折中；因此，我
们对每个示例都会问这四个问题。

\subsubsection{问题1：一个块可以放在缀存中的什么位置？}
图B-1显示，根据对块放置位置的限制，可以将缓存组织方式分为以下三类。

口 如果每个块只能出现在缓存中的一个位置，就说这一缓存是直接映射的。这种映射通常是：
（块地址）MOD（缓存中的块数）
口 如果一个块可以放在缓存中的任意位置，就说该缓存是全相联的。
口如果一个块可以放在缓存中由有限个位置组成的组（set）内，则该缓存是组相联的。组
就是缓存中的一组块。块首先映射到组，然后这个块可以放在这个组中的任意位置。通
常以位选择方式来选定组；即：
（块地址）MOD（缓存中的组数）

如果组中有n个块，则称该缓存放置为n路組相联。

从直接映射到全相联的缓存范围实际上就是组相联的一个统一体。直接映射就是一路组相
联，拥有 m个块的全相联缀存可以称为“m路组相联”。同样，直接映射可以看作是拥有m 个
组，全相联可以看作拥有一个组。

\begin{verbatim}
    全相联：块12可
    以进人任意位置
    块编号
    •01234567
    块编号
    直接映射：块12只能
    进人块4（12 MOD 8）
    01234567
    块编号
    组相联：块12可以进人第0组
    中的任意位置（12 MOD4）
    01234567
    缓存
    第0第1第2第3
    组组组
    组
    块帧地址
    11111222222222233
    块编号 01234567890123456789012345678901
    存储器
    图 B-1
\end{verbatim}

这一缓存示例有 8 个块帧，存储器有32 个块。三种缓存选项由左向右给出。在全相联中，来自
较低层级的块12可以进入该缓存8个块帧的任意一个。采用直接映射时，块12 只能放在块帧4
\verb|（12Mod &）|中。组相联拥有这两者的一些共同特性，允许这个块放在第0组的任意位置（12Mod
4）。由于每个组中有两个块，所以这意味着块12可以放在缓存的块0或块1中。实际缓存包含数
千个块帧，实际存储器包含数百万个块。拥有四个组、每组两个块的组相联组织形式称为两路组
相联。假定缓存中没有内容，而且所关心的块地址确认了较低级别的块12

今天的绝大多数处理器缓存为直接映射、两路组相联或四路组相联，其原因将在稍后介绍。

\subsubsection{问题 2：如果一个块就在缓存中，如何找到它？}
缓存中拥有每个块帧的地址标志，给出块地址。每个缓存块的标志中可能包含所需要的信
息，会对这些标志进行查看，以了解它是否与来自处理器的块地址匹配。由于速度非常重要，
所以会对所有可能标志进行并行扫描，这是一条规则。

必须存在一种方法来获知缓存块中不包含有效信息。最常见的过程是向标志中添加一个有
效位，表明这一项是否包含有效地址。如果没有对这个位进行置位，那就不可能存在对这一地
址的匹配。

在继续讨论下一问题之前，先来研究一个处理器地址与缓存的关系。图B-2显示了址是如
何划分的。第一次划分是在块地址和块偏移之间，然后再将块帧地址进一步分为标志宇段和索
引字段。块偏移字段从块中选择期望数据，索引字段选择组，通过对比标志字段来判断是否命
中。尽管可以对标志之外的更多地址位进行对比，但并不需要如此，原因如下所述。

口 在对比中不应使用偏移量，因为整个块或者存在或者不存在，因此，根据定义，所有块
偏移都会导致匹配。
口核对索引是多余的，因为它是用来选择待核对组的。例如，存储在第0组的地址，其索
引字段必须为0，否则就不能存储在第0组中；第1组的索引值必须为1，以此类推。这
一优化通过缩小缓存标志的宽度来节省硬件和功率。

图B-2 组相联或直接映射缓存中地址的三个组成部分。标志用于检查组中的所有块，索引用于选择该组。
块偏移是块中所需数据的地址。全相联缓存没有索引字段

如果总缓存大小保持不变，增大相联度将提高每个组中的块数，从而降低索引的大小、增
大标志的大小。即，图B-2 中的标志索引边界因为相联度增大而向右移动，到端点处就是全相
关缓存，没有索引字段。

\subsubsection{问题3：在缓存缺失时应当替换哪个块？}
当发生缺失时，缓存控制器必须选择一个用期望数据替换的块。直接映射布置方式的好处
就是简化了硬件判决——事实上，简单到没有选择了：只会查看一个块帧，以确定是否命中，
而且只有这个块可被替换。对于全相联或组相联布置方式，在发生嵌失时会有许多块可供选择。
主要有以下三种策略用来选择替换哪个块。

口 随机——为进行均匀分配，候选块是随机选择的。一些系统生成伪随机块编号，以实现
可重复的行为，这在调试硬件时有一定的用处。
口最近最少使用（LRU）——为尽量避免抛弃不久就会用到的信息，会记录下对数据块的
访问。依靠过去行为来预测未来，将替换掉未使用时间最久的块。LRU依赖于局域性的
一条推论：如果最近用过的块很可能被再次用到，那么放弃最近最少使用的块是一种不
错的选择。
口先入先出（FIFO）—因为 LRU 的计算可能非常复杂，所以这一策略是通过确定最早
的块来近似 LRU，而不是直接确定 LRU。

随机替换的一个好处是易于用硬件实现。随着要跟踪块数的增加，LRU 的成本也变得越得
来高，通常只能采用近似法。一种常见的近似方法（经常称为 “伪 LRU”）是为缓存中的每个
组设定一组比特，每个比特应于缓存中的一路，一路就是组相联缓存中的条（bank）；四路组相
联缓存中有四路。在访问一组时开启一个特定比特，这一比特与包含所需块的路相对应；如果
与一个组相关联的所有比特都被开启，除最近刚被开启的比特之外，将所有其他比特关闭。在
必须替换一个块时，处理器从相应被关闭的路中选择一个块，如果有多种选择，则随机选定。
这种方法会给出近似LRU，这是因为自上次访问组中的所有块之后，被替换块再没有被访问过。
表B-2给出了LUR、随机和 FIFO 替换方式中的缺失率之差。


表B-2 每千条指令的数据缓存缺失，比较了几种不同大小和相联度的最近最少使用、随机和先入先出替
换方式
\begin{verbatim}
    相联度
    两
    路
    四路
    ‘八
    路
    大小
    LRU
    随机
    FIFO
    LRU
    随机
    FIFO
    LRU
    随机
    FIFO
    16 KB
    .114.1
    1117.3
    115.5
    111.7
    115.1
    113.3
    109.0
    111.8
    110.4
    64 KB
    103.4
    104.3
    103.9
    102.4
    102.3
    103.1
    99.7
    100.5
    100.3
    256 KB
    92.2
    92.1
    925
    92.1
    92.1
    92.5
    92.1
    92.1
    925
\end{verbatim}
*对于最大的缓存，LRU 和随机方式之间波有什么差别，当缓存较小时，LUR胜过其他几种方式。当缓存較小时，FIFO
通常优于随机方式。这些数据是使用10个 SPEC2000 基准测试来用64字节的块大小，针对 Alpha 体系结构测得的。
其中5个基准测试来 自 SPECint2000（gap、Bce、Bzip、mcf和 perl），S个来自 SPECp2000（applu、art、eguake、lucas
和swrim）。在本附录的大多数图形中都将使用这一计算机和这些基准测试程序。

问题4：在写入时发生什么？

大多数处理器缓存访问都是读取操作。所有指令访问都是读取，大多数指令不会向存储器
写人数据。附录A中的表A-27和表A-28表明，MIPS程序中存储指令占 10%，载入指令占26%，
总存储器通信流量中，写人占10%/（100%+26%+10%），大约为7%。在数据缓存通信流量中，
写入操作占10%/（26%+10%），大约为28%。要加快常见情景的执行速度，就意味着要针对读
取操作对缓存进行优化，尤其是处理器通常会等待读取的完成，而不会等待写人操作。但Amdahl
定律（见1.9节）提醒我们，高性能设计不能忽视写入操作的速度。

幸运的是，常见情景也是容易提升速度的情景。可以在读取和比对标志的同时从缓存中读
取块，所以只要有了块地址就开始读取块。如果读取命中，则立即将块中所需部分传送给处理
器。如果读取缺失，那就没有什么好处——但除了桌面和服务器计算机增加一点功耗之外，也
没有坏处；只需忽略所读值即可。

不能对写人操作应用这一优化。要想修改一个块，必须先核对标志，以查看该地址是否命
中。由于标志核对不能并行执行，所以写入操作需要的时间通常要长于读取。另一种复杂性在
于处理器还指定写入的大小，通常介于 1~8个字节之间；只能改变一个块的相应部分。而读取
则与之不同，可以毫无顾虑地访问超出所需的更多字节。

写入策略通常可以用来区分缓存设计。在写人缓存时，有下面两种基本选项。

口 直写—信息被写人缓存中的块和低一级存储器中的块。
口 写回—信息仅被写到缓存中的块。修改后的缓存块仅在被替换时才被写到主存储器。

为减少在替换时写回块的频率，通常会使用一种称为重写（脏）位的功能。这一状态位表
示一个块是脏的（在缓存中经历了修改）还是干净的（未被修改）。如果它是干净的，则在缺失
时不会写回该块，因为在低级存储器中可以看到缓存中的相同信息。

写回和直写策略都有自己的优势。采用写回策略时，写入操作的速度与缓存存储器的速度
相同，一个块中的多个写人操作只需要对低一级存储器进行一次写人。由于一些写人内容不会
进入存储器，所以写回方式使用的存储器带宽较少，使写回策略对多处理器更具吸引力。由于
写回策略对存储器层次结构其余部分及存储器互连的使用少于直写，所以它还可以节省功耗，
对于嵌人式应用极具吸引 。

相对于写回策略，直写策略更容易实现。缓存总是清洁的，所以它与写回策略不同，读取
缺失永远不会导致对低一级存储器的写入操作。直写策略还有一个好处：下一级存储器中拥有
数据的最新副本，从而简化了数据一致性。数据一致性对于多处理器和 V/O 来说非常重要，在
第4章和附录D中对此进行了研究。多级缓存使直写策略更适于高一级缓存，这是因为写入操
作只需要传播到下一个较低级别，而不需要传播到所有主存储器。

稍后将会看到，1/O和多处理器有些反复无常：它们希望为处理器缓存使用写回策略，以减
少存储器通信流量，又希望使用直写策略，以与低级存储器层次结构保持缓存一致。

如果处理器在直写期间必须等待写人操作的完成，则说该处理器处于写人停顿状态。减少
写人停顿的常见优化方法是写人缓冲区，利用这一优化，数据被写入缓冲区之后，处理器就可
以立即继续执行，从而将处理器执行与存储器更新重叠起来。稍后将会看到，即使有了写人缓
冲区也会发生写人停顿。

由于在写人时并不需要数据，所以在发生写人缺失时共有以下两种选项。

口 写入分派—在发生写人缺失时将该块读到缓存中，随后对其执行写入命中操作。在这
一很自然的选项中，写人缺失与读取缺失类似。
口 无写入分派—这显然是一种不太寻常的选项，写人缺失不会影响到缓存。而是仅修改
低一级存储器中的块。

因此，在采用无写人分派策略时，在程序尝试读取块之前，这些块一直都在缓存之外，但在采
用写人分派策略时，即使那些仅被写人的块也会保存在缓存中。让我们看一个例子。

例题
假定一个拥有许多缓存项的全相联写回缓存，在开始时为空。下面是由5个存储
器操作组成的序列（地址放在中括号内）：

Write Men［100］；
Write
Mem［100］；
Read
Mem［200］；
Write
Mem［200］；
Write Mem［100］.

在使用无写人分派和写入分派时，命中数和缺失数为多少？

解答
对于无写人分派策略，地址100不在缓存中，在写人时不进行分派，所以前两个
写人操作将导致缺失。地址200也不在缓存中，所以该读取操作也会导致缺失。
接下来对地址200进行的写入将会命中。最后一个对地址100的写人操作仍然是
缺失。所以对无写人分派策略，其结果是4次缺失和1次命中。

对于写人分派策略，前面对地址100和地址200的访问导致缺失，由于地址100
和地址 200 都可以在缓存中找到，所以其他写入操作将会命中。因此，采用写人
分派时，其结果为2次缺失和3次命中。

任何一种写人缺失策略都可以与直写或写回策略一起使用。通常，写回缓存采用写人分派策
略，希望对该块的后续写人能够被缓存捕获。直写缓存通常使用无写人分派策略。其原因在于：
即使存在对该块的后续写入操作，这些写人操作仍然必须进人低一级存储器，那还有什么好处呢？

\subsection{举例：Opteron数据缓存}

为了展示这些思想的本质，图B-3给出了 AMD Opteron 微处理器中数据缓存的组织方式。
该缓存包含 65 536（64KB）字节的数据，块大小为64字节，采用两路组相联布置方式、最近
使用最少替代策略、写缺失时采用写人分派。

Opteron 微处理語中数据缓存的组织方式。这个64KB 的缓存为两路组相联，块大小为64字节。
长为9位的索引从 512个组中进行选择。一次读取命中的四个步骤（按发生顺序表示为带圆圈的
数字）标记了这一组织方式。块偏移量的三位加上索引，提供了 RAM地址，恰好选择8个字节。
因此，该缓存保存了由4096个 64位字组成的群组，每个群组包含512个组的一半。从低级存储
器至缓存的线路用于在发生缺失时载入缓存，不过未在这一示例中展示。离开处理器的地址大小
为40位，这是因为它是物理地址而不是虚拟地址。图B-14 解释了 Opteron 如何从虚拟地址映射
到物理地址，以进行缓存访问

我们通过图B-3中标注的命中步骤来跟踪一次缓存命中的过程。（这4个步骤用带圆圈的数
字表示。）如B.5节所述，Opteron 向缓存提供48位虚拟地址进行标志比对，它将同时被翻译为
40位物理地址。

Opteron 之所以没有利用虚拟地址的所有64位，是因为它的设计者认为还没有人会需要那
么大的虚拟地址空间，而较小的空间可以简化 Opteron 虚拟地址的映射。设计者计划在未来的
微处理器中增大此虚拟地址。

进入缓存的物理地址被分为两个字段：34 位块地址和 6 位块偏移量（64=2°，34+6=40）。
块地址进一步分为地址标志和缓存索引。第1步显示了这一划分。

缓存索引选择要测试的标志，以查看所需块是否在此缓存中。索引大小取决于缓存大小、
块大小和级相联度。Opteron 缓存的组相联度被设置为2，索引计算如下：

2系5）=：
缓存大小
-=65 536-512=29
块大小×组相联度
64×2

因此，索引宽9位，标志宽 34-9=25位。尽管这是选择正确块所需要的索引，但64个字节远多
于处理器希望一次使用的数目。因此，将缓存存储器的数据部分安排为宽8个字节更有意义一
些，这是 64位 Opteron处理器的自然数据字。因此，除了用于索引正确缓存块的9个位之外，
还使用来自块偏移量的另外3个位来索引恰好8个字节。索引选择是图B-3中的第2步。

在从缓存中读取这两个标志之后，将它们与处理器所提供块地址的标志部分进行对比。这一
对比是图中第3步。为了确保标志中包含有效信息，必须设置有效位，否则，对比结果将被忽略。
假定有一个标志匹配，最后一步是通知处理器，使用2选1多工器的获胜输人从缓存中载
入正确数据。Opteron 可以在2个时钟周期内完成这四个步骤，因此，如果后面2个时钟周期中
的指令需要使用载人结果，那就得等待。

在 Opteron 中，写人操作的处理要比读取操作更复杂，这一点与在任何缓存中都是一致的。
如果要写人的字在缓存中，前三步相同。由于 Opteron 是乱序执行的，所以只有在它发出指令
已提交而且缓存标志比对结果显示命中的信号之后，才会将数据写到缓存中。

到目前止，我们假定的是缓存命中的常见情景。那在缺失时会发生什么情况呢？在读取
缺失时，缓存会向处理器发出信号，告诉它数据还不可用，并从下一级层级结构中读取 64个字
节。对于该块的前8个字节，延迟为7个时钟周期，对于块的其余部分，为每8个字节需要2
个时钟周期。由于数据缓存是组相联的，所以需要选择替换哪个块。Opteron 使用 LRU（选择
在最早之前被引用的块），所以每次访问都必须更新LRU位。替换一个块意味着更新数据、地
址标志、有效位和LRU位。

由于 Opteron 使用写回策略，旧的数据块可能已经被修改，所以不能简单地放弃它。Opteron
为每个块保存1个脏位，以记录该块是否被写入。如果“牺牲块”被修改，它的数据和地址就
被发送给牺牲块缓冲区。（这种结构类似于其他计算机中的写入缓冲区。）Opteron 有8个牺牲块
的空间。它会将牺牲块写到低一级层次结构，这一操作与其他缓存操作并行执行。如果牺性块
缓冲区已满，缓存就必须等待。

由于 Opteron 在读取缺失和写入缺失时都会分派一个块，所以写人缺失与读取缺失非常类似。
我们已经看到数据缓存是如何工作的，但它不可能提供处理器所需要的所有存储器：处理
器还需要指令。尽管可以尝试用一个缓存来提供数据、指令两种缓存，但这样可能会成为瓶颈。
例如，在执行载人或存储指令时，流水化处理器将会同时请求数据字和指令字。因此，单个缓
存会表现为载人与存储的结构性冒险，从而导致停顿。解决这一问题的一种简单方法是分开它：
一个缓存专门用于指令，另一个缓存专门用于数据。最近的处理器中都使用了独立缓存，包括
Opteron 在内。因此，它有一个 64KB 的指令缓存和64 KB 的数据缓存。

处理器知道它是在发射一个指令地址，还是一个数据地址，所以可能存在用于这两者的独
立端口，从而使存储器层次结构和处理器之间的带宽加倍。采用分离缓存还提供了分别优化每
个缓存的机会：采用不同的容量、块大小和相联度可能会得到更佳性能。（与 Opteron 中的指令
缓存和数据缓存相对，统一或混合等词适用于可能包含指令或数据的缓存。）

表B-3显示指令缓存的缺失率低于数据缓存。指令与数据缓存分离，消除了因为指令块和
数据块冲突所导致的缺失，但这种分离固定了每种类型所能使用的缓存空间。与缺失率相比，
哪个更重要呢？要公平地对比指令数据分离缓存和统一缓存，需要总缓存大小相同。例如，分
离的16KB指令缓存和16KB数据缓存应当与32KB统一缓存相对比。要计算分离指令与数据
缓存的平均缺失率，需要知道对每种缓存的存储器引用百分比。从附录A 中的数据可以找到：
指令引用为100%《100%+26%+10%），大约为74%；数据引用为（26%+10% X 100%+26%+10%），
大约为26%。稍后将会看到，分割对性能的影响并非仅限于缺失率的变化。

表B-3 对于不同大小的指令、数据与统一缓存，每干条指令的缺失数
\begin{verbatim}
    大小（KB）
    8
    16
    32
    64
    128
    256
    为64字节。
    指令缓存
    数据级存
    8.16
    44.0
    3.82
    40.9
    1.36
    38.4
    0.61
    36.9
    0.30
    35.3
    0.02
    32.6
    统一缓存
    63.0
    $1.0
    43.3
    39.4
    36.2
    32.9
\end{verbatim}
*指令引用所占百分比大约沟 749。此数据的收集采用与表 B.-2 中相同的计算机和基准测试，两路相联缓存，块大小

\section{缓存性能}
由于指令的数目与硬件无关，所以用这个数值来评价处理器性能是很有诱惑力的。这种间
接性能度量已经让一位又一位计算机设计师栽了跟头。由于缺失率也与硬件的速度无关，所以
评价存储器层次结构性能的相应焦点就主要集中在缺失率上。后面将会看到，缺失率可能与指
令数目一样产生误导。存储器层次结构性能的一个更好度量标准是存储器平均访问时间：

存储器平均访问时间=命中时间+缺失时间x缺失代价

式中，命中时间是指在缓存中命中的时间；其他两项已经在前面看到过。平均访问时间的各个
分量可以用绝对时间衡量，比如，一次命中的时间为0.25~1.0ns，也可以用处理器等待该存储
器的时间周期数来衡量，比如一次缺失代价为150~200个时钟周期。注意，存储器平均访问时
间仍然是性能的间接度量；尽管它优于缺失率，但并不能替代执行时间。

这个公式可以帮助我们决定是选择分离缓存还是统一缓存。

例题
解答
16 KB 指令缓存加上16 KB数据缓存相对于一个32 KB统一缓存，哪一种的缺失
率较低？利用表B-3 中的缺失率数据来帮助计算正确答案，假定36%的指令为数
据传输指令。假定一次命中需要1个时钟周期，缺失代价为100个时钟周期。对于
统一缓存，如果仅有一个缓存端口来满足两个同时请求，一次载人或存储命中另
需要一个时钟周期。利用第3章的流水线技术，统一缓存会导致结构性冒险。每
种情况下的存储器平均访问时间为多少？假定采用具有写人缓冲区的直写缓存，
忽略由于写入缓冲区导致的停顿。

首先让我们将每干条指令的缺失数转换为缺失率。求解上面的一般公式，失率为：

\begin{verbatim}
    缺失率
    缺失率=1000条指今^1000
    存储器访问数
    指令数
\end{verbatim}

由于每次指令访问都正好有一次存储器访问来提取指令，所以指令缺失率为：
缺失率16KB指今=
3.82/ 1000
一=0.004
1.00

由于36%的指令为数据传输，所以数据缺失率为：

缺失率（6kB酸製=40.9/1000=0.114
0.36
统一缺失率需要考虑指令和数据访问：
43.3/1000
缺失率32K日统一=：
-=0.0318
1.00+0.36

如上所述，大约74%的存储器访问为指令引用。因此，分离缓存的总缺失率为：

（74% × 0.004）+（26% ×0.114）=0.0326

因此，32 KB统一缓存的实际缺失率略低于两个 16 KB缓存。
存储器平均访问时间公式可分为指令访问和数据访问：
存储器平均访问时间
=指令百分比x（命中时间+指令缺失率 ×缺失代价）
+数据百分比×（命中时间＋数据缺失率×缺失代价）
因此，每种组织方式的时间为：
存储器平均访问时间分满
= 74% ×（1+0.004 ×200）+26%×（1+0.114×200）
= （74% × 1.80）+（26% ×23.80）=1.332+6.188=7.$2
存储器平均访问时间统-
= 74% ×（1+0.0318×200）+26% ×（1+1+0.0318×200）
= （74% ×7.36）+（26% ×8.36）=5.446+2.174=7.62

因此，在这个示例中，尽管分离缓存（每时钟周期提供两个存储器端口，从而避
免了结构性冒险）的实际缺失率较差，但其存储器平均访问时间要优于单端口统
一缀存。

\subsection{存储器平均访问时间与处理器性能}
一个显而易见的问题是：因缓存缺失导致的存储器平均访问时间能否预测处理器性能。
首先，还有其他原因会导致停顿，比如使用存储器的1/O设备产生争用。由于存储器层次
结构导致的停顿远多于其他原因导致的停顿，所以设计人员经常假定所有存储器停顿都是由于
缓存缺失导致的。我们这里也采用这一简化假定，但在计算最終性能时，一定要考虑所有存储
器停顿。

第二，上述问题的回答也受处理器的影响。采用循序执行处理器（见第3章），那回答基本
上就是肯定的。处理器会在缺失期间停顿，存储器停顿时间与存储器平均访问时间存在很强的
相关性。现在假定采用循序执行，但下一小节会返回来讨论乱序处理器。

如上一节所述，可以为 CPU时间建立如下模型：

CPU 时间=（CPU执行时钟周期＋存储器停顿时钟周期）×时钟周期时间
这个公式会产生一个问题：一次缓存命申的时钟周期应看作CPU执行时钟周期的一部分，还是
存储器停顿时钟周期的一部分？尽管每一种约定都有自己的正当理由，但最为人们广泛接受的
是将命中时钟周期包含在 CPU执行时钟周期中。

我们现在可以研究缓存对性能的影响了。

例题
让我们对第一个示例使用循序执行计算机。假定缓存缺失代价为200个时钟周期，
所有指令通常都占用1.0个时钟周期（忽略存储器停顿）。假定平均缺失率为2%，
每条指令平均有1.5 次存储器引用，每干条指令的平均缓存缺失数为30。如果考
虑缓存的行为特性，对性能的影响如何？使用每条指令的缺失数及缺失率来计算
此影响。

解答
CPUE：间 C×、CPIen +套体點經例时针 類）x时鉀周期叶刷
其性能（包括缓存嵌失）为：
CPU时间包括缓在 = IC ×［1.0+（30/1000 ×200）】 × 周期时钟时间
= IC ×7.00x时钟周期时间
现在使用缺失率计算性能：
CPU时间=IC×
CPU城行＋觖失率×存储髒访回×缺失代价
×时钟周期时旧
CPU时间包括缓存=IC×［1.0x（1.5×2%×200）］ ×时钟周期时间
= IC ×7.00x时钟周期时间

在有、无缓存情况下，时钟周期时间和指令数均相同。因此，CPU 时间提高至7
倍，CPI 从“完美缓存”的1.00 增加到可能产生缺失的缓存的 7.00。在根本没有
任何存储器层次结构时，CPU将再次升高到 1.0+200x 1.5=301，比带有缓存的系
统长出 40多倍。

如上例所示，缓存特性可能会对性能产生巨大影响。此外，对于低CPI、高时钟频率的处
理器，缓存缺失会产生双重影响。

（1）CPI *t越低，固定数目的缓存缺失时钟周期产生的相对影响越高。
（2） 在计算CPI时，一次缺失的缓存缺失代价是以处理器时钟周期进行计算的。因此，即使
两个计算机的存储器层次结构相同，时钟频率较高的处理器在每次缺失时会占用较多的时钟周
期，CPI 的存储器部分也相应较高。

对于低 CPI、高时钟频率的处理器，缓存的重要性更高，因此，如果在评估此类计算机的
性能时忽略缓存行为，其危险性更大。Amdahl定律再次发挥威力！

尽管将存储器平均访问时间降至最低是一个合理的目标（在本附录中大多使用这一目标），
但请记住，最终目标是缩短处理器执行时间。下面的例子说明如何区分这两者。

例题

两种不同缓存组织方式对处理器性能的影响如何？假定完美缓存的CPI为1.6，时
钟周期时间为0.35ns，每条指令有1.4次存储器引用，两个缓存的大小都是128 KB，
两者的块大小都是 64 字节。一个缓存为直接映射，另一个为两路组相联。图B-3
显示，对于组相联缓存，必须添加一个多工器，以根据标志匹配在组中的块之间作
出选择。由于处理器的速度直接与缓存命中的速度联系在一起，所以假定必须将处
理器时钟周期时间扩展 1.35倍，才能与组相联缓存的选择多工器相适应。对于一
级近似，每一种缓存组织方式的缓存缺失代价都是65纳秒。（在实践中，通常会舍
人为整数个时钟周期。）首先，计算存储器平均访问时间，然后再计算处理器性能。

解答
假定命中时间为1个时钟周期，128 KB 直接映射缀存的觖失率为2.1%，同等大小
的两路组相联缓存的缺失率为1.9%。
存储器平均访问时间为：
存储器平均访问时间=命中时间+缺失率×缺失代价
因此，每种组织方式的时间为：
存储器平均访问时间-時=0.35+（0021× 65）=1.72ns
存储器平均访问时间两W=0.35×1.35+（0019 x 65）=1.71ns
这一存储器平均访问时间优于两路组相联缓存。
处理器性飴为：
CPU时间=ICxCPTu+
觖失数 × 缺失代价 ×时钟周翅时间
指令数
=1 IC×
（cPi以行 ×时钟周期时间）
敏失率x任傳慧等婴改數x皱失代价x时鲜圆期时间））」
将（缺失代价 ×时钟周期时间）代以 65ns，可得每种缓存组织方式的性能为：
CPU 时间-路=IC ×［1.6x 0.35+（0.021 ×1.4×65）］=2.47 ×IC
CPU 时间商時=IC × ［1.6× 0.35 × 1.35+（0.019×1.4×65）］-2.49 ×IC
相对性能为：
2PU時開地-3织x指參發-2
=1.01
CPU时间一路

与存储器平均访问时间的对比结果相反，直接映射缓存的平均性能略好一些，这是
因为尽管两组组相联的缺失数较少，但针对所有指令扩展了时钟周期。由于CPU
时间是我们的基本评估，而且由于直接映射的构建更简单一些，所以本示例中的优
选缓存为直接映射。

\subsection{缺失代价与乱序执行处理器}
对于乱序执行处理器，如何定义“缺失代价”呢？是存储器缺失的全部延迟，还是仅考虑
处理器必须停顿时的“暴露”延迟或无重叠延迟？对于那些在完成数据缺失之前必须停顿的处
理器，不存在这一问题。

让我们重新定义存储器停顿，得到缺失代价的一种新定义，将其表示为非重叠延迟：
在雙緊參緩些塑。警麥發x（台被失代价-正產鍊失速地）

与此类似，由于一些乱序处理器会拉长命中时间，所以性能公式的这一部分可以除以总命中延
迟减去重叠命中延迟之差。可以对这一公式进一步扩展，将总缺失延迟分解为没有争用时的延
迟和因为争用导致的延迟，以考虑乱序处理器中的存储器资源。我们仅关注缺失延迟。
我们现在必须决定以下各项。

口 存储器延迟长度——在乱序处理器中如何确定存储器操作的起止时刻。
口 延迟重叠的长度——如何确定与处理器相重叠的起始时刻（或者说，在什么时刻我们说
存储器操作使处理器停顿）

由于乱序执行处理器的复杂性，所以不存在单一的准确定义。

由于在流水线退出阶段只能看到已提交的操作，所以我们说：如果处理器在一个时钟周期
内没有退出（retire）最大可能数目的指令，它就在该时钟周期内停顿。我们将这一停顿记在第
一条未退出指令的账上。这一定义绝不像看上去那么简单。例如，为缩短特定停顿时间而应用
某一种优化，并不一定总能缩短执行时间，这是因为此时可能会暴露出另一种类型的停顿（原
本隐藏在所关注的停顿背后）。

关于延迟，我们可以从存储器指令在指令窗口中排队的时刻开始测量，也可以从生成地址
的时刻开始，还可以从指令被实际发送给存储器系统的时刻开始。只要保持一致，任何一种选
项都是可以的。

例题
让我们重做上面的例题，但这一次假定具有较长时钟周期时间的处理器支持乱序技
术，但仍采用直接映射缓存。假定65 ns 的缺失代价中有30%可以重叠，也就是说，
CPU 存储器平均停顿时间现在为45.5 ns。

解答
乱序计算机的存储器访问时间为：
存储器平均访问时间一路、热序=0.35 ×1.35+（0.021 × 45.5）=1.43 ns
乱序缓存的性能为：

CPU 时间-路、乱净 IC×［1.6× 0.35 × 1.35+（0.021 × 1.4×45.5）］=2.09 ×IC
因此，尽管乱序计算机的时钟周期时间要慢得多，直接映射缓存的缺失率也更高一
些，但如果它能隐藏30%的缺失代价，那仍然可以稍快一些。

总而言之，尽管乱序处理器存储器停顿的定义和测量比较复杂，但由于它们会严重影响性
能，所以应当了解这些问题。这一复杂性的出现是因为乱序处理器容忍由缓存缺失导致一定的延
迟，不会对性能造成伤害。因此，设计师在评估存储器层次结构的权衡时，通常使用乱序处理器
与存储器的模拟器，以确保一项帮助缩短平均存储器延迟的改进能够真的有助于提高程序性能。
为了帮助总结本节内容，同时也作为一个方便使用的参考，图B-4列出了本附录中的缓存
公式。

缓存大小
241-块大尔×组相联度
CPU执行时间=（CPU时钟周期＋存储器停顿周期）×时钟周期时间
存储器停顿周期=缺失数×缺失代价
存储群停顿周期=ICx鲮失救 ×饮失代价
鲛失数二鉄失率x在储器访间
指令
措令

存储器平均访问时间-命中时间+缺失率 ×觖失代价
CPU执行时间=ICx CPla +仔儲器修顿时钟周期
×时钟周期时间
指令数
图B-4 本附录中的性能公式汇总。第一个公式计算缓存索引大小，其余公式帮助评估性能。后两个公式
处理多级缓存，在下一节的开头部分会对其进行介绍。将它们包含在此处，使本图成为有用的参
考资料

\begin{verbatim}
    CPU救行时何二ICx（ cPlawi - 紫券發） x故共代分x时鉀勵期时圖
    缺失访问
    CPU执行时 =IC×
    CPI执行+缺失率×-
    指令数
    ×缺失代价 ×时钟周期时间
    存储器停顿周期_䱀失数
    x（总缺失延迟-重叠缺失延迟）
    指令
    指令效
    存储器平均访问时间=命中时间L+缺失率1×（命中时间 12+缺失率_2×觖失代价_2）
    任储鲜仁奶周期-集参×命中时间心+警袋發
    蚊失数 ×缺失代价 2
    图B-4（续）
    421
\end{verbatim}

\section{6种基本的缓存优化}
存储器平均访问时间公式 我们提供了一个框架，用于展示提高缓存性能的缓存优化方法：

存储器平均访问时间=命中时间＋缺失率×缺失代价

因此，我们将6种缓存优化分为以下3类。

口降低缺失率—较大的块、较大的缓存、较高的关联度。
口降低缺失代价——多级缓存，为读取操作设定高于写入操作的优先级。
口缩短在缓存中命中的时间—在索引缓存时避免地址转换。

表B-8 汇总了这6种技术的实现复杂度和性能优势，作为本节的总结。

改进缓存特性的经典方法是降低缺失率，我们给出3种实现技术。为了更好地理解导致缺
失的原因，首先介绍一个模型，将所有缺失分为3个简单类别。

口强制缺失（Compulsory）—在第一次访问某个块时，它不可能会在缓存中，所以必须
将其读到缓存中。这种缺失也被称为冷启动缺失或首次引用毓失。
口 容量缺失（Capacity）——如果缓存无法容纳程序执行期间所需要的全部块，由于一些块
会被放弃，过后再另行提取，所以会（在强制缺失之外）发生容量续失。
口 冲突缺失（Confict）——如果块布置策略为组相联或直接映射，则会（在强制缺失和容
量缺失之外）发生冲突缺失，这是因为如果有太多块被映射到一个组中，这个组中的某
个块可能会被放弃，过后再另行提取。这种缺失也被称为碰撞缺失。其要点就是：由于
对某些常用组的请求数超过n，所以本来在全相联缓存中命中的情景会在 n 路组相联缓
存中变为缺失。

（第5 章增加了第四个 C，即一致性（Cohereney）缺失，它是因为要在多处理器中保持多个缓
存一致而进行缓存刷新所导致的；这里不讨论此类毓失。）

表B-4显示了根据3C分类后的缓存缺失相对频率。强制缺失在无限缓存中发生，容量缺
失在全相联缓存中发生。冲突缺失在从全相联变为八路相联、四路相联•••时发生。图B-S以
图形方式展示相同数据。上图显示绝对缺失率，下图绘制了当缓存大小变化时，各类觖失占总
缺失数的百分比曲线。

B-22
422
附录B 存储器层次结构回顾
表B-4 每种缓存大小的总缺失率，及根据3C划分的每种缺失所占百分比
\begin{verbatim}
    缺失率组成（相对百分比）（总和=总缺失率的百分之百）
    相联魔
    总缺失率
    容量缺失
    0.070
    缓存大小（KB）
    4
    4
    4
    4
    gs
    8
    8
    8
    9r
    16
    16
    32
    32
    32
    32
    64
    64
    64
    64
    128
    128
    128
    128
    2$6
    256
    256
    0.0001
    256
    0.0001
    512
    0.0001
    512
    0.0001
    512
    0.0001
    0.00s
    512
    八路
    0.0001
    1.1%
    0.005
    95%
\end{verbatim}
*强制缺失与绿存大小无关，而容量缺失随容量的增加而降低，冲突缺失随相联度的增大而降低。图B-5 以圈形方式
显示了相同数据。注意，在不超过128 KB时，大小为N的直接映射缓存的缺失率大約与大小为 NZ2 的两路組相联缓
存的缺失率相同。大于128KB的组存不符合这一规则。注意，“容量”列给出的也是全相联缺失率。数据的收集方
或与表B-2中一样，也是使用LRU替換方式收集的。

图B-5 根据表B-4 中的3C 数据，每种不同缓存大小的总缺失率（上）和缺失率分布（下）。上图显示
实际数据缓存缺失率，下图显示每个类别的百分比（与表B-4 中所能容纳的缓存大小相比，本图
中的空间使这些图形能够多显示一种缓存大小。）

为了展示相联度的好处，将冲突缺失划分为每次相联度下降时所导致的缺失。一共有4类
冲突缺失，其计算方式如下所示。

口 八路从全相联（无冲突）到八路相联时产生的冲突缺失。
口 四路—从八路相联到四路相联时产生的冲突缺失。
口 两路—从四路相联到两路相联时产生的冲突缺失。
口一路——从两路相联到一路相联（直接映射）时产生的冲突缺失。

从图中可以看出，SPEC2000 程序的强制缺失率非常低，对许多长时间运行的程序都是
如此。

在确认这3C缺失率之后，计算机设计师可以针对它们做点什么呢？从概念上来讲，冲突
缺失是最容易避免的：全相联布置策略就可以避免所有冲突缺失。但是，全相联的硬件实现成
本非常高昂，可能会降低处理器时间频率（见B.3.3 节的示例），从而降低整体性能。

除了增大缓存之外，针对容量缺失没有什么办法了。如果上一级存储器远小于程序所需要
的容量，那就会有相当一部分时间用于在层次结构的两级之间移动数据，我们说这种存储器层
次结构将会摆动。由于需要太多的替换操作，所以摆动意味着计算机的运行速度接近于低级存
储器的速度，甚至会因为缺失开销变得更慢。

另外一种降低3C 缺失的方法是增大块的大小，以降低强制缺失数，但稍后将会看到，大
型块可能会增加其他类型的缺失。

3C分类使我们可以更深入地了解导致缺失的原因，但这个简单的模型也有它的局限性；它
让我们深人地了解了平均性能，但不能解释个体毓失。例如，由于较大的缓存可以将引用扩展
到更多个块中，所以改变缓存大小会改变冲突缺失和容量缺失。因此，当缓存大小变化时，一
个缺失可能会由容量缺失变为冲突缺失。注意，3C分类还忽略了替换策略，一方面是因为其难
以建模，另一方面是因为它总体来说不太重要。但在具体环境中，替换策略可能会实际导致异
常行为，比如，在大相联度下得到较低的缺失率，这与3C模型的结果矛盾。（有人提议使用地
址跟踪来确定存储器中的最优放置策略，以避免3C模型中的放置缺失；我们在这里没有采纳
这一建议。）

遗憾的是，许多降低缺失率的技术也会增加命中时间或缺失代价。在使用3种优化方法降
低缺失率时，必须综合考虑提高整体系统速度的目标，使两者达到平衡。第一个例子显示了平
衡观点的重要性。

\subsection{第一种优化方法：增大块大小以降低缺失率}

降低缺失率的最简单方法是增大块大小。图B-6针对一组程序及缓存大小，给出了块大小
与缺失率的折中。较大的块大小也会降低强制缺失。这一降低是因为局域性原理分为两个部分：
时间局域性和空间局域性。较大的块充分利用了空间局域性的优势。

图B-6 对于5种不同大小的缓存，缺失率与块大小的相互关系。注意，如果与缓存大小相比，块大小过
大，则缺失率实际上会上升。每条曲线表示一个不同大小的缓存。表B-5给出绘制这些曲线的数
据。遗憾的是，如果包含块大小因素，SPEC2000 跟踪所需要的时间过长，所以这些数据是在
DECstation 5000上运行 SPEC92 获得的［Gee等人，1993］

同时，较大的块也会增加缺失代价。由于它们降低了缓存中的块数，所以较大块可能会增
大冲突缺失，如果缓存很小，甚至还会增加容量缺失。显然，没有理由要将块大小增大到会升
高缺失率的程度。如果它会增加存储器平均访问时间，那降低缺失率也没有什么好处。缺失代
价的增加会超过缺失率的下降。

表B-5 图B-6中5种不同大小缓存的实际缺失率随块大小的变化
\begin{verbatim}
    綴存大小
    块大小
    4K
    16K
    16
    8.57%
    3.94%
    32
    7.24%
    2.87%
    64
    7.00%
    2.54%
    128
    7.78%
    2.77%
    256
    9.51%
    3.29%
    64K
    2.04%
    1.35%
    1.06%
    1.02%
    1.15%
    256K
    1.09%
    0.70%
    0.51%
    0.49%
    0.49%
\end{verbatim}
*注意，财于4KB缓存，块大小为256字节时的敏失率高于32字节。在本例中，缓存大小必须为 256 KB，以使块大
小为256 字节时能够降低缺失。

例题
解答

表B-5显示了图B-6中绘制的实际缺失率。假定存储器系统的开销为80个时钟周
期，然后每2个时钟周期提交16 个字节。因此，它可以在82个时钟周期内提供
16个字节，在84个时钟周期内提供32个字节，以此类推。对于表B-5中的每种
缓存大小，哪种缓存大小的存储器平均时间最短？

存储器平均访问时间为：
存储器平均访问时间=命中时间+缺失率x缺失代价
如果我们假定命中时间为1个时钟周期，与块大小无关，那么在4KB缓存中，对
16学节块的访问时间为：
存储器平均访问时间=1+（8.57%×82）=8.027时钟周期
在256 KB缓存中，对256字节块的存储器平均访问时间为：
存储器平均访同时间=1+（0.49%×112）=1.549时钟周期

表B-6显示了这两个极端值之间所有块与缓存大小的存储器平均访问时间。粗体
项目表示对于给定缓存大小能够实现最快访问的块大小：若缓存大小为 4 KB，则
块大小为32字节时的访问速度最快；若缓存大小大于4 KB，则块大小应为64字
节。事实上，这些数值也正是当前处理器缓存的常见块大小。

表 B-6
图B-10中5种不同大小缓存的存储器平均访问时间随块大小的变化
\begin{verbatim}
    缓存大小
    块大小
    缺失代价
    4K
    16K
    64K
    256K
    16
    82
    8.027
    4.231
    2.673
    1.894
    32
    84
    7.082
    3.411
    2.134
    1.588
    64
    88
    7.160
    3.323
    1.933
    1.449
    128
    96
    8.469
    3.659
    1.979
    1.470
    256
    112
    11.651
    4.685
    2.288
    1.549
\end{verbatim}
*注意，绝大多教的块大小为32字节和64字节。每种缓存大小的最短平均訪间时间用黑体标共点
在所有这些技术中，缓存设计者都在尝试尽可能同时降低缺失率和缺失代价。块索小的选
择有赖于低级存储器的延迟和带宽。高延迟和高带宽鼓励采用大块，因为缓存在每次缺失愈能
够获取的字节可以多出许多，而缺失代价却很少增加。相反，低延迟和低带宽则鼓励采用可块
因为这种情况下采用较大块不会节省多少时间。例如，一个小块的两倍觖失代价可能接近一个
两倍大小块的缺失代价。更多的小块还可能减少冲突缺失。注意，图B-6和表B-6给出了基于
缺失率最低、存储器平均时间最短选择块大小时的差别。

在了解了较大块对强制缺失和容量缺失的正面与负面影响之后，下面两小节将研究较高容
量和较高相联度的可能性。

\subsection{第二种优化方法：增大缓存以降低缺失率}

降低表B-4和图B-5中容量缺失的最明显方法是增加缓存的容量，其明显的缺点是可能延
长命中时间、增加成本和功耗。这一技术在片外缓存中尤其常用。

\subsection{第三种优化方法：提高相联度以降低缺失率}

表B-4 和图B-5显示了缺失率是如何随着相联度的增大而得以改善的。从中可以看出两个
一般性的经验规律。第一条规律是：对于这些特定大小的缓存，从实际降低缺失数的功效来说，
八路组相联与全相联是一样有效的。通过对比表B-4 中的八路项目与容量缺失列可以看出这一
差别，其中的容量缺失是使用全相联缓存计算得出的。

从图中观察得到的第二条规则称为 2：1缓存经验规律：大小为 N 的直接映射缓存与大小
为N2 的两路组相联缓存具有大体相同的缺失率。这一规律对3C图形中小于128KB 的缓存也
是成立的。

与许多此类示例类似，要改善存储器平均访问时间的一个方面，可能会导致另一方面的恶
化。增大块大小可以降低缺失率，但会提高缺失代价；增大相联度可能会延长命中时间。因此，
加快处理器时钟速度的压力鼓励使用简单的缓存设计，但提高相联度的回报是提高缺失代价，
如下例所示。

例题
假定提高相联度将会延长时钟周期时间，如下所示：
时钟周期时间两路= 1.36x时钟周期时间-略
时钟周期时间四路= 1.44x时钟周期时间-路
时钟周期时间八略=1.52x时钟周期时间一路

假定命中时间为1个时钟周期，直接映射情景的缺失代价为到达第2级缓存的25
个时钟周期（见下一小节），在第2级缓存中绝对不会缺失，还假定不需要将续失
代价舍人为整数个时钟周期。利用表B-4 中的缺失率，对于哪种缓存大小来说，
这三种表述是正确的？

存储器平均访问时间八路＜存储器平均访问时间四路
存储器平均访问时间网路＜存储器平均访问时间网路
存储器平均访问时间两路<存储器平均访同时间-路

解答

每种相联度的存储器平均访问时间为：
存储器平均访问时间人二命中时间人略＋缺失率人時×缺失代价人解
=1.52＋缺失率八將×25
存储器平均访问时间四購=1.44+缺失率四W ×25
存储器平均访问时间两1.36+缺失率两路 ×25

存储器平均访问时间-路=1.00+缺失率-路 ×25
每种情况下的缺失代价相同，所以我们使其保持25个时钟周期。例如，对于一个
4 KB 的直接映射缓存，存储器平均访问时间为：
存储器平均访问时间-路 1.00+（0.098×25）=3.44
对于512 KB 八路组相联缓存，该时间为：
存储器平均访问时间人路=1.52+（0.006×25）=1.66

利用这些公式及表B-4 中的缺失率，表B-7 给出了每种缓存和相联度时的存储器
平均访问时间。该表显示，对于不大于8KB、不超过四路相联度的缓存，本例中
的公式成立。从16 KB开始，较大相联度的较长命中时间超过了因为缺失降低所
节省的时间。

表B-7 以表B-4中的缺失率作为本例中参数得出的存储嚣平均访问时间
\begin{verbatim}
    相联魔
    缓存大小（KB）
    一路
    两路
    4
    3.44
    3.25
    8
    2.69
    2.58
    16
    2.23
    2.40
    32
    2.06
    2.30
    64
    1.92
    2.14
    128
    1.52
    1.84
    256
    1.32
    1.66
    512
    1.20
    1.55
    四路
    3.22
    2.55
    2.46
    2.37
    2.18
    1.92
    1.74
    1.59
    八路
    3.28
    2.62
    2.53
    2.45
    2.25
    2.00
    1.82
    1.66
\end{verbatim}
*粗体类型意味着这一时间高于左侧的数字，即较高的相联度延长了存储器平均访问时间。
注意，在本例中，我们没有考虑较慢时钟频率对程序其余部分的影响，因此低估
了直接映射缓存的收益。

\subsection{第四种优化方法：采用多级缓存降低缺失代价}

降低缓存缺失已经成为缓存研究的传统焦点，但缓存性能公式告诉我们：通过降低缺失代
价同样可以获得降低缺失率所带来的好处。此外，图2-2显示的技术趋势表明：处理器的速度
增长快于 DRAM，从而使缺失代价的相对成本随时间的推移而升高。

处理器与存储器之间的性能差距让架构师开始思考这样一个问题：是应当加快缓存速度以
与处理器速度相匹配呢？还是让缓存更大一些，以避免加宽处理器与主存储器之间的鸿沟？
一个回答是：两者都要。在原缓存与存储器之间再添加一级缓存可以简化这一决定。第一
级缓存可以小到足以与快速处理器的时钟周期时间相匹配。而第二级缓存则大到足以捕获本来
可能进入主存储器的访问，从而降低实际缺失代价。

尽管再添加一级层次结构的思路非常简单，但它增加了性能分析的复杂程度。第二级缓存
的定义也并非总是那么简单。首先让我们为一个二级缓存定义存储器平均访问时间。用下标L1
和L2分别指代第一级、第二级缓存，原公式为：

存储器平均访问时间=命中时间工+缺失率 LI×鋏失代价LI

及

缺失代价=命中时间 r2+缺失率L2×缺失代价z2
得
B-29
B-3g
F3
428
附录B 存储器层次結构回顾
存储器平均访问时间=命中时间L+缺失率L！
x（命中时间 z2+缺失率L2×缺失代价12）

在这个公式中，第二级缺失率是针对第一级缓存未能找到的内容进行测量的。为了避免模糊，
对二级缓存系统采用以下术语。

口局部缺失率——此比值即是缓存中的缺失数除以对该缓存进行存储器访问的总数。可以
想到，对于第一级缓存，它等于缺失率L1，对于第二级缓存，它等于缺失率 \_20
口 全局缺失率—缓存中的缺失数除以处理器生成的存储器访问总数。利用以上术语，第
一级缓存的全局缺失率仍然为缺失率L1，但对于第二级缓存则为缺失率L1*缺失率L20
第二级缓存的这一局部缺失率很大，这是因为第一级缓存已经提前解决了存储器访问中便
于实现的部分。这就是为什么说全局缺失率是一个更有用的度量标准：它指出在处理器发出的
存储器访问中，有多大比例指向了存储器。

这是一个让每条指令缺失数度量闪光的地方。利用这一度量标准，不用再担心局部缺失率
或全局缺失率的混淆问题，只需要扩展每条指令的存储器停顿，以增加第二级缓存的影响。
\begin{verbatim}
    每条指令的平均存储器停顿时间-每条指令的缺失数LI ×命中时间12
    +每条指令的缺失数L2×缺失代价_2
\end{verbatim}

例题


假定在1000次存储器引用中，第一级缓存中有40次缺失，第二级缓存中有20次
缺失。各缺失率等于多少？假定L.2缓存到存储器的缺失代价为200个时钟周期，
L2缓存的命中时间为10个时钟周期，L.1 的命中时间为1个时钟周期，每条指令
共有1.5次存储器引用。每条指令的存储器平均访问时间和平均停顿周期为多少？
忽略写人操作的影响。

解答
第一级缓存的缺失率（局部缺失率或全局缺失率）为40/1000=4%。第二级缓存的
局部缺失率为 20/40=50%。第二级缓存的全局缺失率为20/1000-2%。则：
\begin{verbatim}
    存储器平均访问时间=命中时间_1+缺失率 L1
    x（命中时间z2+鉄失率12×缺失代价rz）
    =1+4%×（10+50% ×200）
    =1+4%×110-5.4个时钟周期
\end{verbatim}

为了知道每条指令会有多少次缺失，我们将1000次存储器引用除以每条指令的1.5
次存储器引用，得到667条指令。因此，我们需要将缺失数乘以1.5，得到每干条
指令的缺失数。于是得到每干条指令的L1缺失数为40x1.5=60次，L2缺失数为
20x1.5=30次。关于每条指令的平均存储器停顿，假定缺失数在指令与数据之间
是均匀分布的：

每条指令的平均存储器停顿=每条缺失的缺失数LI ×命中时间12
+每条指令的缺失数L2×缺失代价L2
=（60/1000） × 10+（30/1000）×200
=0.060 x 10+0.030x 200=6.6个时钟周期

如果从存储器平均访问时间（AMAT）中减去L1 命中时间，然后再乘以每条指令
的平均存储器引用数，则可以得到每条指令平均存储器停顿值：

（5.4-1.0） ×1.5=4.4×1.5=6.6个时钟周期
B.3 6种基本的缓存优化
429
如本例所示，与缺失率相比，使用每条指令的缺失数进行计算可能减少多级缓存
造成的混淆。

注意，这些公式是针对混合式读取与写人操作的，假定采用写回第一级缓存。显然，直写
第一级缓存会将所有写人操作都发往第二级，而不是仅限于缺失，而且还可能使用写入缓冲区。
图B-7和图B-8显示了一个设计中的缺失率和相对执行时间是如何随着第二级缓存的大小
而变化的。从两个图中可以有两点体悟。第一，如果第二级缓存远大于第一级缓存，则全局缓
存缺失率与第二级缓存的单一缓存敏失率非常类似。第二，局部缓存缺失率不是第二级缓存的
良好度量标准；它是第一级缓存缺失率的函数，因此可以通过改变第一级缓存而变化。所以，
在评估第二级缓存时，应当使用全局缓存缺失率。

100%
99%
99%
90%
98%
96%
88%
80%
—本地缺失率
一-全局缺失率
—一单个缓存缺失率
70%
60%
50%
67%
：55%
51%
40%
46%
39%
30%
34%
20%
10%
0% -
14%4%~2
16
32
64
128
256
512
1024 2048
4096
缓存大小（KB）
图 B-7

多级缓存的缺失率随缓存大小的变化。小于两个64KB一级缓存总和的第二级缓存没有什么意义，
从其高缺失率中可以反映出这一点。大于256 KB 之后，单个缓存在全局缺失率在10%以内。单
级缓存的缺失率随大小的变化是根据第二级缓存的局部缺失率和全局缺失率绘制的，采用的是
32 KB一级缓存。L2缓存（统一缓存）为两路组相联，采用替换策略。分别有独立的L.2指令与
数据缓存，它们都是64 KB 两路组相联，采用LRU替换策略。L1 与L.2缓存的块大小均为64字
节。数据的收集条件与图表B-2相同

有了这些定义，我们可以考虑第二级缓存的参数。两级缓存之间的首要区别就是第一级缓
存的速度影响着处理器的时钟频率，而第二级缓存的速度仅影响第一级缓存的缺失代价。因此，
我们可以在第二级缓存中考虑许多不能用于第一级缓存的替代选项。在设计第二级缓存时，主
要有两个问题：是否要降低 CPI 的存储器平均访问时间部分？其成本有多高？

首先要决定的是第二级缓存的大小。由于第一级缓存中的所有内容都可能在第二级缓存中，
所以第二级缓存应当远大于第一级缓存。如果第二级缓存只是稍大一点，那局部缺失率将会
很高。这一观察结果激励了巨型第二级缓存的设计——其大小达到较早期计算机主存储器的
规模！

B-32
430
附录B 存储器层次结构回顾
8192
1.02
1,06
L2命中=8时钟周期
翻L2命中=16时钟周期
4096
1.10
1.14
2048
1.60
1.65
1024
H782
512
11.94
1.99
256
2.34
2.39
2.30
留 B-8
1.00
1.25
1.50
15s
2.00
225
相对执行肘间
相对执行时间与第二级缓存大小的关系。图中的每两个长条表示一次L.2 缓存命中的不同时钟周
期。引用执行时间1.00是指一个8192KB 第二级缓存在第二级命中的延迟为1个时钟周期。这些
数据的收集方式与图B-7相同，使用模拟器模拟了 Alpha 21264
有一个问题是：组相联对于第二级缓存是否有意义？

例题
解答
B-33

给定以下数据，第二级缓存相联度对其缺失代价的影响如何？

口 直接映射的命中时间z2为10个时钟周期。
口 两路组相联将命中时间增加0.1个时钟周期，达到10.1个时钟周期。
口 直接映射的局部缺失率12为25%。
口缺失代价12为200个时钟周期。
口两路组相联直接映射的局部缺失率12为20%。

对于直接映射第二级缓存，第一级缓存缺失代价为：
缺失代价-路L2= 10+25% ×200=60.0个时钟周期
加上相联度的成本仅使命中成本增加 0.1个时钟周期，由此得到新的第一级缓存缺
失代价为：

B-34
缺失代价两将12= 10.1+20% ×200=50.1个时钟周期
事实上，第二级缓存几乎总是与第一级缓存、处理器同步。相应地，第二级命中
时间必须为整数个时钟周期。如果幸运的话，我们可以将第二级命中时间缩短到
10个时钟周期；如果不够幸运，则会舍人到11个周期。相对于直接映射第二级缓
存，任一选项都是一种改进：
缺失代价两時12=10+20%×200=50.0个时钟周期
缺失代价两時12=11+20% ×200= 51.0个时钟周期
现在我们可以通过降低第二级缓存的缺失率来降低敏失代价了。
另一条关注事项涉及第一级缓存中的数据是否在第二级缓存中。多级包含是存储器层次结
构的一种自然策略：L1 数据总是出现在L2 中。这种包含性是我们所希望的，因为仅通过检查
第二级缓存就能确定1/O与缓存之间（或多处理器中的缓存之间）的一致性。

包含性的一个缺点就是：测量结果可能提议对较小的第一级缓存使用较小的块，对较大的
第二级缓存使用较大的块。例如，Pentium 4的LI缓存中的块为64个字节，L2缓存中的块为
128个字节。包含性仍然能够得到保持，但在第二级缺失时要做更多工作。如果一级块所映射
的二级块将被替换，则第二级缓存必须使所有此类—级块失效，从而会略微提高第一级缺失率。
为了避免此类问题，许多缓存设计师使所有各级缓存的块大小保持一致。

但是，如果设计师只能承受略大于L1缓存的L2缓存呢？它是不是有很大一部分空间要被
用作L1缓存的冗余副本？在此种情况下，可以使用一种明显相反的策略：多级互斥，L1 中的
数据绝对不会出现在L.2缓存中。典型情况下，在采用互斥策略时，L1中的缓存缺失将会导致
L1 与L.2的块交换，而不是用L.2块来替代L.1块。这一策略防止了L2缓存中的空间痕费。例如，
AMID Opteron 芯片使用两个64KBL1缓存和1 MB L1缓存来执行互斥策略。

这些问题表明，尽管一些新手可能会独立地设计第一级和第二级缓存，但在给定一个兼容
第二级缓存时，第一级缓存设计师的任务要简单一些。比如，如果下一级有写回缓存来为重复
写人操作提供支持，而且使用了多级包含，那使用直写的风险就会小一些。

所有缓存设计的基础都是在加速命中和减少缺失之间实现平衡。对于第二级缓存，命中数
要比第一级缓存中少得多，所以重心更多地偏向减少缺失。因为这一认知，人们开始采用大得
多的缓存和降低缺失率的技术，比如更高的相联度和更大的块。

B.3.5
\subsection{第五种优化方法：使读取缺失的优先级高于写入缺失，以降低缺失代价}
这一优化方法在完成写入操作之前就可以为读取操作提供服务。我们首先看一下写人缓冲
区的复杂性。

采用直写缓存时，最重要的改进就是一个大小合适的写人缓冲区。但是，由于写人缓冲区
可能包含读取缺失时所需要的更新值，所以它们的确会使存储器访问变得复杂。

例题

看以下序列：
SW R3,512（RO）
；M［512］ R3
（cache index 0）
LH R1，
1024（R0）
；R1个 M［1024］
（cache index O）
LW R2,512（RO）
；R2 M［512］
（cache index 0）

假定有一个直接映射直写缓存，它将512和 1024映射到同一块中，假定有一个四
字写人缓存区，在读取缺失时不会进行检查。R2中的值是否总等于R3中的值？
解答

使用第2章的术语，这是存储器中的一个“写后读”数据冒险。我们通过眼踪一次
缓存访问来了解这种危险性。R3的数据在存储之后被放在写人缓冲区中。随后的
载人操作使用相同的缓存索引，因此产生一次缺失。第二条载人指令尝试将位置
512 处的值放到寄存器R2 中，这样也会导致一次缺失。如果写人缓冲区还没有完
成向存储器中位置512的写入，对位置512的读取就会将错误的旧值放到缓存块中，
然后再放人R2中。如果没有事先防范，R3是不等于R2的！

摆脱这一两难境地的最简单方法是让读取缺失一直等待到写人缓冲区为空为止。一种替代
方法是在发生读取缺失时检查写入缓冲区的内容，如果没有冲突而且存储器系统可用，则让读取
缺失继续。几乎所有桌面与服务器处理器都使用后一方法，使读取操作的优先级高于写入操作。
处理器在写回缓存中的写人成本也可以降低。假定一次读取缺失将替换一个脏服务器块。

我们不是将这个脏块写到存储器中，然后再读取存储器，而是将这个脏块复制到缓冲区中，然
后读存储器，然后再写存储器。这样，处理器的读取操作将会很快结束（处理器可能正在等待
这一操作的完成）。和前一种情况类似，如果发生了读取缺失，处理器或者停顿到缓冲区为空，
或者检查缓冲区中各个字的地址，以了解是否存在冲突。

我们已经介绍了五种用于降低缓存嵌失代价或缺失率的优化方法，现在该来研究一下如何
降低存储器平均访问时间的最后一个分量。命中时间会影响到处理器的时钟频率，所以它是至
关重要的；在今天的许多处理器中，缓存访问时间限制都限制了时钟频率，即使那些使用多个
时钟周期来访问缓存的处理器也是如此。因此，缩短命中时间可以对各个方面提供帮助，从而
具有多重重要性，超出了存储器平均访问时间公式的限制。

\subsection{第六种优化方法：避免在索引缓存期间进行地址转换，以缩短命中时间}
即使一个小而简单的缓存也必须能够将来自处理器的虚拟地址转换为用以访问存储器的物
理地址。如 B.4 节所述，处理器就是将主存储器看作另一级存储器层次结构，因此，必须将存
在于磁盘上的虚拟存储器地址映射到主存储器。

根据“加快常见情景速度”这一指导原则，我们为缓存使用虚拟地址，因为命中的出现频
率当然远高于缺失。这种缓存被称为虚拟缓存，而物理缓存用于表示使用物理地址的传统缓存。
稍后将会看到，区别以下两项任务是非常重要的：索引缓存、对比地址。因此，问题是：在索
引缓存中应当使用虚拟地址还是使用物理地址，在标志对比中应当使用虚拟地址还是使用物理
地址。如果对索引和标志都完全采用虚拟寻址，那在缓存命中时就可以省掉地址转换的时间。
那为什么不是所有体系结构都构建虚拟寻址的缓存呢？

一个原因是要提供保护。在将虚拟地址转换为物理地址时，无论如何都必须检查页级保护。
一种解决方案是在缺失时从 TLB 复制保护信息，添加一个字段来保存这一信息，然后在每次访
问虚拟寻址缓存时进行核对。

另一个原因是：在每次切换进程时，虚拟地址会指向不同的物理地址，需要对缓存进行刷
新。图B-9显示了这一刷新对缺失率的影响。一种解决方案是增大缓存地址标志的宽度，增加
一个进程识别符标志（PID）。如果操作系统将这些标志指定给进程，那么只需要在 PID被回收
时才刷新缓存；也就是说，PID可以区分缓存中的数据是不是为此这个程序准备的。图B-9显
示了通过PID避免缓存刷新而对缺失率的改善。

虚拟缓存没有更加普及的第三个原因是操作系统和用户序可能为同一物理地址使用两种
不同的虚拟地址。这些重复地址称为同义地址或别名地址，可能会在虚拟缓存中生成同一数据
的两个副本；如果其中一个被修改了，另一个就会包含错误值。而采用物理缓存是不可能发生
这种情况的，因为这些访问将会首先被转换为相同的物理缓存块。

同义地址问题的硬件解决方案称为别名消去，保证每个缓存块都拥有一个独一无二的物理
地址。例如，AMD Opteron使用两路组相联的64KB 指令缓存，页大小为4KB；因此，硬件必
须处理组索引中三个虚拟地址位所涉及的别名问题。它避免别名的方法就是在发生缺失时检查
所有8种可能地址（4个组中各有2个块），以确保它们都与被提取数据的物理地址相匹配。如
果发现匹配，则使其失效，所以在向缓存中载入新数据时，就能保证它们的物理地址是独一无
二的。

软件可以强制这些别名共享某些地址位，从而大大简化了这一问题。比如 Sun Microsystems
出品的一个较早 UNIX版本，它要求所有别名地址的后面18位都必须相同；这一限制称为页面
着色。注意，页面着色就是向虚拟存储器应用的组相联映射：使用64（26）个组来映射 4 KB
（22）个页面，确保物理地址和虚拟地址的后18位匹配。这一限制意味着不大于28（256K）
字节直接映射缓存绝对不会为块使用重复的物理地址。从缓存的角度来看，页着色有效地增大
了页偏移，因为软件保证了虚拟、物理页地址的最后几位是相同的。

20%
0.6%
0.4%
18% -
16%-
14%-
1.1%
0.5%
圈清除
•PID
•单进程
12%-
煉 10%0-
8%-
18.8%
1.8%
0.6%
13.0%
6%-
2.7%
3.4%
4%-
8.7%
0.6%
3.9%
0.4%
4.1%
4.3%
4.3%
4.3%
2%-
3.9%
2.7%
0.4%
0.9%
1.3%
1:49
0%
0.3%
03%
2K
4K
8K
I6K
32K
64K
128K
256K
93%
00.3%
18:38
512K 1024K
缓存大小
图 B-9

一个程序的缺失率随虚拟寻址缓存大小的变化，分三种情况测量：没有进程切换（单进程）、使
用进程识别符标志（PID）进行进程切换，有进程切换但没有 PID，即清除（purge）模式，PID
使单进程绝对缺失率增加 0.3%~0.6%，比清除模式节省0.6%~4.3%。Agarwal ［1987］针对 VAX
上运行的 UItrix 操作系统收集了这些统计数字，假定采用直接映射缓存，块大小为16字节。注意
缓存大小从128 K到256K时缺失率的增加。因为大小变化会改变存储器块到缓存块的映射，而
这种变化又会改变冲突缺失率，所以在缓存中可能会发生这种与人们直观感觉不一致的行为
最后一部分与虚拟地址相关的领域是I/O。1/O通常使用物理地址，从而需要映射到虚拟地
址，以与虚拟地址进行交换。（1/O对缓存的影响将在附录D中另行深入讨论。）

一种使虚拟缓存与物理缓存均能实现最佳性能的备选方法是使用一部分页偏移量（也就是
虚拟地址与物理地址保持一致的那一部分）来索引缓存。在使用索引读取缓存的同时，地址的
虚拟部分被转换，标志匹配使用了物理地址。

这一备选方法允许缓存读取操作立即开始，而标志对比仍然使用物理地址。这种虚拟索引、
物理标志备选方法的局限性是直接映射缓存不能大于页大小。例如，在图B-3中的数据缓存中，
这个索引为9位，缓存块偏移量为6位。为了利用这一技巧，虚拟页大小至少为200个字节，
即32KB。如果不是这样，则必须将该索引的一部分由虚拟地址转换为物理地址。图B-10显示
了在使用这一技术时的缓存、转换旁视缓冲区（TLB）和虚拟存储器的组织方式。

\begin{verbatim}
    B-38
    434
    附录B
    存储器层次结构回顾
    虚拟地址<64>
    虚拟页号<$0>
    TLB标志对比地址<43>
    页偏移量<14>
    TLB 索引 7>
    LI 缓存索引<8≥ 块偏移量≤6>
    至CPU
    TLB 标志<43>
    TLB 数据<26>
    L.I缓存标志<26>
    LI 数据<512>
    L1标志对比地址<26>
    至CPU
    物理地址<40>
    L2 标志对比地址<21> L2缓存索引<14>
    块偏移量<6>
    至CPU
    L2缓存标志<21>
    L.2 数据<512>
    1-39
    至LI缓存或CPU
\end{verbatim}
图B-10 一种从虚拟地址到L2缀存访问的虚设存储层次结构的整体图像。页大小为16 KB。TLB 是拥
有256项的两路组相联。L1缓存是一个直接映射16 KB，L2缓存是一个总容量为4 MB 的四路
组相联。这两者的块大小都是64个字节。虚拟地址为64位，物理地址为40位

相联度可以将此索引保存在地址的物理部分，但仍支持大型缓存。回想一下，索引的大小
受以下公式的控制：

缓存大小
243- 玦大小x组相联

例如，使相联度和缓存大小同时加倍并不会改变索引的大小。作为一个极端示例，IBM3033缓
存是个十六路组相联，尽管研究表明：在八路以上的组相联中，对缺失率没有什么好处。尽
管 IBM 体系结构中存在页大小为4 KB这一障碍，这一高相联度允许使用物理索引对64KB缓
存进行寻址。

\subsection{基本缓存优化方法小结}

本节介绍了用于降低缺失率与缺失代价、缩短命中时间的技术，这些技术通常会影响到存
储器平均访问公式的其他部分，还会影响到存储器层次结构的复杂性。表B-8总结了这些技术，
并估计了对复杂性的影响，“+” 表示该技术对该因素有改进，“\_” 表示该技术对该因素有伤害，
空白表示没有影响。本图中任何一项优化方法都不能对一个以上的类别提供帮助。

表B-8 关于本附录中介绍的技术，基本缓存优化对缓存性能和复杂度的影响汇总
技术
衛中时间
缺失代价
缺失率
硬件复杂廑
备注
较大的块大小
-
+
微小；Peatium 4L2使用128字节
较大的缓存大小
+
较高的相联度
+
多级缓存
+
1
1
2
产泛应用，特别是对L2缓存
广泛应用
昂贵的硬件，如果L1块大小 L.2块大
小，广泛应用
广泛应用
读取操作优先级高
于写入操作
+
1
避免在级存索引期
广泛应用
间进行地址转换
+
1
*从整体上来说，一项技术只能改善一个因素。+意味着该技术对诚因素有改进，一意味着它财该困素有伤害，空白表
示没有影响。复杂康是主观的，0表示最容易，3表示最富挑战性。

\section{虚拟存储器}
……已经设计了一种系統，使磁芯组合存储方式（core drum combination）在程序员看来就
是单个存储层，必要的转移都是自动进行的。
—Kilburn 等人［1962］

计算机在任何时刻都在运行多个进程，每个进有自己的地址空间。（进程将在下一节描
述。）让每个进程专门使用存储器的完整地址空间，成本太高了，特别是许多进程连其自己的地
址空间也只使用了很少一部分。因此，必须有一种方法，用于在许多进程之间共享较少量的物
理空间。

其中一种做法—虚拟存储器，将物理存储器划分为块，并分配给不同的进程。这种方法
必然要求采用一种保护机制来限制各个进程，使其仅能访问属于自己的块。虚拟存储器的许多
形式还缩短了程序的启动时间，因为程序启动之前不再需要物理存储器中的所有代码和数据。
尽管由虚拟存储器提供的保护对于目前的计算机来说是必需的，但共享并不是发明虚拟内
存的原因。如果一个程序对物理内存来说变得过于庞大，就需要由程序员负责将其装进去。程
序员将程序划分为片段，然后确认这些互斥的片断，在执行时间根据用户程序控制来加载或
载这些覆盖段（overlay）。程序员确保程序绝对不会尝试访问超出计算机现有的物理主存储器，
并确保会在正确的时间加载正确的覆盖段。容易想到，这种责任降低了程序员的生产效率。
虚拟存储器的发明是为了减轻程序员的这一负担；它自动管理表示为主存储器和辅助存储
的两级存储器层次结构。图B-11显示了程序从虚拟存储器到物理存储器的映射，共有4个页面。
除了共享受保护的存储器空间和自动管理存储器层次结构之外，虚拟存储器还简化了为执行
程序而进行的加载过程。这种被称为再定位（relocation）的机制允许同一程序在物理存储器中的
任意位置运行。图B-11中的程序可以定位在物理存储器中的任何位置，也可以放在磁盘上，只需
要改变它们之间的映射即可。（在虚拟存储器普通之前，处理器中包含一个用于此目的的再定位
寄存器。）硬件解决方案的一种替代方法是使用软件，在每次运行一个程序时，改变其所有地址。

\begin{verbatim}
    B-40
    B-41
    B-42
    436
    附录B 存储器层次结构回顾
    虚拟地址
    0
    4KB
    8KB
    12KB
    A
    B
    C
    D
    虚拟存儲器
    物理地址
    o
    「4KB
    8KB
    12KB
    -16KB
    20KB
    - 24KB
    28KB
    C
    A
    B
    物理主
    存储器
    磁盘
    D
\end{verbatim}
图B-11 左侧给出位于相邻虚拟地址空间中的逻辑程序。它包括A、B、C和D4个页。这些块中有3个
的实际位置在物理主存储器中，另一个位于磁盘上

第1章中几个有关缓存的一般性存储器层次结构思根与虚拟存储器类似，当然，其中有许
多术语不同。页或段表示块，页错误或地址错误用于觖失。有了虚拟存储器，处理器会给出虛
拟地址，由软硬件组合方式转换为物理地址，再来访问主存储器。这一过程称为存储最映射或
地址转换。今天，由虚拟地址控制的两级存储器层次结构为 DRAM和磁盘。表B-9显示了虚拟
存储器存储器层次结构参数的典型范围。

除了表B-9中提到的量化区别之外，缓存与虚拟存储器之间还有其他一些区别，如下所述。

口 发生缓存缺失时的替换主要由硬件控制，而虚拟存储器替换主要由操作系统控制。缺失
代价越长，正确作出决定就显得越重要，所以操作系统可以参与其中，花费一些时间来
决定要替换哪些块。
口处理器地址的大小决定了虚拟存储器的大小，但缓存大小与处理器地址大小无关。
• 除了在层次结构中充当主存储器的低一级后援存储之外，辅助存储还用于文件系统。事
实上，文件系统占用了大多数辅助存储。它通常不在地址空同中。

表B-9 缓存与虚拟存储器的典型参数范围
第一级缓存
参
数
虛拟存储器
块（页大小）
16~128字节
4096~65 536字节
命中时间
1~3个时钟周期
100~200个时钟周期
缺失代价
8-200个时钟周期
1 000 000~10 000 000个时钟周期
（访问时间）
（6~160个时钟周期）
（800 000~8 000000个时钟周期）
（传输时间）
（2-40个时钟周期）
（200000~2 000000个时钟周期）
觖失率
0.1%~10%
0.000 01%~-0.001%
地址映射
25~45位物理地址到14~20位级存地址
32~64位虚拟地址到25~45位物理地址
*虚拟存储器参敬是缓存参教的10到1 000000倍。通常，第一級缓存包含至少1NI数据，而物理存儲器包含256MIB
到1TB数据。

虚拟存储器还包含儿种相关技术。虚拟存储器系统可分为两类：页，采用大小固定的块；
段，采用大小可变的块。页大小通常固定为4096至8192字节，而段大小是变化的。任意处理
器所支持的最大段范围为2“个字节至23个字节，最小段为1个字节。图B-11显示了这两种方
法可以如何划分代码和数据。

代码
擞据
分页
分段

图B-11 分页和分段方式对程序的划分示例
是使用页虚拟存储器还是段虚拟存储器，这一决定会影响处理器。页寻址方式的地址是单
一固定大小，分为页编号和页内偏移量，与缓存寻址类似。单一地址对分段地址无效，可变大
小的段需要1个字来表示段号，1个字表示段内的偏移量，总共2个字。对编译器来说，不分段
地址空间更简单一些。

这两种方法的优缺点已经在操作系统教科书中进行了很好的阐述，表B-10总结了这些观
点。由于替换问题（表中第三行），今天很少再有计算机使用纯粹的分段方法。一些计算机使用
一种名为页式分段的混合方式，在这种方式中，一个段由整数个页组成。由于存储器不需要是
连续的，也不需要所有段都在主存储器中，从而简化了替换过程。最近的一种混合方式是由计
算机提供多种页面大小，较大页面的大小为最小页面大小的整数倍，且为2的幂。例如，IBM
40SCR 嵌入式处理器允许单个页面为1 KB、4KB （2 ×1 KB）、16 KB （2* × 1 KB）、64 KB （26 x
1 KB）、256 KB （28× 1 KB）、1024 KB （21x1 KB）、4096 KB （212 × 1 KB）。

表B-10 分页与分段的对比
页
段
每个地址的字
程序员是否可见
替换块
1
2（段和偏移）
应用程序程序员不可见
根容易（所有块的大小相同）
应用程序程序员可以看到
困难（必须查找主存储器中相邻的、可变
大小的未使用部分）
存储器使用效率低下
内部分段（页的未使用部分）
外部分段（主存储器的未使用部分）
高效的磁盘通信

是的（调整页大小，以平衡访同时间和传输时间）并非总是如此（小段可能仅传输几个字节）
*这两者都可能浪费存储器，取决于块大小及各分段能否很好地容纳于主存储器中。采用不受限指针的编程语言需委
传递段和地址。一种称为页式分段的混合方法可以发挥这两者的最佳状态：分段由页組成，所以替换一个坎是很轻
松的，而一个段仍被看作一个還辑单住。

\subsection{再谈存储器层次结构的4个问题}

我们现在已经为回答虚拟存储器的四个存储器层次结构问题做好了准备。

问题1：一个块可以放在主存储器的什么位置？

虚拟存储器的缺失代价涉及旋转磁存储设备的访问，因此非常高。如果在较低峡失率与较
筒单放置算法之间进行选择，操作系统设计人员通常选择较低缺失率，因为其缺失代价可能会
高得离谱。因此，操作系统允许将块放在主存储器中的任意位置。根据图 B-1 中的术语，这一
策略可以标记为全相联的。

问题2：如果一个块在主存储器中，如何找到它？

分页和分段都依靠一种按页号或段号索引的数据结构。这种数据结构包含块的物理地址。
对于分段方式，会将偏移量加到段的物理地址中，以获得最终物理地址。对于分页方式，该偏
移量只是被串接到这一物理分布地址（见图B-13）。
虚拟地址
虚拟页号
页偏移嫩
主存储器
分页表
物理地址
留 B-13
通过页表将虚拟地址映射到物理地址

这一包含物理页地址的数据结构通常采用一种分页表的形式。这种表通常根据虚拟页号进
行索引，其大小就是虚拟地址空间中的页数。如果虚拟地址为32位、4KB页、每个页表项（PTE）
大小为4字节，则页表的大小为（23 2 2）×22-222即4MB。

为了缩小这一数据结构，一些计算机向虚拟地址应用了一种散列功能。这种散列允许数据
结构的长度等于主存储器中物理页的数目。这一数目可以远小于虚拟页的数目。这种结构被称
为反转分页表。利用前面的例子，一个512 MB 的物理存储器可能只需要1MB （8× 512 MB/
4KB）的反转分页表；每个页表项另外需要4字节，用于表示虚拟地址。HP/Intel IA-64同时支
持传统页表和反转分页表，具体使用哪一种机制，交由操作系统程序员选择。

为了缩短地址转换时间，计算机使用一个专门进行这些地址变换的缓存，称为变换旁视缓
冲区，或者简称为变换缓冲区，稍后将进行详细介绍。

问题 3：在虚拟存储器缺失时应当替换哪个块？

前面曾经提到，操作系统的最高指导原则是将页错误降至最低。几乎所有操作系统都与这
一指导原则保持一致，尝试替换最近使用最少（LRU）的块，这是因为如果用过去的信息来预
测未来，将来用到这种块的可能性最低。

为了帮助操作系统评估LRU，许多处理器提供了一个使用位或参考位，从逻辑上来说，只要
访问一个页，就应对其进行置位。（为了减少工作，通过仅在发生转换缓冲区缺失时对其进行置
位，稍后将对此进行介绍。）操作系统定期对这些使用位清零，之后再记录它们，以判断在一个
特定时间段时使用了哪些页。通过这种方式进行跟踪，操作系统可以选择最近引用最少的一个页。
问题4：在写入时发生什么？

主存储器的下一级包含旋转磁盘，其访问会耗时数百万个时钟周期。由于访问时间的巨大
差异，还没有人构建一种虚拟存储器操作系统，在处理器每次执行存储操作时将主存储器直写
B.4 虚拟存储器
439
到磁盘上。（不要因为看到这一叙述，就认为这是一个通过首次构建这种操作系统而成名的机
会！）因此，这里总是采用写回策略。

由于对低一级的非必需访问会带来如此之高的成本，所以虚拟存储器系统通常会包含一个
重写位。利用这一重写位，可以仅将上次读取磁盘之后经过修改的块写至磁盘。

\subsection{快速地址变换技术}

分页表通常很大，从而存储在主存储器中，有时它们本身就是分页的。分页意味着每次存
储器访问在逻辑上至少要分两次进行，第一次存储器访问是为了获得物理地址，第二次访问是
为了获得数据。第2章曾经提到，我们使用局域性来避免增加存储器访问次数。将地址变换局
限在一个特缓存中，存储器访问就很少再需要第二次访同来转换数据。这一特地址变换缓
存被称为变换旁视缓冲区（TLB），有时也称为变换缓冲区（TB）。

TLB 项就像是一个缓存项目，其中的标志保存了虚拟地址部分，数据部分保存了特页帧
编号、保护字段、有效位，通常还有一个使用位和重写位。要改变页表中某一项的特页帧编
号或保护字段，操作系统必须确保旧项不在 TLB 中；否则，系统就不能正常运行。注意，这个
重写位意味着对应页曾被改写过，而不是指 TLB 中的地址变换或数据缓存中的特殊块经过改
写。操作系统通过改变页表中的值，然后再使相应 TLB 项失效来重置这些位。在从分页表中重
新加载该项时，TLB会获得这些位的准确副本。

图B-14给出了 Opteron 数据TLB 组织方式，并标出了每一个变换步骤。这个 TLB使用全
相联布置；因此，变换首先向所有标志发送虚拟地址（步骤1和步骤2）。当然，这些标志必须
标记为有效，以允许进行匹配。同时，根据 TLB 中的保护信息核对存储器访问的类型，以确认
其是否有效（也在步骤2中完成）。

虚拟页号 页偏移量
<362
<12>
①
<＞
<IX1><36>
②
VR/W
U/S D A
Tag
<28＞
物理地址
B-45
（地址的
低12位）
③
40选1多工器
<28≥
40位牧
④理地址
（地址的高28位）

图 B-14 在地址变换期间 Opteron 数据TLB 的操作。一次 TLB 命中的4个步骤用带圆圈的数字显示。这
个TLB有40项。B.5 节描述了 Opteron 页表项的各种保护字段与访问字段
和缓存中的理由相似，TLB 中也不需要包含页偏移量的12个位。匹配标志通过一个40选
1多工器，高效地发送相应的物理地址（步骤3）。然后将页偏移量与物理页帧合并，生成一个
完整的物理地址（步骤4）。地址大小为40位。

关于处理器时钟周期的确定，地址变换很可能发挥至关重要的作用，所以 Opteron 使用虚
拟寻址、物理标记的L1缓存。

\subsection{选择页大小}
最显而易见的体系结构参数是页大小。页大小的选择实际就是在偏向较大页与偏向较小页
的力量之间进行平衡的问题。以下因素偏向较大尺寸。

口 页表的大小与页大小成反比，因此，增大页的大小可以节省存储器（或其他用于存储器
映射的资源）。
口B.3节曾经提到，分页较大时，可以允许缓存命中时间较短的较大缓存。
口 与传递较小页相比，从（向）辅助存储传递较大页（有可能通过网络）的效率更高一些。
口 TLB项目的数量受限，所以分页较大意味着可以高效地映射更多存储器，从而可以降低
TLB 缺失数量。

由于最后这个原因，近来的微处理器决定支持多种页大小；对于一些程序，TLB缺失对CPI 的
重要性可能与缓存缺失相同。

采用较小分页的主要动机是节省存储。当虚拟内存的相邻区域不等于页大小的整数倍时，
采用较小页可以减少存储的浪费空间。页面中这种未使用存储器的术语名称为内部醉片。假定
每个进程有三个主要段（文本、堆和栈），每个进程的平均浪费存储量为页大小的1.5倍。对于
有数百 M存储器、页大小为4KB至8KB的计算机来说，这点数量是可以忽略的。当然，当页
大小非常大（超过32KB）时，那就可能浪费存储（主存储器和辅助存储器）和1/O带宽了。
最后一项关注是进程启动时间；许多进程都很小，较大的页面可能会延长调用一个进程的时间。
B.4.4 虚拟存储器和缓存小结

由于虚拟存储器、TLB、第一级缓存、第二级缓存都映射到虚拟与物理地址空间的一部分，
所以人们可能会混淆哪些位去了哪里。图B-15给出了一个从64位虚拟地址到41位物理地址的
假设示例，它采用两级缓存。这一L1缓存的缓存大小和页大小都是8KB，所以它是虚拟寻址、
物理标记的。L2缓存为4 MB。这两者的块大小都是64个字节。

第一，64位虚拟地址在逻辑上被划分为虚拟页号和页偏移量。前者被发送到TLB，以备变
换为物理地址，后者的高位被发送到L1缓存，充当索引。如果 TLB匹配命中，则将物理页号
发送到L1缓存标志，检查是否匹配。如果匹配，则是L1缓存命中。块偏移随后为处理器选择
该字。

如果L1缓存核对显示为缺失，则使用物理地址尝试L.2缓存。物理地址的中间部分用作4MB
L.2缓存的索引。将所得到的L2缓存标志与物理地址的上半部分对比，以检查是否匹配。如果
匹配，我们得到一次L.2缓存命中，数据被送往处理器，它使用块偏移量来选择所需字。在1.2
缺失时，会使用物理地址从存储器获取该块。

尽管这是一个简单示例，但该图与真实缓存之间的主要区别只是重复问题。因为，只有一
个L1缓存。如果有两个L1缓存，会重复该图的上半部分。注意，这会导致拥有两个 TLB，而
这正是典型情况。因此，一个缓存和 TLB 用于指令，由PC驱动，一个缓存和 TL.B 用于数据，
由实际地址驱动。

第二种简化是所有缓存与 TLB 都是直接映射的。如果有任何一个是n路组相联的，则会将
每一组标志存储器、比较器和数据存储器重复n次，并用一个n选1多工器将数据存储器连接
在一起，以选择命中内容。当然，如果总缓存大小保持不变，则缓存索引也会收缩log2n 位，
如图B-4中的公式所示。

虚拟地址<64>
虚拟页编号<51>
TLB标志比较地址<43>
页偏移量<13>
TLB 索引 8>L1缓存素引 7>
块偏移量<6>
至CPU
TLB 标志<43>
TLB 数据<28>
LI 标志比较地址<28>
LI 缓存标志<43>
LI 数据<512>
至CPU
1.2 标志比较地址<19>
物理地址<41>
12缓存索引≤16>
块偏移量<6
至CPU
L2缓存标志<19>
L.2 数据<512>
-②
至LI级存或CPU

图B-15 一个从虚拟地址到L2缓存访问的虚设存储层次结构的整体图像。页大小为8KB。TLB 为直接
映射，有256项。L1缓存为直接映射8 KB,L.2缓存为直接映射，大小为4MB。两者的块都是
64字节。虚拟地址为64位，物理地址为41位。这一简单图像与实际缓存的主要差别在于这一图
像多个组成部分的重复

\section{虚拟存储器的保护与示例}

在多重编程中，计算机由几个并行执行的程序共享，它的发明为程序之间的保护和共享提
供了新的要求。这些要求与今天计算机中的虚拟存储器紧密捆绑在一起，所以我们在这里用两
个虚拟存储器的示例来介绍这一主题。

多重编程导致了进程概念的出现。打个比方，进程就是程序呼吸的空气和生活的空间—
即一个正在运行的程序加上持续运行它所需要的所有状态。时分共享是多重编程的一种变体，
由几个同时进行交互的用户来共享处理器和存储器，给人的感觉是所有用户都拥有自己的计算
机。因此，它在任何时刻都必须能够从一个进程切换到另一进程。这种交换被称为进程切换或
上下文切换。

一个进程无论是从头到尾持续执行，还是被反复中断，与其他进程进行切换，其运行都必
须正常进行。维护正确进程行为的责任由程序和操作系统的设计者共同分担。计算机设计师必
须确保进程状态的处理器部分能够保存和恢复。操作系统设计师必须确保这些进程不会相互干
扰对方的计算。

保护一个进程的状态免受其他进程损害的最安全方法就是将当前信息复制到磁盘上。但是，
一次进程切换可能需要几秒的时间—这对时分共享环境来说过长了。

这一问题的解决方法是由操作系统对主存储器进行划分，使几个不同进程能够在存储器同
时拥有自己的状态。这种划分意味着操作系统设计师需要计算机设计师的帮助，以提供保护，
使一个进程无法修改其他进程。除了保护之外，计算机还为进程之间共享代码和数据提供了支
持，允许进程之间进行通信，或者通过减少相同信息的副本数目来节省存储器。

\subsection{保护进程}
使进程拥有自己的分页表，分别指向存储器的不同页面，这样可以为进程提供保护，避免
相互损害。显然，必须防止用户修改它们的分页表，或者以欺骗方式绕过保护措施。

根据计算机设计者或购买者的理解，可以逐步升高保护级别。向处理器保护结构中加人环，
可以将存储器访问保护扩展到远远超出最初的两级（用户级和内核级）。就像军用分类系统将信
息划分为绝密、机密、秘密和非涉密相似，安全级别的同心环状结构可以让最受信任的人访问
所有信息，第二受信任的人访问除最内层级别之外的所有信息，以此类推。“民用”程序是可信
度最低的，因此对访问范围的限制也最多。关于存储器中可能包含代码的部分也有一些限制（执
行保护），甚至对级别之间的入口点也要提供保护。本节后面介绍 Intel 80x86保护结构，这一结
构使用了环。在实践中，这些环相对于用户、内核模式的简单系统的改善并不是非常明显。

当设计者因为深入理解而加重安全恐惧时，这些简单的环可能就不够了。要限制程序在内
层保密位置的自由度，需要采用一种新的分类系统。除了军用模型之外，还可以将这一系统比
作钥匙和锁：没有钥匙的程序是不能对数据访问进行解锁的。为使这些钥匙（或者说能力）发
挥作用，硬件和操作系统必须能够明确地在程序之间传送它们，而不允许程序自行伪造它们。
为缩短钥匙核对时间，需要为这一核对机制提供大量硬件支持。

80x86 体系结构多年来已经尝试了这几种方法。由于保持后向兼容性是这种体系结构的指
导原则之一，所以这一体系结构的最新版本包含了它在虚拟存储器中的所有试验探索。这里将
回顾其中的两种：首先是较早的分段地址空间，然后是一种较新的平面64位地址空间。

\subsection{分段虚拟存储器举例：Intel Pentium中的保护方式}

一个人设计的第二个系统是他所有设计中最为危险的系统…•第二个系統的功能设计过多
是一种普遍倾向，设计师会将自己在第一个系统中谨慎排除的所有思想和装饰都塞到第二个系
统中。
-F.P. Brooks,Jr.
The Mvthical Man-Month （1975）

最早的8086使用分段寻址，但它没有提供任何虚拟存储器或保护。分段拥有基础寄存器，
但没是界限寄存器，也没有访问核查，在能够载人分段寄存器之前，必须将相应段载人物理存
储器中。Intel 对虚拟存储器和保护的专注在8086的后续产品中得到体现，扩展了一些字段来支
持更大地址。这种保护机制非常精巧，精心设计了许多细节，以尝试避免安全漏洞。我们将其
称为IA-32。接下来的几页内容将重点介绍Intel 的一些安全措施。如果你觉得阅读起来比较困
难，那就想想实现它们的难度吧！

第一种增强是将传统的两级保护模型加倍：IA-32 有四级保护，最内层（0）对应于传统的
内核模式，最外层（3）是权限最少的模型。IA-32为每一级提供独立栈，以避免突破不同级别
之间的安全措施。还有一些与传统分页表类似的数据结构，其中包含了段的物理地址，还有一
个对变换地址进行的核对清单。

Intel 设计师并没有就此驻足不前。IA-32 划分了地址空间，让操作系统和用户都能访问整
个空间。IA-32用户能够在保持全面保护的情况下调用这一空间中的操作系统例程，甚至还可以
向其传送参数。由于操作系统栈不同于用户栈，所以这一安全调用可不是一个简单操作。另外，
LA-32允许操作系统为那些传递给被调用例程的参数保持这些被调用例程的保护级别。禁止用户
进程要求操作系统间接访问一些该进程自己不能访问的东西，就可以防止这一潜在保护漏洞。
（此类安全漏洞称为特洛伊木马。）

Intel 设计师有一条指导原则：尽可能对操作系统持怀疑态度，并支持共享和保护。作这
种受保护共享的一个应用示例，假定有一个薪金支付系统，它要填写支票，并更新有关本年度
截至当前为止的总薪金和津贴支付信息。因此，我们希望赋予该程序读取薪金、当前信息和修
改当前信息的功能，但不能修改薪金。稍后将会看到支持这些功能的机制。在本小节的其他部
分，将研究IA-32保护的整体描述，并研究其开发动机。

1.增加界限检查和存储器映射

增强 Intel 处理器的第一个步骤是利用分段寻址来检查界限和提供基址。1A-32 中的分段寄
存器中包含的不是基址，而是指向虚拟存储器数据结构的索引，这种结构称为描述符表。描述
符表扮演着传统分页表的角色。IA-32上与页表项等价的是段描述符。它包含可以在PTE 中找
到的字段，如下所述。

口 存在位—等价于PTE 有效位，用于表明这是一个有效变换。
口 基址宇段——等价于一个页帧地址，包含该段第一个字节的物理地址。
口访问位—类似于某些体系结构中的引用位或使用位，可以为替换算法提供帮助。
口属性字段—为使用这一段的操作指定有效操作和保护级别。

还有一个在分页系统中没有出现的界限段，它确定这一分段有效偏移量的上限。图B-16给出了
IA-32段描述符的示例。

除了这种段式寻址之外，IA-32 提供了一种可选的分页系统。32位地址的上面部分选择段
描述符，中间部分是描述符所选页表中的索引。下面介绍不依赖分页的保护系统。

2. 增加共享和保护

为提供受保持的共享，地址空间的一半由所有进程共享，另一半由各进程独享，分别称为
全局地址空间和局部地址空间。为每一半都提供一个拥有适当名字的描述符表。指向共享段的
描述符被放在全局描述符表中，而指向专用段的描述符则被放在局部描述符表中。

程序向IA-32 段寄存器中载入一个案引和一个位，索引指向描述符表，这一个位表明程序
希望获得哪个表。根据描述符中的属性对操作进行检查，将来自处理器的偏移量加到描述符中
的基址来构成物理地址，前提是这一偏移量要小于界限字段。每个段描述符都有一个独立的2
位字段，提供这个段的合法访问级别。仅当程序尝试以段描述符中的较低保护级别使用段时，
才会发生违反错误。

我们现在可以介绍如何调用上述薪金支付程序来更新当前信息，但不允许它更新薪金数据。
可以向程序提供该信息的一个描述符，描述符的可写字段被清零，表明程序能够读取数据但不
能写数据。然后可以提供一个受信任的程序，它只会写入当前最新信息。在向这一程序提供的
描述符中，其可写字段已被置位（见图B-16）。薪金支付程序使用一个代码段描述符来调用受
信任的代码，描述符的一致性字段已被置位。这种设置意味着被调用程序取得了被调用代码的
权限级别，而不是调用者的权限级别。因此，薪金支付程序可以读取薪金信息，并调用受信任
的程序来更新当前总值，但薪金支付程序不能修改这些薪金信息。如果系统中存在特洛伊术马，
它必须位于受信任代码中才能生效，而这段代码的唯一任务就是更新截至目前的最新信息。这
种保护类型的观点是通过限制易损范围来提高安全性。

\begin{verbatim}
    8位
    4位
    32位
    属性位
    GD
    基址位
    24位
    界限位
    代码段
    存在位
    DPL11
    一致性位
    可读位
    访问位
    数据段
    存在位
    DPL 10
    向下扩展位
    可写位
    访问位
    8位
    属性位
    8位
    宇数
    16位
    目标选择位
    16位
    目标偏移量
    调用门
    存在位
    DPL
    0
    00100
\end{verbatim}
图 B-16 IA-32 段描述符由其属性字段中的位进行区分。基址位、界限位、存在位、可读位和可写位的用
途都是不言自明的。D是指令的默认寻址大小：16位或32位。G是段界限的粒度：0表示采用
字段，1表示采用4KB的页。在开启分页以设置页表大小时，将G设置为1。DPL 表示描述符
权限级别——根据代码权限级别核对 DPL，以查看是否允许访问。一致性是指代码采用被调用代
码的权限级别，而不是调用者的权限级别；用于库例程。向下扩展段颠倒检查过程，以基址字段
为高位标记，界限字段为低位标记。可以猜到，这种方式用于向下发展的栈段。宇数控制从当前
栈向调用门上新栈复制的字数。调用门描述符的其他两个字段——目标选择位和目标偏移量，分
别选择该调用目标的描述符及其内部的偏移量。IA-32保护模型中的段描述符远不止这三种

3. 增加从用户到操作系统门的安全调用，为参数继承保护级别

允许用户介入操作系统是非常大胆的一步。但是，硬件设计师如何能在不信任操作系统或
其他代码的情况下增加安全系统的可能性呢？IA-32方法是限制用户能够进人代码段的位置，将
参数安全地放到正确的栈中，并确保用户参数不会取得被调用代码的保护级别。

为限制进入其他代码，IA-32 提供了一种被称为调用门（call gate）的特殊段描述符，用属
性字段中的一位来识别。与其他描述符不同，调用门是一个对象在存储器中的完整物理地址；
处理器提供的偏移量被忽略。如上所述，它们的目的是防止用户随机进入一段受保护或拥有更
高权限的代码段中。在我们这个编程示例中，这意味着薪金支付程序唯一能够调用受信任代码
的位置就是在准确的边界位置。一致性段的正常工作需要这一限制。

如果调用者和被调用者“相互怀疑”，都不相信对方，那会怎么样呢？在图B-16询问描述
符的字数学段中可以找到解决方案。当一条调用指令调用一个调用门描述符时，描述符将局部
栈中的一些字复制到这个段级别相对应的栈中，字的数量由描述符指定。这一复制过程允许用
户首先将参数压人局部栈中，从而实现参数传递。随后由硬件将参数安全地传送给正确的栈。
在从调用门返回时，会将参数从栈中弹出，并将返回值复制到正确的栈中。注意，这一模型与
目前在寄存器中传递参数的实际做法不兼容。

这一机制仍然未能关闭潜在的安全漏洞：操作系统以操作系统的安全级别来使用作为参数
传递的用户地址，而不是使用用户级别。IA-32在每个处理器段寄存器中专门拿出2个位来指定
所请求的保护级别，从而解决了上述问题。当这些地址参数载人段寄存器时，它们将所请求的
保护级别设置为正确值。IA-32硬件随后使用所请求的保护级别来防止出现欺骗：对于使用这些
参数的系统例程，如果其权限保护级别高于被请求级别，则不允许该例程访问任何段。

\subsection{分页虚拟存储器举例：64位Opteron存储管理}

AMD 工程师发现人们很少使用上述这种精致、复杂的保护模型。常用的模型是在80386
中引人的一种平面32位地址空同，它将段寄存器的所有基址值都设置为0。因此，AMD在
64位模式中摒弃了多个段。它假定段基址为0，忽略了界限字段。页大小为4KB、2MB 和
4 MB。

AMD64体系结构的64位虚拟地址被映射到52位物理地址，当然，具体实现可以采用较少
的位数，以简化硬件。例如，Opteron 使用48位虚拟地址和40位物理地址。AMD64需要虚拟
地址的高16位就是低48位的符号扩展，这称为规范格式。

64 位地址空间页表的大小是惊人的。因此，AMI64 使用了一种多级层次结构分页表来映
射地址空间，使其保持合理大小。级别数取决于虚拟地址空间的大小。图B-17 显示了 Opteron
的48位虚拟地址的四级变换。

这些页表中各个表的偏移量来自4个9位字段。地址变换时，首先将第一个偏移量加到页
映射第4级基址寄存器，然后从这个位置读取存储器，获取下一级页表的基址。然后再将下一
级地址偏移量添加到这个新获取的地址，再次访问存储器，以确定第三个页表的基址。再次重
复以上过程。最后一个地址字段被加到这一最终基址，使用两者之和读取存储器，（最终）获得
所引用页面的物理地址。这个地址与12位页面偏移量串接在一起，获得完整的物理地址。注意，
Opteron 体系结构中的页表可以放在单个4KB 页中。

Opteron 在每个页表中使用64位的项目。前12位为保留位，供以后使用，接下来的52位
包含物理页帧编号，最后12 位提供保护、使用信息。尽管不同页表级别之间的字段会有所变化，
但基本上都有以下位。

口 存在位—表明该页存在于存储器中。
口读取/写入位—表明一个页是只读的，还是读写的。
口用户/管理员位——表明用户是可以访问该页，还是仅限于上面三个权限级别。
口脏位—表明该页是否已经被修改。
口访问位—表明自该位上次清零以来，是否曾读取或写人过该页。
口页面大小位—表明最后一级是4 KB页面，还是4 MB 页面；如果是后者，则 Opteron
只使用3个页面级别，而不是4个。
口 不执行位——未出现在80386保护机制中，添加这个位是为了防止代码在某些页内执行。
口 页级缓存禁用—表明是否可以缓存该页。
口页级直写

表明该页对数据缓存应用写回还是直写。
63
48 47
39 38
30 29
000...0or
111...1
页面映射 L4
页目录指针
页目录
21 20
页表
12 11
页偏移量
0
页映射L4基
址（CR3）
页映射L4表
页目录指针表
页目录表
：
页表
B-5G
物理地址
物理页帧号
页偏移盘
主存储器

图B-17 Opteron 虚拟地址的映射。拥有4个页表级别的 Opteron 虚拟存储器实现方式支持40位的有效物
理地址大小。每个页表有512项，所以每一级字段的宽度为9位。AMD64 体泰结构文档允许虚
拟地址大小从当前的48位增长到64位，允许物理地址从当前的40位增长到52位

由于 Opteron 在TLB 缺失时通常会经历四级页表，所以有3个可能位置来核对保护限制。
Opteron 仅服从底级PTE，检查其他各项只是为了确保设置了有效位。

由于该项目的长度为8个字节，每个页表有512项，而且 Opteron拥有大小为4KB的页，
所以这些页表的长度恰好为一页。这些四级字段的每一个字段长9位，页偏移量为12位。这一
推导留出 64-（4 x 9+12）=16位进行符号扩展，以确保地址的规范化。

尽管我们已经解释了合法地址的转换，那什么会防止用户创建非法地址转换并阻止故障发
生呢？这些页表本身是受保护的，用户程序不能对其进行写人。因此，用户可以尝试任意虚拟
地址，但操作系统通过控制页表项来控制访问哪个物理存储器。为了实现进程之间的存储器共
享，在每个地址空间中都设置一个页表项，指向同一个物理存储器页。

Opteron 采用4个 TLB来缩短地址转换时间，两个 TLB用于指令访问，两个用于数据访问。
与多级缓存类似，Opteron 通过两个较大的L2 TL及B 来减少 TLB 缺失：一个用于指令，一个用于
数据。表B-11介绍了数据 TLB。

表B-11
Opteron L1和L2指令与数据TLB的存储器层次结构参数
说 明
郵数
块大小
L1命中时间
I PTE（8个字节）
1个时间周期
B.6 谬论与易犯错误
447
（续）
参
数
L.2命中时间
L1TLB大小
L.2 TLB大小
块选择
写入策略
L1块布置
L2块布置
说明
7个时钟周期
指令TLB与数据TLB相同：每个TL.B40个PTE，有32个4KB的页和8个2MB或4MB的页
指令TLB与数据TL.B相同：512个PTE，均为4KB页
LRU
（不适用）
全相联
四路组相联

\subsection{小结：32位Intel Pentium与64位AMD Opteron的保护对比}

Opteron 中的存储器管理是当今大多数桌面或服务器计算机的典型代表，依靠页级地址变换
和操作系统的正确操作，为共享计算机的多个进程提供安全性。尽管 Intel 也提出了一些替代方
案，但它还是沿袭了 AMD的领先作法，接纳了 AMID64体系结构。因此，AMD 和 Intel都支持
80x86的64位扩展；但出于兼容性原因，这两者都支持复杂的分段保护机制。

如果分段保护模型的构建看起来要难于 AMD64，那是因为事实的确如此。由于很少有客
户使用这种精心设计的保护机制，所以构建这种模型所付出的努力重让工程师体验到挫败感。
此外，这种保护模型与 UNIX 等系统的简单分页保护机制也不一致，这一事实意味着只有专门
为这一计算机编写操作系统的人们才会采用它，而这种情况还没有发生过。

\section{谬论与易犯错误}

即使是对存储器层次结构的回顾也存有谬论和易犯错误！

易犯错误 地址空间太小。

DEC 和卡内基梅隆大学合作设计了新的PDP-11 计算机系列，但仅仅五年之后就发现他们
创造的作品中存在一个致命缺陷。IBM在 PDP-11诞生六年前发布的一种体系结构在25年之后
仍然生机勃勃，而且仅做了非常微小的修改。而曾被批评包含了多余功能的 DECVAX在 PDP-11
停产之后卖出了数百万件。为什么？

PDP-11 的致使缺陷就在于它的地址大小（16位），可以与TBM 360和 VAX的地址大小进
行一下对比，IBM360为24~31位，VAX为32位。由于程序的大小和程序所需要的数据量必须
小于 2 地址大小，所以地址大小限制了程序长度。地址大小之所以很难修改，其原因在于它确定了
所有与地址相关的最小宽度：PC、寄存器、存储器字和实际地址运算。如果从开始就没有扩展
地址的计划，那么成功改变地址大小的机会微乎其微，通常就意味着该计算机系列的终结。Bell
和 Strecker［1976］这样来讲述这一问题：

计算机设计中只有一种错误是很难挽回的，那就是没有足够的地址位用于存储器寻
址和存储器管理。几乎所有著名计算机都未曾打破这一“魔咒”，PDP-11也不例外！［P2］
一些曾经取得成功的计算机最终因为地址位不足而“饥渴”致死，下面是此类计算机的一
份不完整清单：PDP-8、PDP-10、PDP-11、Intel 8080、Intel 8086、Intel 80186、Intel 80286、
Motorola 6800、AMI 6502、Zilog 280、CRAY-1、CRAY X-MP。

令人尊敬的 80x86系列也已经进行了两次扩展，第一次是 1985年的 Intel 80386 扩展到32
位，最近一次是和 AMD Opteron一起扩展到64位。

易犯错误 忽视操作系统对存储器层次结构性能的影响。

表B-12 给出在执行三个大型工作负载时由于操作系统而产生的存储器停顿时间。大约25%
的停顿时间与操作系统有关，或者消耗在操作系统的缺失中，或者是因为应用程序与操作系统
互相干扰而导致的缺失。

表B-12
缺失
应用程序与操作系统中的缺失及消耗的时间百分比
间
由于应用程序缺失消
耗的时间百分比
时
由于操作系统缺失直接消耗的时间百分比
工作负栽
操作缺失和
应用程
序中的
百分比
操作系
统中的
百分比
固有的
操作系统
应用程
与应用程
序缺失
序冲突
操作系
统指令
缺失
迁移过程
中的数据
缺失
块操怍
中的数
据缺失
其他操
应用程序冲
作系统
突消耗的时
缺失
间百分比
Pmake
47%
53%
14.1%
4.8%
10.9%
1.0%
6.2%
2.9%
25.8%
Multipgm
53%
47%
21.6%
3.4%
9.2%
4.2%
4.7%
3.4%
24.9%
Oracle
73%
27%
25.7%
10.2%
10.6%
2.6%
0.6%
2.8%
26.8%

*操作系绒使应用程序的执行时间增加了大約25%。每个处理露有一个64 KB 指令缓存和一个两级教据雏存，第一級
*64KB，第二级为 256KB；所有缓存都与 16 字节块直接映射。这些数据是在 Silicon Graphics POWER 工作站 4D/340
上收集，它是一个由4个33 MHz R3000处理器組成的多处理器，在 UNIX System V上运行三个应用程序工作负載
-Pamke，并行编译 56个文件；Multipgm，并行数值程序 MP3D，与 Pmake 和五屏编辑会话同时运行；还有 Oracle，
使用 Oracle 数据库运行TP-1 基准测试的一个受限版本。（數据来自 Torrellas、Gupta 和 Hennessy ［1992］。）
易犯错误 依靠操作系统来改变页面大小。

Alpha 体系结构有一个非常精细的计划：通过增大页面大小，甚至达到虚拟地址的大小，
借以发展其体系结构。在后来的 Alpha 结构中增大页面大小时，操作系统设计人员拒绝了这项
修改，最终通过修改虚拟存储器系统来增大地址空间，页面大小保持8KB不变。

其他计算机的架构师注意到 TLB 缺失率极高，所以向 TLB 中增加了多种较大的页面大小。
希望操作系统程序员会将一个对象分配到最大页中，从而保留 TLB 项目。在尝试了10来年之
后，大多数操作系统仅在精心选择的功能中使用了这些“超级页面”，比如映射显示存储器或其
他1/O设备，或者为数据库代码使用这种极大页面。

\section{结语}

要想制造出能够跟上处理器步伐的存储器系统，其难度极大，无论多么先进的计算机，其
主存储器的制造原材料都与最廉价的计算机一致，这一事实为上述难度添加了新的注脚。这里
能为我们提供帮助的是局域性原理—当前计算机中存储器层次结构的各个级别（从磁盘到
TLB）都证明了它的正确性。

但是，到存储器的相对延迟不断增加，2011年达到数百个时钟周期，这就意味着，如果程
序员和编译器编写人员希望自己的程序能够正常执行，就必须了解缓存和TLB的参嫩。

\section{历史回顾与参考文献}
附录L.3节中，我们研究了缓存、虚拟存储器和虚拟机的历史。（这一历史内容包含了本附
录和第3章。）IBM在所有这三种技术的历史上都扮演着重要角色。这一节还包含了供扩展阅读
的参考文献。

练习（Amr Zaky设计）
B.1［10/10/10/15］<B.1>你正在尝试理解局域性原理对于证明缓存存储器应用的正当性有多么重要，
于是用一个拥有 L.I 数据缓存和主存储器的计算机进行实验（专注于数据访问）。不同访问类
型的延迟如下（用CPU周期表示）：缓存命中，1个周期；缓存缺失，105个周期；禁用缓存
时的主存储器访问，100个周期。

a.［107<B.1>在运行一个总缺失率为5%的程序时，存储器平均访问时间为多少（用CPU 周期
表示）？

b. ［10］<B.1>运行一个专门设计用于生成完全随机数据访问的程序，这些访问中不存在局域性。
为此，使用一个大小为256 MB 的数组（整个数组都装在主存储器中）。持续访问这一数组
的随机元素（使用均匀随机数生成器来生成元素索引）。如果数据缓存大小为64 KB，存储
器平均访问时间为多少？

c.［10］<B.1>如果将（b）部分得到的结果与禁用缓存时的主存储器访问时间对比，则可以说局域
性原理在证明缓存存储器使用正当性方面扮演着什么样的角色？

d. ［15］ <B.1>你观察到一次缓存命中可以得到99个周期的收益（1个周期对100个周期），但
它会在缺失时造成5个周期的损失（105个周期对100个周期）。在一般情况下，我们可以
将这两个量表示为G（收益）和L（损失）。使用这两个量（G和L），给出缓存应用不会
产生反作用的最高敏失率。

［15/15］<B.1>对于本练习，我们假定有512字节的缓存，块大小为64字节。我们还假定主存储
器的大小为2KB。我们可以将存储器看作是一个由 64字节块组成的数组：MO、MI、•⋯
M31。表B-13列出了在缓存为全相联时，可以驻存于不同缓存块中的主存储器块。
a.［15］<B.1>如果缓存的组织方式采用直接映射，请给出表中内容。
b.［15］<B.1>如果缓存的组织方式采用四路组相联，重复（a）部分中的工作。
表B-13 可以驻存在缓存块中的存储器块
缓存块
0
1
2
3
4
5
6
7
组
0
0
0
0
0
0
o
0
路
可以驻存在缀存块中的存储嚣块
0
MO, M1,M2，•，M31
1
MO, M1, M2，•，M31
2
MO, M1,M2，•，M31
3
MO, M1, M2，•，M31
4
MO, M1,M2，，M31
s
MO, M1,M2，：，M31
6
MO, MI, M2.，M31
7
MO, MI, M2，⋯，M31
B.3 ［10/10/10/10/15/10/15/20］<B.1>人们希望降低缓存的功耗，这一愿望经常会影响到缓存的组织方
式。为此，我们假定缓存在物理上分布到一个数据数组（保存数据）、标志数据（保存标志）
B-59
450
B-60
B-
B.4
附录B 存储器层次结构回顾
和替换数组（保存替换策略所需要的信息）。此外，这些数组中的每一个数组都在物理上分布
到多个可以各别访同的子数组中（每路一个子数组）；例如，四路组相联最近最少使用（LRU）
缓存将拥有4个数据子数组、4个标志子数组和4个替换子数组。我们假定在使用L.RU替换策
略时，在每次访问时都会访问一次替换子数组，如果使用先人先出（FIFO）替换策略，会在每
次缺失时访问一次。在使用随机替换策略时不需要它。对于一个具体缓存，已经确定对不同数
组的访何具有以下功耗权重：
数组
功耗权重（每一被访问路）
数据数组
20个单位
标志数组
S个单位
其他数组
1个单位

估计以下配置的缓存功耗（以功率单位表示）。我们恨定该缓存为四路组相联。这里不考
忠主存储器访问功率（尽管它也非常重要）。给出LRU、FIFO 和随机替换策略下的答案。

a. ［10］<B.1>次缓存读取命中。同时读取所有数组。
b.［10］＜B.1>针对缓存读取缺失重复（a）部分。
c.［10］<B.1>假定缓存访问分跨在两个周期内，重复（a）部分。在第一个周期内，访问了所有标
志子数组。在第二个周期内，仅访问那些标志匹配的子数组。
d. ［10］ <B.1>对缓存读取觖失重复（c）部分（第二个周期没有数据数组访问）。
e. ［15］<B.1>假定添加了预测待访问缓存路的逻辑，重复（c）部分。在第一个周期时，仅访问预
测路的标志子数组。一次路命中（在预测路内的地址匹配）意味着缓存命中。发生路觖失时
则在第二个周期内查看所有标志子数组。在路命中时，在第二周期内仅访问一个数据子数组
（标志匹配的那个子数组）。假定存在路命中。

f.［10］ <B.1>假定路预测器缺失（选择的路是错误的），重复（e）部分。当其失败时，路预测器
另外增加一个周期，在这个周期中访问所有标志子数组。假定一次缀存读取命中。
8.［1.5］ <B.1>假定一次缓存读取缺失，重复（f）部分。
h. ［20］ <B.1>对于工作负载具有以下统计数字的一般情况，重复（e）、（t）和（g）部分：路预测器敏
失率=5%，缓存缺失率=3%。（考虑不同替换策略）。

［10/10/15/15/15/20］<B.1>我们使用一个具体示例来对比直写缓存与写回缓存的写人带宽需求。
我们假定有一个 64KB缓存，其行大小为32个字节。缓存会在写人缺失时分配一行。如果配置
为写回缓存，它会在需要替换时写回整个脏行。我们还惯定该缓存通过一个宽度为64位（8个
字节）的总线连接到层次结构的下一级。在这一总线上进行B字节写人访问的CPU周期数为：
10+s（ ）

例如，一次8字节写人将爾要10+5（号」一〕个周期，而使用间一公式时，12字节的写人将需
要15个周期。参考下面的C代码段，回答以下问题：
\begin{verbatim}
    #define PORTION 1 Base = 8*i: for （unsigned int j=hases
    j ≤ base+PORTION: j++）//假定寸已被存緒在寄存器中
    data［jl = j：
\end{verbatim}
a. ［10］<B.1>对于一个直写缓存，j循环的所有迭代中，在向存储器执行写人传输时，一共花费
多少个CPU周期？
b. ［10］<B.1>如果缓存配置写回缓存，有多少个CPU周期花费在写回缓存行上？
c.［15］<B.1>将 PORTION 改为8，重复（a）部分。
B.8 历史回顾与参考文献
451
d.［15］<B.1>（在替换缓存行之前），对同一缓存行至少进行多少次数组更新时，才会使写回
缓存占优？
e. ［1S］<B.I>给出这样一种情景：缓存行的所有字都将被写人（不一定使用上述代码），直写
缓存需要的总CPU間期少于写回缓存。
B.S【10/10/10/10/］<B.2>你正要来用一个具有以下特征的处理器构建系统：循序执行，运行频率为
1.1 GHz，排除存储器访问在外的CPI为0.7。只有载人和存储指令能从存储器读写数据，载人
指令占全部指令的20%，存储指令占5%。此计算机的存储器系统包括一个分离的L.1缓存，它
在命中时不会产生任何代价。I缓存和 D缓存都是直接映射，分别为32KB。I缓存的缺失率2%，
块大小为32字节，D缓存为直写缓存，缺失率为5%，块大小为16字节。D缓存上有一个写人
缓冲区，消除了绝大多数写入操作的停顿，占总写人操作的95%。512 KB写回、统一L.2缓存
的块大小为64字节，访间时间为I5ns。它由128位数据总线连接到L1缓存，运行频率为266
MHz，每条总线每个时间周期可以传送一个128位字。在发往此系统L.2缓存的所有存储器引
用中，其中80%的引用无须进入主存储器就可以得到满足。另外，在被替换的所有块中，50%
为脏块。主存储器的宽度为128位，访同延迟为60ns，在此之后，可以在这个宽128位、频率
为133MIHz的主存储器总线上以每个周期传送一个字的速率来传送任意数目的总线字。
a.［10］<B.2>指令访问的存储器平均访问时间为多少？
b.［10］<B.2>数据读取的存储器平均访问时间为多少？
c.［10］<B.2>数据写人的存储器平均访问时间为多少？
d. ［10］<B.2>包括存储器访问在内的整体CPI为多少？
B.6
［10/15/15］<B.2>在将缺失率（每次引用的映失数）转换为每条指令的缺失数时，需要依靠两个
因数：每条所提取指令的引用数，所提取指令中实际提交的比例。
a.［L0］<B.2>B.1.1 节中每条指令缺失数的公式最初是用三个因数表示的：映失率、存储器访问
和指令数。这些因数中的每一个都代表实际事件。将每条指令的缺失数写为缺失率乘以因数
每条指令的存储器访问数，会有什么不同？
b. ［15］<B.2>推测处理器会提取一些最终不会提交的指令。B.1.1节中每条指令缺失数的公式是
指执行路径上每条指令的缺失数，也就是说，仅包括那些为运行程序而必须实际执行的指令。
将 B.1.1节中每条指令缺失数的公式转换为仅使用缺失率、所提取每条指令的引用数和所提
交指令占所提取指令的比例。为什么要依靠这些因数而不是B.1.1 节公式中的因数？
c.［15］<B.2>（b）部分的转换可能会得出一个错误值：每条所提取指令的引用值不等于任意特定
指令的引用数。重写（b）部分的公式，以纠正这一不足。
B.7
［20］<B.1、B.3>如果系统采用直写L1缓存，再以写回L.2缓存（而非主存储器）提供后备支援，
则可以简化合并写人缓冲区。解释为什么可以这样做。拥有完整写人缓冲区（而不是你刚刚提
议的简单版本）时能否有所帮助？
B.8
［20/20/15/25］ <B.3>LRU 替换策略基于以下假定：如果最近访问地址 A1 的频率低于地址 A2，
那么未来再次访问A2的时机要早于A1。因此，为A2指定了高于A1的优先级。试讨论，当一
个大于指令缓存的循环连续执行时，这一假定为什么不成立。例如，考虑一个全相联128字节
指令缓存，其块大小为4个字节（每个块可以正好容纳一条指令）。此缓存使用LRU替换策略。
a. ［20］<B.3>对于一个拥有大量迭代的64字节循环，渐近指令缺失率为多少？
b.［20］<B.3>对于大小为192字节和320字节的循环，重复（a）部分。
c.［15］<B.3>如果缓存替换策略改为最近使用最多（MRU）（替换最近访问最多的缓存行），
以上三种情景（64、192、320字节的循环）中的哪一种情景将因为这一策略而受益？
d. ［25］ <B.3>提出执行性能可能优于LRU的更多替換策略。
B.9
［20］<B.3>从统计的角度来看，增加缓存的相联度（所有其他常数保持恒定）可以降低嵌失率。
但也可能存在一些不正常情景：对于特定工作负载，增加缓存相联度反而会使缺失率增大。考
B-62
B-63
452
B-64
附录B 存储嚣层次结构回顾
虑同等大小的直接映射与两路组相联缓存的对比。假定组相联缓存使用LRU替换策略。为进行简
化，假定块大小为一个字。现在构造一组会在两路相联缓存中产生更多缺失的字访问。（提示：
集中精力使构造的访问全部指向两路组相联缓存中的单个组，从而使同一种跟踪独占访问直接
映射缓存中的两个块。）
B.10 ［10/10/15］<B.3>考虑一个由L！ 和1.2数据缓存组成的两级存储器层次结构。假定两个缓存在写
人命中时都使用写回策略，两者的块大小相同。列出在以下事件时采取的操作。
a. ［10］<B.3>当缓存组织方式为包含式层次结构时，发生L1缓存觖失。
b. ［10］<B.3>当缓存组织方式为互斥式层次结构时，发生L1缓存缺失。
c.［15］<B.3>在（a）部分和（b）部分中，考虑被逐出行为胜行或清净行的可能性（需要更新和不需
要更新的可能性）。
B.11 ［15/20］<B.2、B.3>禁止某些指令进人缓存可以降低冲突缺失。
a. ［15］ <B.3>画出一个程序层次结构，其中最好禁止其中一部分程序进人指令缓存。（提示：
考虑一个程序，其代码块所在的循环嵌套要深于其他块所在的嵌套。）
b.［20］<B.2、B.3>给出一些软件或硬件技术，用于禁止特定块进人指令缓存。
B.12 ［15］<B.4>一个程序运行于拥有四项全相联（微）变换旁视缓冲区（TLB）的计算机上。
虚拟页号
57
10
15
物理页号
30
1
10
25
有效项
1
下面是一组由程序访问的虚拟页号。指出每个访问是否会发生 TLB 命中/缺失，如果访问
页表，它是发生页命中还是页错误。如果未被访问，则在页表列下放人一个X。
虚拟页号
0
1
2
3
4
5
6
7
8
物理页号
3
7
6
是否存在
是
否
否
是
是
10
11
12
13
14
15
14
30
26
11
13
18
10
56
110
33
12
25
B.8 历史回顾与参考文献
页表（衛中或缺失）
453
被访问的處拟页
1
TLB（命中或缺失）
9
14
10
6
15
12
7
2
B.13 ［1S/15/15/15/<B.4>—些存储器系统以软件处理 TLB 缺失（将其作为异常），而另外一些则使
用硬件来处理 TLB 缺失。
a.［15］<B.4>这两种用于处理TLB缺失的方法有哪些折中？
b.［15］<B.4>在软件中进行的TLB缺失处理是否总是慢于在硬件中进行的TLB缺失处理？请解
释原因。
c.［15］ <B.4>是否存在一些页表结构，在硬件中难以处理，但在软件中则有可能实现？是否有
一些结构难以在软件中处理，但易于用硬件管理？
d. ［15］ <B.4>为什么浮点程序的 TLB 缺失率通常高于整数程序的缺失数？
B.14 ［25/25/25/25/20］＜B.4>TLB应当有多大？TLB缺失通常非常快（加上异常成本，少于10条指令），
因此，仅仅为了使 TLB 缺失率降低一点点而使用庞大的 TLB 是不值得的。使用 SimpleScalar
模拟器（www.cs.wisc.edu/mscalar/simplescalar.htrml）和一或多个 SPEC95基准测试，计算以下
TLB 配置的 TLB缺失率和 TLB开销（以处理TLB 缺失所浪费的时间百分比表示）。假定每个
TLB 缺失需要20条指令。
a. ［25］ <B.4>128 项，两路组相联，4KB至64KB 页面（均为2的幂）。
b. ［25］<B.4>256项，两路组相联，4KB 至64KB 页面（均为2的幂）。
c.［25］<B.4>512项，两路组相联，4KB 至64KB 页面（均为2的幂）。
d. ［25］<B.4>1024项，两路组相联，4KB 至64KB 页面（均为2的幕）。
e.［20］<B.4>多任务环境对 TLB 缺失率和开销的影响如何？上下文切换频率对开销有什么样的影响？
B.15 ［15/20/20］<B.5>利用类似于 Hewlett-Packard Precision Architecture （HP/PA）中使用的保护机制，
有可能提供一种比 Intel Pentium 体系结构更灵活的保护方式。在这种机制中，每个页表项包含
一个“保护 TD”（键），还有对该页的访问权限。在每次引用中，CPU 将页表项中的保护 ID
与存储在4个保护 ID 寄存器中的保护 ID 逐一对比（对这些寄存器的访问要求 CPU处于管理员
模式）。如果寄存器内容与页表项中保护 D 都不匹配，或者如果该访问不是受权访问（比如，
写人只读页），则会生成异常。
2. ［15］<B.5>进程如何在任意给定时刻都拥有4个以上的有效保护 LD？换句话说，假定进程希
望同时拥有10个保护 ID。请给出一种可以实现这一愿望的机制（可能需要来自软件的帮助）。
b.［20］＜B.S>请解释：如何利用这一模型，用一些不能相互改写的较小段代码（微内核）组合
构造出操作系统。与整体操作系统（在这种操作系统中，操作系统的任意代码都可以写入任
意存储器位置）相比，这种操作系统可能拥有哪些优势？
c.［20］<B.S>简单地改变这一系统的设计，就能使每个页表项有两个保护ID，一个用于读取访
问，一个用于写人或执行访问（如果可写位或可执行位都未被置位，则不使用这一字段）。
为读取与写人功能使用不同保护ID 会有什么好处？（提示：这样能否简化进程之间数据与
代码的共享？）
B-69
B-6a
B-67
©.J